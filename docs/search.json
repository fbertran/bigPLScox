[{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Benchmarking bigPLScox","text":"bigPLScox package now provides three distinct engines extracting PLS components Cox regression: original matrix-based solver (big_pls_cox), new Armadillo backend (big_pls_cox_fast), stochastic gradient descent routine (big_pls_cox_gd). vignette shows benchmark implementations coxgpls() standard survival::coxph() fit. rely bench package collect timing memory statistics. chunks wrapped LOCAL flag CRAN builds can skip heavier computations.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"dependencies","dir":"Articles","previous_headings":"","what":"Dependencies","title":"Benchmarking bigPLScox","text":"","code":"library(bigPLScox) library(survival) library(bench) library(bigmemory) library(plsRcox)"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"simulated-data","dir":"Articles","previous_headings":"","what":"Simulated data","title":"Benchmarking bigPLScox","text":"reuse helper dataCox() generate survival outcomes right censoring. Adjust n p stress-test solvers larger problems.","code":"set.seed(2024) sim_design <- dataCox(   n = 2000,   lambda = 2,   rho = 1.5,   x = matrix(rnorm(2000 * 50), ncol = 50),   beta = c(1, 3, rep(0, 48)),   cens.rate = 5 )  cox_data <- list(   x = as.matrix(sim_design[, -(1:3)]),   time = sim_design$time,   status = sim_design$status )  X_big <- bigmemory::as.big.matrix(cox_data$x)"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"running-the-benchmark","dir":"Articles","previous_headings":"","what":"Running the benchmark","title":"Benchmarking bigPLScox","text":"Dense matrix scenario – compares classical coxgpls() workflow dense variants big-memory solvers survival::coxph(). Big-memory scenario – evaluates big_pls_cox_fast() big_pls_cox_gd() directly big.matrix, illustrating benefit shared-memory interface. number iterations can increased stable measurements running locally.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"dense-matrix-comparison","dir":"Articles","previous_headings":"","what":"Dense matrix comparison","title":"Benchmarking bigPLScox","text":"higher itr/sec value indicates faster throughput. fast backend provide best compromise speed accuracy dense setting.","code":"bench_dense <- bench::mark(   coxgpls = coxgpls(     cox_data$x,     cox_data$time,     cox_data$status,     ncomp = 5   ),   big_pls = big_pls_cox(cox_data$x, cox_data$time, cox_data$status, ncomp = 5),   big_pls_fast = big_pls_cox_fast(cox_data$x, cox_data$time, cox_data$status, ncomp = 5),   big_pls_gd = big_pls_cox_gd(X_big, cox_data$time, cox_data$status, ncomp = 5),   coxph = coxph(Surv(cox_data$time, cox_data$status) ~ cox_data$x, ties = \"breslow\"),   iterations = 75,   check = FALSE ) bench_dense$expression <- names(bench_dense$expression) bench_dense[, c(\"expression\", \"median\", \"itr/sec\", \"mem_alloc\")] #> # A tibble: 5 × 4 #>   expression     median `itr/sec` mem_alloc #>   <chr>        <bch:tm>     <dbl> <bch:byt> #> 1 coxgpls       20.61ms     47.9    31.06MB #> 2 big_pls       136.9ms      7.24    4.34MB #> 3 big_pls_fast   8.62ms    116.      5.42MB #> 4 big_pls_gd    14.24ms     69.7     6.41MB #> 5 coxph         28.34ms     35.2    13.39MB"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"big-memory-comparison","dir":"Articles","previous_headings":"","what":"Big-memory comparison","title":"Benchmarking bigPLScox","text":"next experiment reuses big.matrix version predictors adds SGD solver. coxgpls() requires -memory matrix, included round. classical solver still run dense matrix reference, fast SGD routines operate big.matrix without copying. Expect fast backend dominate runtime SGD maintains scalability --memory workflows.","code":"bench_big <- bench::mark(   big_pls_fast = big_pls_cox_fast(X_big, cox_data$time, cox_data$status, ncomp = 5),   big_pls = big_pls_cox(cox_data$x, cox_data$time, cox_data$status, ncomp = 5),   big_pls_gd = big_pls_cox_gd(X_big, cox_data$time, cox_data$status, ncomp = 5, max_iter = 300),   iterations = 75,   check = FALSE ) bench_big$expression <- names(bench_big$expression) bench_big[, c(\"expression\", \"median\", \"itr/sec\", \"mem_alloc\")] #> # A tibble: 3 × 4 #>   expression     median `itr/sec` mem_alloc #>   <chr>        <bch:tm>     <dbl> <bch:byt> #> 1 big_pls_fast   7.25ms    137.      3.41MB #> 2 big_pls      142.74ms      6.89    4.25MB #> 3 big_pls_gd    14.77ms     66.5     6.34MB"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"visualising-the-results","dir":"Articles","previous_headings":"","what":"Visualising the results","title":"Benchmarking bigPLScox","text":"bench includes autoplot() plot() helpers visual inspection timing distribution.   Additional geometries, ridge plots, available via autoplot(bench_res, type = \"jitter\").","code":"plot(bench_dense, type = \"ridge\") plot(bench_big, type = \"ridge\")"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"exporting-benchmark-tables","dir":"Articles","previous_headings":"","what":"Exporting benchmark tables","title":"Benchmarking bigPLScox","text":"integrate benchmark automated pipelines, store results inst/benchmarks/ directory. run can include meta-data dataset parameters, number iterations, git commit identifiers.","code":"if (!dir.exists(\"inst/benchmarks/results\")) {   dir.create(\"inst/benchmarks/results\", recursive = TRUE) } write.csv(bench_dense[, 1:9], file = \"inst/benchmarks/results/benchmark-dense.csv\", row.names = FALSE) write.csv(bench_big[, 1:9], file = \"inst/benchmarks/results/benchmark-big.csv\", row.names = FALSE)"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"additional-scripts","dir":"Articles","previous_headings":"","what":"Additional scripts","title":"Benchmarking bigPLScox","text":"package also ships standalone scripts inst/benchmarks/ mirror vignette exposing additional configuration points. Run repository root : script accepts environment variables adjust problem size stores results inst/benchmarks/results/ time-stamped filenames.","code":"Rscript inst/benchmarks/cox-benchmark.R Rscript inst/benchmarks/benchmark_bigPLScox.R Rscript inst/benchmarks/cox_pls_benchmark.R"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Overview of bigPLScox","text":"goal bigPLScox provide Partial Least Squares (PLS) variants Cox proportional hazards model scale high-dimensional survival settings. package implements several algorithms tailored large-scale problems, including sparse, grouped, deviance-residual-based approaches. integrates bigmemory ecosystem data stored disk can analysed without exhausting RAM. vignette gives quick tour core workflows. highlights prepare data, fit model, assess model quality, explore advanced extensions. complementary vignette “Getting started bigPLScox” offers hands-tutorial, “Benchmarking bigPLScox” focuses performance comparisons.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"package-highlights","dir":"Articles","previous_headings":"","what":"Package highlights","title":"Overview of bigPLScox","text":"Generalised PLS Cox regression via coxgpls() support grouped predictors. Sparse structured-sparse extensions coxsgpls() coxspls_sgpls(). Deviance-residual estimators coxgplsDR() increased robustness. Cross-validation helpers (cv.coxgpls(), cv.coxsgpls(), …) select number latent components. Big-memory interfaces (big_pls_cox(), big_pls_cox_gd()) designed file-backed matrices stored bigmemory.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"available-algorithms","dir":"Articles","previous_headings":"","what":"Available algorithms","title":"Overview of bigPLScox","text":"following modeling functions provided: coxgpls() generalized PLS Cox regression. coxsgpls() coxspls_sgpls() sparse structured sparse extensions. coxgplsDR() coxsgplsDR() deviance-residual-based estimation. cv.coxgpls() related cv.* helpers component selection. stochastic gradient descent large data package includes big_pls_cox() big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"loading-an-example-dataset","dir":"Articles","previous_headings":"","what":"Loading an example dataset","title":"Overview of bigPLScox","text":"package ships small allelotyping dataset use throughout vignette. data include censoring indicators alongside large set predictors.","code":"library(bigPLScox)  data(micro.censure) data(Xmicro.censure_compl_imp)  train_idx <- seq_len(80) Y_train <- micro.censure$survyear[train_idx] C_train <- micro.censure$DC[train_idx] X_train <- Xmicro.censure_compl_imp[train_idx, -40]"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"fitting-a-pls-cox-model","dir":"Articles","previous_headings":"","what":"Fitting a PLS-Cox model","title":"Overview of bigPLScox","text":"coxgpls() provides matrix interface mirrors survival::coxph() adds latent components stabilise estimation high dimensions. summary includes convergence diagnostics, latent component information, predicted linear predictors can used risk stratification.","code":"fit <- coxgpls(   X_train,   Y_train,   C_train,   ncomp = 6,   ind.block.x = c(3, 10, 15) ) fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>          coef exp(coef) se(coef)      z       p #> dim.1 -0.6003    0.5486   0.2197 -2.733 0.00628 #> dim.2 -0.6876    0.5028   0.2816 -2.442 0.01460 #> dim.3 -0.4922    0.6113   0.2498 -1.971 0.04877 #> dim.4  0.2393    1.2703   0.2861  0.836 0.40292 #> dim.5 -0.3689    0.6915   0.2200 -1.677 0.09359 #> dim.6  0.1570    1.1700   0.2763  0.568 0.56979 #>  #> Likelihood ratio test=23.99  on 6 df, p=0.0005249 #> n= 80, number of events= 17"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model assessment","title":"Overview of bigPLScox","text":"Cross-validation helps decide many components retained. cv.coxgpls() helper accepts either matrix list containing x, time, status elements.  resulting object may plotted visualise cross-validated deviance apply one-standard-error rules choosing number components.","code":"set.seed(123) cv_res <- cv.coxgpls(   list(x = X_train, time = Y_train, status = C_train),   nt = 10,   ind.block.x = c(3, 10, 15) ) #> CV Fold 1 #> CV Fold 2 #> CV Fold 3 #> CV Fold 4 #> CV Fold 5 cv_res #> $nt #> [1] 10 #>  #> $cv.error10 #>  [1] 0.5000000 0.6013049 0.5183694 0.4226056 0.3860331 0.4071207 0.4252845 #>  [8] 0.4001223 0.4464093 0.4526887 0.4695600 #>  #> $cv.se10 #>  [1] 0.00000000 0.03487588 0.06866706 0.07717020 0.07373734 0.07084802 #>  [7] 0.07707939 0.07247893 0.07317843 0.06341118 0.06252387 #>  #> $folds #> $folds$`1` #>  [1] 31 42 69 75 72 12 66 27 71 55 58 49 11 30 37 22 #>  #> $folds$`2` #>  [1] 79 50 57 68 17 15 64 74 34 13 80 76 61  2 24 35 #>  #> $folds$`3` #>  [1] 51 43  9 62 73 32 41 78 29 18  6 16 44 59 33 48 #>  #> $folds$`4` #>  [1] 14 77 26 19 39 65 10 56  5  1 21 20 46 60  3 47 #>  #> $folds$`5` #>  [1] 67 25  7 36 53 45 23 38  8 40 54 28 52  4 70 63 #>  #>  #> $lambda.min10 #> [1] 1 #>  #> $lambda.1se10 #> [1] 0"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"alternative-estimators","dir":"Articles","previous_headings":"","what":"Alternative estimators","title":"Overview of bigPLScox","text":"Deviance-residual-based estimators provide increased robustness iteratively updating residuals. Sparse variants enable feature selection extremely high-dimensional designs. Additional sparse estimators can invoked via coxsgpls() coxspls_sgpls() providing keepX penalty arguments control number active predictors per component.","code":"dr_fit <- coxgplsDR(   X_train,   Y_train,   C_train,   ncomp = 6,   ind.block.x = c(3, 10, 15) ) dr_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>          coef exp(coef) se(coef)     z        p #> dim.1 0.92699   2.52690  0.23301 3.978 6.94e-05 #> dim.2 0.85445   2.35008  0.27352 3.124  0.00178 #> dim.3 0.56308   1.75607  0.29847 1.887  0.05922 #> dim.4 0.49242   1.63627  0.32344 1.522  0.12789 #> dim.5 0.18706   1.20569  0.38769 0.482  0.62946 #> dim.6 0.08581   1.08960  0.31517 0.272  0.78541 #>  #> Likelihood ratio test=51.46  on 6 df, p=2.39e-09 #> n= 80, number of events= 17"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"working-with-big-data","dir":"Articles","previous_headings":"","what":"Working with big data","title":"Overview of bigPLScox","text":"extremely large problems, stochastic gradient descent routines operate memory-mapped matrices created bigmemory. helper converts standard matrix big.matrix runs small example. big_pls_cox_gd() function exposes gradient-descent variant often preferred streaming workloads. functions can combined foreach::foreach() multi-core execution.","code":"X_big <- bigmemory::as.big.matrix(X_train) big_fit <- big_pls_cox(   X_big,   time = Y_train,   status = C_train,   ncomp = 6 ) big_fit #> $scores #>               [,1]        [,2]        [,3]         [,4]         [,5] #>  [1,] -1.057691442 -0.91808629 -0.55160423  0.610842224 -0.698100417 #>  [2,]  0.357620245 -1.68049116  1.06881321 -1.370769779  0.069686124 #>  [3,]  0.890037203 -0.48772481 -0.43628009 -0.011833733 -0.523369440 #>  [4,]  0.367488795  0.10054495 -0.46883245 -1.879590192  1.773509331 #>  [5,]  0.903470844  0.01518964 -1.01787232  0.275282810  1.511007308 #>  [6,] -0.734723223 -0.20970400 -0.17592505  0.157109400  1.492831471 #>  [7,] -0.781116052  0.93552226 -0.86927585 -0.091047843 -0.155438134 #>  [8,]  1.862985380  0.49567079 -1.51989814 -0.114046931 -0.337534718 #>  [9,]  0.013263162 -1.11695934 -0.52389935 -0.698570599 -1.456536784 #> [10,]  0.281817048 -0.67388720  1.89736990 -0.878702955  0.793550654 #> [11,]  0.686835134  1.57085473 -0.29254131  0.728580810 -0.446407041 #> [12,] -1.380630565  1.33881147 -0.21810275  1.262138454  0.267895641 #> [13,]  0.680242709 -1.00119258  0.33987736  0.626444104 -0.854635921 #> [14,] -1.023827340  0.61940247  0.23567420  0.562136815 -0.562949187 #> [15,]  0.327366374 -0.66241169 -0.47769998  0.242896297 -1.401717065 #> [16,]  0.696787597 -1.24730951 -0.67669477  0.547688115  0.599442037 #> [17,] -1.160288793 -0.30275653  0.23404305 -0.820779257  0.145122925 #> [18,] -1.229767452 -0.70020376 -0.41538023 -1.103563807  0.122397952 #> [19,]  0.474747590  1.38332129 -0.48760777 -0.946269867 -1.391471451 #> [20,] -1.323785735  0.91675748 -0.58959085  0.223131196 -0.784508329 #> [21,] -0.676201807 -1.25851405  1.00406597  0.169990426  0.890898543 #> [22,] -0.460363613 -0.94447412  0.42414575  1.881667415 -0.812707658 #> [23,]  0.434584944 -0.95345600  0.95661179 -0.154181134 -1.012236385 #> [24,]  0.405417623  0.60872670 -0.93358184  0.351494234  0.879224262 #> [25,] -2.001768372 -0.35079572 -1.10353782  0.851017736 -0.266591138 #> [26,] -1.280170067  0.92678430  0.33550112 -0.668292099  0.537666143 #> [27,]  1.516627653  0.30311515  0.84157130  0.277435969  0.296238010 #> [28,]  1.135607402 -0.47623800 -1.59321402  0.391019881  0.220533655 #> [29,] -0.440870666  0.46433023  0.91740183 -0.636039962  0.193183592 #> [30,] -1.247587296  0.29220818  0.11366841 -1.202161519  2.289769942 #> [31,]  0.916078015 -0.02717985  1.50759676  2.129121693 -0.836208870 #> [32,] -1.183848404 -0.90484455  0.74296420  0.770462537  0.318822484 #> [33,] -0.989070106 -1.12734452  1.46523276  0.498692439 -0.886269079 #> [34,] -0.190331860  1.32576365 -0.65838798 -0.684686463 -1.611840821 #> [35,]  1.228261591 -0.08676566 -0.39029225  1.926302382  0.611812427 #> [36,] -0.174988461  0.48642193 -0.54331684 -0.245860269 -0.869437742 #> [37,]  1.239570180  1.83021030  0.76095531  0.675720747  1.378750787 #> [38,] -0.757158745  1.19823673  1.29572024  1.101976260  0.105575024 #> [39,] -1.360175735 -0.29942751  0.60772966  0.297233334  0.413033989 #> [40,]  0.300293266 -0.50275288  0.03398259  2.373971715 -0.095899194 #> [41,]  0.006573713  0.85832512  1.29566678 -0.009902972  0.210924212 #> [42,]  1.136032395 -0.64946729 -0.79621361  0.321781315 -0.708769688 #> [43,] -1.277382893  0.74838459  1.76730007  1.264634618  0.378361186 #> [44,] -0.257044762 -1.18309793  1.49031745  1.468151876  0.754713306 #> [45,] -0.728904838  0.55425371 -0.33128462 -1.454648518 -0.801641810 #> [46,]  0.080256632  0.40118632 -0.89821842  0.772430776  2.060234543 #> [47,] -0.325229728 -1.06766514 -1.26738123 -1.152754129  0.904905680 #> [48,]  0.554076117 -0.84408303 -0.20964816 -2.291866502  2.282421843 #> [49,]  1.080774216 -0.29858076  0.74271045  1.105686606  0.375605013 #> [50,] -0.056861121  0.09359631 -0.51801971 -1.459047448 -0.814658016 #> [51,] -0.279208261  0.41720838  0.15320535 -1.691330048  0.173602626 #> [52,]  1.759626388 -2.97885390  0.22323912  0.120850649  0.065137908 #> [53,]  0.394773535 -0.72070512  0.16112904  0.384172457 -1.038943651 #> [54,]  1.262434022  1.40890556  2.95345799 -1.006778607  1.073372699 #> [55,]  1.728167348  0.29567406  1.28125255 -0.678332331 -0.086767542 #> [56,] -1.049401780 -0.37087582 -0.03207555 -0.036923882  0.073087734 #> [57,] -1.732421214 -0.39772207 -0.18644854 -0.175987586 -1.182646765 #> [58,] -0.069369600  0.91188211  1.85696555 -0.602786862  0.008200431 #> [59,] -0.798072356  2.29315088  0.27505974  0.767803540  1.093852798 #> [60,] -0.963395562  1.25625947 -0.25326358  0.726388531 -0.847846273 #> [61,]  0.857347742  1.72203044 -0.19244402 -1.214133464 -0.285753268 #> [62,]  0.592076303 -0.43369238  1.60438784 -0.040617347 -1.392595804 #> [63,]  2.763127339  0.35861686 -1.67385652  1.549183168  0.012390487 #> [64,]  0.316329864 -2.40076859 -0.59864294 -0.908126260  0.891060724 #> [65,]  1.443724603 -0.13607123  0.77493250 -2.457383559 -1.190232065 #> [66,] -0.150032733  0.47310027 -0.21808529 -0.186686954 -1.885677598 #> [67,] -1.544590304 -0.68795362 -1.93035684 -0.964995102  0.279915206 #> [68,]  0.055493347 -0.17231038 -1.99040856  0.107431313 -0.555621730 #> [69,]  1.058644687  1.04942217  0.06166945 -1.279968648 -1.044716723 #> [70,] -0.698346550 -0.10995660 -0.45337446 -0.091039250 -0.189249749 #> [71,]  0.125445344  0.70663095  0.54666527  1.135824787  2.341891020 #> [72,]  0.626145672  2.31376257 -1.46652685  0.015119025 -0.967300589 #> [73,]  0.774673005 -0.49606443  1.62568540 -0.676425152 -1.163117184 #> [74,] -0.647482200 -0.18103806 -0.49706863 -1.341787508  1.567779533 #> [75,]  1.039132154 -0.71939319 -0.70054461  0.331531931 -0.607350233 #> [76,]  1.146190775  0.40486835 -1.68481390  0.899779337  2.104415321 #> [77,] -0.675584944 -0.20884802  0.20090540 -0.115599574 -1.295834004 #> [78,] -0.491354295 -0.27404283 -1.47380425  0.631487818 -0.073999104 #> [79,] -0.767880597  0.88756326 -0.24995837 -0.205270178 -0.627641082 #> [80,] -1.553218484 -1.70298354 -0.23150082  1.014173551  0.201397680 #>               [,6] #>  [1,] -1.681314844 #>  [2,]  0.109460206 #>  [3,] -0.049283265 #>  [4,]  0.956403890 #>  [5,] -0.912163665 #>  [6,]  0.998380013 #>  [7,] -1.229355532 #>  [8,] -1.557511739 #>  [9,]  0.750521868 #> [10,] -1.063991892 #> [11,] -2.346035979 #> [12,]  0.154712531 #> [13,]  0.196730701 #> [14,] -0.345141009 #> [15,]  0.678027059 #> [16,] -1.232518327 #> [17,]  0.726483579 #> [18,] -1.047240491 #> [19,]  1.763679169 #> [20,] -0.304301737 #> [21,] -1.416126622 #> [22,] -0.580693246 #> [23,]  0.001507040 #> [24,]  0.012279593 #> [25,] -0.074475224 #> [26,]  0.085883847 #> [27,]  1.264731457 #> [28,]  1.896551387 #> [29,]  2.610735922 #> [30,]  0.341812336 #> [31,]  0.232973897 #> [32,] -0.982011719 #> [33,]  1.066749867 #> [34,]  0.387558283 #> [35,]  0.589148420 #> [36,]  0.156211021 #> [37,]  0.615708570 #> [38,]  0.742428610 #> [39,] -0.311992069 #> [40,]  0.591370590 #> [41,]  1.198126168 #> [42,] -1.571833317 #> [43,] -0.464900832 #> [44,]  1.433739347 #> [45,]  0.451020219 #> [46,] -1.424222110 #> [47,]  0.003990556 #> [48,]  0.929038368 #> [49,] -1.741459267 #> [50,] -1.726518637 #> [51,]  0.498111929 #> [52,]  0.420789635 #> [53,]  1.810211404 #> [54,] -0.630811701 #> [55,] -0.470750158 #> [56,] -0.258860461 #> [57,] -0.745299913 #> [58,] -0.662867713 #> [59,] -0.913171501 #> [60,] -0.153232027 #> [61,]  0.580034382 #> [62,] -0.199170693 #> [63,]  1.598750718 #> [64,]  0.434040307 #> [65,] -1.331700294 #> [66,] -0.600543032 #> [67,]  0.076276702 #> [68,] -0.910560572 #> [69,] -1.241309067 #> [70,]  0.141554412 #> [71,]  0.259439391 #> [72,]  1.407141048 #> [73,] -0.525751680 #> [74,]  0.367885075 #> [75,] -0.252717073 #> [76,] -1.184086477 #> [77,]  0.900889879 #> [78,]  1.294132109 #> [79,]  0.994859579 #> [80,]  0.413842798 #>  #> $loadings #>              [,1]         [,2]         [,3]         [,4]         [,5] #>  [1,] -0.01249289  0.386519358 -0.175915209  0.142642722  0.165739063 #>  [2,] -0.08586893  0.164198917 -0.023769642  0.076272008 -0.193852504 #>  [3,] -0.10260523  0.237412606  0.180208540 -0.373085059  0.025725292 #>  [4,]  0.45653301  0.408288717  0.058419876 -0.139720696  0.117171972 #>  [5,] -0.01586879  0.437101417 -0.001287363 -0.076797945  0.032346506 #>  [6,] -0.04070823  0.384716552 -0.160137861 -0.153866665  0.397583642 #>  [7,] -0.19460130  0.462467413 -0.340410483  0.290071168 -0.044674480 #>  [8,] -0.31337128  0.315855237 -0.466151309 -0.040245071  0.179564760 #>  [9,] -0.13371278  0.182138648 -0.245009791  0.226855245  0.026193656 #> [10,]  0.26367185  0.215783999 -0.404680857  0.195745760 -0.127182812 #> [11,] -0.28074023 -0.006999664  0.098452186 -0.212323607 -0.285912120 #> [12,] -0.53821212 -0.039843017 -0.060059944 -0.013502608 -0.181012046 #> [13,]  0.08889652  0.371435729  0.212359810  0.474538405  0.489000260 #> [14,] -0.32968201  0.351061571 -0.064737703 -0.345019624 -0.411593679 #> [15,]  0.30702316  0.198430683 -0.318444855 -0.081513237  0.033994796 #> [16,] -0.39331096 -0.001746886 -0.158869321  0.151441819  0.533968694 #> [17,] -0.15641858  0.070113093 -0.115320435  0.442636007  0.325270233 #> [18,] -0.16616164  0.170481037  0.129159710 -0.178645666  0.140155475 #> [19,] -0.23652619 -0.127281388 -0.124007112  0.197311078  0.107308135 #> [20,] -0.04496451 -0.005410546  0.292238510  0.317014940 -0.273826135 #> [21,]  0.11157297  0.277701209 -0.416536105 -0.222882422 -0.186106801 #> [22,] -0.08537752  0.406429076  0.002132278  0.015657479 -0.121877054 #> [23,] -0.46872309  0.313582206 -0.274295434 -0.072532544  0.126515747 #> [24,] -0.17065184  0.204061287  0.042207752  0.005592996 -0.082202931 #> [25,] -0.02075303 -0.137929389  0.590175809  0.353606931  0.155357437 #> [26,] -0.43011292  0.312207974  0.102326925  0.257597329 -0.004220737 #> [27,]  0.07862213  0.349258578  0.042795621  0.057830761  0.169992652 #> [28,] -0.22071839  0.067182562 -0.287824419  0.597240134  0.254610781 #> [29,] -0.04195021  0.478524436 -0.194361581  0.148377975 -0.393275185 #> [30,] -0.15128604  0.269616732  0.376184319  0.043015421  0.442887500 #> [31,] -0.45236869  0.024267457 -0.004607516  0.143564021 -0.378856470 #> [32,] -0.38211577  0.298294981 -0.002957238  0.103558347  0.338344280 #> [33,] -0.26592647  0.057951395 -0.018891916  0.396620616 -0.128082858 #> [34,]  0.05829837 -0.336356180  0.023008033  0.096806630 -0.157164557 #> [35,]  0.08805016  0.245602076 -0.061288127 -0.252731204 -0.023593238 #> [36,]  0.09638370 -0.365308807 -0.125684660  0.326372149  0.146273293 #> [37,]  0.31654542  0.079903927 -0.466427416  0.163652176 -0.435090539 #> [38,]  0.60654920 -0.057598955 -0.268557775  0.282947472 -0.127922817 #> [39,]  0.52771440 -0.255735445 -0.233301956  0.230140286  0.220562573 #>                [,6] #>  [1,]  0.0063391844 #>  [2,]  0.4713274961 #>  [3,] -0.1067750806 #>  [4,] -0.0176036321 #>  [5,] -0.2034229998 #>  [6,]  0.1666499484 #>  [7,] -0.1413171811 #>  [8,] -0.0767435879 #>  [9,]  0.0713624095 #> [10,] -0.1371957208 #> [11,]  0.0484540957 #> [12,]  0.3405858497 #> [13,] -0.0002831229 #> [14,]  0.0347285682 #> [15,] -0.2456681739 #> [16,] -0.1654983983 #> [17,]  0.1808495161 #> [18,] -0.1980570947 #> [19,] -0.3979934874 #> [20,]  0.3518217167 #> [21,]  0.0680205301 #> [22,] -0.3199329580 #> [23,] -0.1136524098 #> [24,]  0.0181112939 #> [25,] -0.0056750183 #> [26,]  0.0317675772 #> [27,]  0.0512538586 #> [28,] -0.3932803385 #> [29,]  0.1895734610 #> [30,]  0.0640666274 #> [31,]  0.4472456095 #> [32,] -0.3710595650 #> [33,]  0.1595623171 #> [34,] -0.3785580886 #> [35,]  0.3962147564 #> [36,]  0.3631479241 #> [37,]  0.0687554183 #> [38,] -0.0057914182 #> [39,] -0.1452723891 #>  #> $weights #>               [,1]         [,2]         [,3]         [,4]          [,5] #>  [1,]  0.052215879  0.240419308 -0.161908752  0.024740216  0.2111604497 #>  [2,] -0.034827909  0.084474856 -0.173922160  0.067864937  0.1175210182 #>  [3,] -0.001391453  0.141335334  0.154065251 -0.224649019 -0.0089002370 #>  [4,]  0.269622725  0.313179816 -0.037979386 -0.054736782  0.0012735403 #>  [5,]  0.027378727  0.211060958  0.007106119  0.071613945  0.1542108542 #>  [6,] -0.002555356  0.099603511 -0.178109475 -0.187903009  0.2954068622 #>  [7,] -0.116609767  0.181948312 -0.091708642  0.187746575 -0.1348122575 #>  [8,] -0.199633821 -0.070587422 -0.459236466 -0.003164958  0.1282159006 #>  [9,] -0.149144225 -0.050383249 -0.146224130  0.187872439 -0.0326676473 #> [10,]  0.101522309  0.137118268 -0.246453561  0.093856356 -0.0142865523 #> [11,] -0.189760666  0.026011039  0.053665156 -0.137372414 -0.2331523845 #> [12,] -0.276556703  0.065526328 -0.067606740  0.057921765 -0.1478701776 #> [13,]  0.218056618  0.280310383  0.065577276  0.231986307  0.2279127641 #> [14,] -0.151591107  0.117880080 -0.112208565 -0.242467908 -0.2201492887 #> [15,]  0.195864430  0.189164526 -0.185165309 -0.026577860 -0.1077735435 #> [16,] -0.257267985 -0.042343842 -0.073419847  0.045830324  0.2249531996 #> [17,] -0.148346511  0.020431183 -0.143372621  0.046835578  0.3366421512 #> [18,] -0.084111601  0.053355845  0.094413706 -0.227346273  0.0567815343 #> [19,] -0.195725609 -0.010192432 -0.019555057  0.118765157 -0.0686796085 #> [20,]  0.007935439 -0.035123813  0.176232317  0.217041233  0.0173703772 #> [21,]  0.056749548  0.140405020 -0.181444012 -0.108024779 -0.0780527249 #> [22,]  0.013721499  0.193867288 -0.050439336  0.072322950 -0.1762406678 #> [23,] -0.216454579  0.067135799 -0.177081772  0.015522853  0.0345302368 #> [24,] -0.097751534  0.079034635  0.023245750  0.146139763 -0.0076540950 #> [25,]  0.002239107  0.009120856  0.440139152  0.164461637  0.1230349122 #> [26,] -0.081356991  0.257305767  0.140494374  0.136831602 -0.0555499048 #> [27,]  0.173124225  0.196695428 -0.028694998  0.030037514  0.0267072869 #> [28,] -0.073427432  0.078668734 -0.047100811  0.352253902  0.0570259242 #> [29,]  0.050438770  0.209972241 -0.155411864  0.068260790 -0.1590282865 #> [30,]  0.009624597  0.136710186  0.155944665 -0.024523385  0.4211525788 #> [31,] -0.294404574  0.115712071  0.054534578  0.193810422 -0.1746227806 #> [32,] -0.155982776  0.100292492  0.041414692 -0.030958106  0.1892936819 #> [33,] -0.069622279  0.136210412 -0.001628406  0.296639360 -0.0556256063 #> [34,]  0.015047130 -0.126879646  0.095115710  0.077653748 -0.0529430847 #> [35,]  0.210646938  0.090614166 -0.054018010 -0.267620344 -0.0007203354 #> [36,]  0.050204885 -0.235970969 -0.029264420  0.205742962  0.1602293133 #> [37,]  0.187580708  0.035035882 -0.127899924  0.140120255 -0.2123884365 #> [38,]  0.382605577 -0.160444754 -0.059080333  0.284081768 -0.1337327840 #> [39,]  0.180538911 -0.415369848 -0.300875022  0.086247873  0.1001053218 #>               [,6] #>  [1,]  0.029665386 #>  [2,]  0.430577447 #>  [3,] -0.162026460 #>  [4,] -0.047873822 #>  [5,]  0.031603106 #>  [6,]  0.005719541 #>  [7,] -0.234496364 #>  [8,] -0.060561520 #>  [9,]  0.038825188 #> [10,] -0.036902990 #> [11,] -0.006304792 #> [12,]  0.164474372 #> [13,]  0.029147353 #> [14,]  0.052668936 #> [15,] -0.236984837 #> [16,] -0.219672387 #> [17,]  0.131679559 #> [18,] -0.122756935 #> [19,] -0.245419135 #> [20,]  0.217703853 #> [21,]  0.117210298 #> [22,] -0.095201600 #> [23,] -0.127892607 #> [24,] -0.072265151 #> [25,]  0.041220612 #> [26,] -0.102400260 #> [27,] -0.071365384 #> [28,] -0.239776939 #> [29,]  0.144274171 #> [30,] -0.019200216 #> [31,]  0.317604921 #> [32,] -0.173622871 #> [33,]  0.124328637 #> [34,] -0.213372600 #> [35,]  0.227915458 #> [36,]  0.187689566 #> [37,]  0.070876063 #> [38,] -0.120492759 #> [39,] -0.091659035 #>  #> $center #>  [1]  0.52500  0.45000  0.47500  0.60000  0.53750  0.47500  0.52500  0.47500 #>  [9]  0.37500  0.50000  0.46250  0.51250  0.46250  0.40000  0.43750  0.48750 #> [17]  0.45000  0.51250  0.51250  0.51250  0.45000  0.55000  0.42500  0.42500 #> [25]  0.47500  0.46250  0.52500  0.51250  0.48750  0.40000  0.57500  0.48750 #> [33]  0.41250  0.70000 64.23634  1.77500  2.51250  0.55000  0.25000 #>  #> $scale #>  [1]  0.5025253  0.5006325  0.5025253  0.4929888  0.5017375  0.5025253 #>  [7]  0.5025253  0.5025253  0.4871774  0.5031546  0.5017375  0.5029973 #> [13]  0.5017375  0.4929888  0.4992082  0.5029973  0.5006325  0.5029973 #> [19]  0.5029973  0.5029973  0.5006325  0.5006325  0.4974619  0.4974619 #> [25]  0.5025253  0.5017375  0.5025253  0.5029973  0.5029973  0.4929888 #> [31]  0.4974619  0.5029973  0.4953901  0.4611488 13.5030422  0.7458747 #> [37]  0.8999824  0.7778581  0.4357447 #>  #> $cox_fit #> $cox_fit$coefficients #> [1]  7.905889  3.923515  3.692730  4.283208 -2.900388 -2.360674 #>  #> $cox_fit$var #>           [,1]       [,2]      [,3]       [,4]       [,5]       [,6] #> [1,]  4.536974  2.2590963  2.119616  2.5037040 -1.7136872 -1.3754037 #> [2,]  2.259096  1.2656583  1.075768  1.2911052 -0.8711192 -0.7019801 #> [3,]  2.119616  1.0757684  1.094191  1.2342944 -0.8522000 -0.6511180 #> [4,]  2.503704  1.2911052  1.234294  1.5352526 -1.0382724 -0.8329159 #> [5,] -1.713687 -0.8711192 -0.852200 -1.0382724  0.8292542  0.5642397 #> [6,] -1.375404 -0.7019801 -0.651118 -0.8329159  0.5642397  0.5430090 #>  #> $cox_fit$loglik #> [1] -56.43995 -13.11777 #>  #> $cox_fit$score #> [1] 47.66948 #>  #> $cox_fit$iter #> [1] 8 #>  #> $cox_fit$linear.predictors #>  [1]  -5.39087955  -6.15109660   5.09550487 -13.88375547   2.39351618 #>  [6] -13.29476930  -2.75192032  15.22802654  -6.75150764   3.03694859 #> [11]  20.46668210  -2.20388522   7.40235358   0.06153643   1.73042067 #> [16]   1.63285788 -15.14819858 -16.61315366   3.19944499  -5.09653794 #> [21]  -5.08886457   6.00858147   5.49932139   1.07251252 -16.68306316 #> [26]  -9.87033333  13.63075463  -2.21580410  -7.72364593 -20.89429368 #> [31]  23.69774455  -5.47242729  -4.64364378   2.09307288  13.01430218 #> [36]  -0.38140506  17.23261789   6.16118530  -8.87236032   9.57734124 #> [41]   4.72160666  10.63749894   4.78039144  -0.45588309  -9.78156407 #> [46]  -0.41319153 -19.01181143 -18.33508937  17.87312742  -1.80604943 #> [51]  -8.92843325   2.38355006   1.27385539  20.47855089  18.01160999 #> [56]  -9.62908763 -11.50954928   8.84579672   5.97522735   2.30930801 #> [61]   7.08300227  13.23913535  19.89632332 -16.62795366   9.81202643 #> [66]   5.95200818 -27.16404514  -3.36617391  13.19271845  -7.80186252 #> [71]   3.24305062   8.16133664  11.89873024 -18.82754928   6.58394537 #> [76]   4.97416410  -4.28205147 -10.53776977  -4.91879100 -17.03328838 #>  #> $cox_fit$residuals #>             1             2             3             4             5  #> -2.744308e-02 -1.781275e-09 -1.504830e-08 -1.243296e-15 -1.760046e-01  #>             6             7             8             9            10  #> -5.402201e-15 -2.047726e-10  1.600869e-01 -9.771827e-10 -9.588986e-10  #>            11            12            13            14            15  #>  5.583397e-01 -1.017192e-11 -5.262802e-06 -1.051131e-01 -2.596300e-10  #>            16            17            18            19            20  #> -2.354962e-10 -2.204648e-13 -1.956207e-16  6.059654e-01 -6.046914e-04  #>            21            22            23            24            25  #> -1.855479e-10 -2.322817e-07 -7.847668e-07 -4.696986e-02 -5.617846e-09  #>            26            27            28            29            30  #> -2.377997e-15 -2.501978e-02 -3.282543e-09 -1.419315e-12 -7.767146e-20  #>            31            32            33            34            35  #> -8.044200e-01 -8.592934e-10 -8.042840e-09 -2.514877e-04  1.856192e-01  #>            36            37            38            39            40  #> -1.097466e-02  8.261257e-02 -3.961750e-04 -6.450978e-15  5.523967e-01  #>            41            42            43            44            45  #> -5.169046e-09 -8.523020e-03 -1.586027e-07 -1.018698e-02 -2.598743e-15  #>            46            47            48            49            50  #> -3.069642e-03 -5.472771e-10 -3.278640e-16 -1.856164e-01  1.075299e-02  #>            51            52            53            54            55  #> -1.014002e-08 -7.175306e-02 -4.758185e-09 -4.216039e-02  9.969438e-01  #>            56            57            58            59            60  #> -5.498683e-11 -9.917412e-07 -3.195386e-07 -8.049978e-05 -1.617904e-01  #>            61            62            63            64            65  #> -6.801896e-07  5.303204e-01 -4.037155e-01 -1.927468e-16 -3.961013e-01  #>            66            67            68            69            70  #> -1.769160e-08 -4.800948e-20 -7.061154e-09 -9.098569e-01 -6.572449e-06  #>            71            72            73            74            75  #> -4.115968e-01 -2.056243e-01 -4.426646e-03 -1.361713e-15 -2.321597e-06  #>            76            77            78            79            80  #>  3.289011e-01 -2.220045e-04 -7.980437e-13 -6.108218e-09 -1.205199e-15  #>  #> $cox_fit$means #> [1]  0.000000e+00 -1.110223e-17  4.163336e-17 -5.551115e-18  1.804112e-17 #> [6] -1.110223e-17 #>  #> $cox_fit$method #> [1] \"efron\" #>  #> $cox_fit$class #> [1] \"coxph\" #>  #>  #> $keepX #> [1] 0 0 0 0 0 0 #>  #> $time #>  [1] 6.1342466 2.0383562 0.8328767 1.1205479 3.9917808 1.4164384 1.3205479 #>  [8] 1.6712329 2.0547945 0.4520548 0.9150685 0.8794521 1.2356164 5.6712329 #> [15] 0.5013699 0.7506849 2.0164384 1.2794521 3.5452055 4.8493151 1.5890411 #> [22] 0.9150685 1.3287671 4.1123288 4.7589041 0.5945205 1.5780822 1.5780822 #> [29] 1.3506849 0.8602740 0.7753425 1.8109589 2.3452055 2.5178082 2.4356164 #> [36] 4.2246575 1.4246575 2.1972603 0.6054795 2.5013699 0.7150685 1.7260274 #> [43] 1.1315068 3.9013699 0.6164384 3.4191781 5.4219178 1.6054795 1.2849315 #> [50] 5.9260274 2.7726027 4.7041096 1.0849315 1.0246575 0.1835616 2.0958904 #> [57] 5.3369863 0.6410959 1.7726027 4.6821918 0.9260274 1.9397260 1.1890411 #> [64] 1.3260274 2.6575342 0.7561644 1.5972603 1.9150685 2.4493151 4.3726027 #> [71] 3.6876712 2.9753425 1.6000000 1.8410959 1.1890411 3.3397260 3.6958904 #> [78] 1.4712329 2.2712329 1.6630137 #>  #> $status #>  [1] 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 #> [39] 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 #> [77] 0 0 0 0 #>  #> attr(,\"class\") #> [1] \"big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Overview of bigPLScox","text":"vignette(\"getting-started\", package = \"bigPLScox\") detailed walkthrough data preparation model diagnostics. vignette(\"bigPLScox-benchmarking\", package = \"bigPLScox\") reproducible performance comparisons. package website https://fbertran.github.io/bigPLScox/ hosts reference documentation additional examples.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fast big-memory workflows with bigPLScox","text":"Large survival datasets often outgrow capabilities purely -memory algorithms. bigPLScox therefore offers three flavours Partial Least Squares (PLS) components Cox models: big_pls_cox() – original R/C++ hybrid expects dense matrices; big_pls_cox_fast() – new Armadillo backend variance-one components support dense matrices bigmemory::big.matrix objects; big_pls_cox_gd() – stochastic gradient descent (SGD) solver streaming disk-backed data. allowing datasets large fit RAM. vignette demonstrates build file-backed matrices, run fast backends, reconcile outputs. complements introductory vignette vignette(\"getting-started\", package = \"bigPLScox\") focuses workflow patterns specific large datasets.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"simulating-a-large-survival-dataset","dir":"Articles","previous_headings":"","what":"Simulating a large survival dataset","title":"Fast big-memory workflows with bigPLScox","text":"generate synthetic dataset correlated predictors known linear predictor. object used illustrate dense big-memory interfaces.","code":"library(bigPLScox) set.seed(2024)  n_obs  <- 5000 n_pred <- 100 k_true <- 3  Sigma <- diag(n_pred) for (b in 0:2) {   idx <- (b * 10 + 1):(b * 10 + 10)   Sigma[idx, idx] <- 0.7   diag(Sigma[idx, idx]) <- 1 }  L <- chol(Sigma) Z <- matrix(rnorm(n_obs * n_pred), nrow = n_obs) X_dense <- Z %*% L  w1 <- numeric(n_pred); w1[1:4]   <- c( 1.0,  0.8,  0.6, -0.5) w2 <- numeric(n_pred); w2[5:8]   <- c(-0.7,  0.9, -0.4,  0.5) w3 <- numeric(n_pred); w3[9:12]  <- c( 0.6, -0.5,  0.7,  0.8) w1 <- w1 / sqrt(sum(w1^2)) w2 <- w2 / sqrt(sum(w2^2)) w3 <- w3 / sqrt(sum(w3^2))  t1 <- as.numeric(scale(drop(X_dense %*% w1), center = TRUE, scale = TRUE)) t2 <- as.numeric(scale(drop(X_dense %*% w2), center = TRUE, scale = TRUE)) t3 <- as.numeric(scale(drop(X_dense %*% w3), center = TRUE, scale = TRUE))  beta_true <- c(1.0, 0.6, 0.3) eta       <- beta_true[1]*t1 + beta_true[2]*t2 + beta_true[3]*t3  lambda0 <- 0.05 u <- runif(n_obs) time_event <- -log(u) / (lambda0 * exp(eta))  target_event <- 0.65  f <- function(lc) {   mean(time_event <= rexp(n_obs, rate = lc)) - target_event } lambda_c <- uniroot(f, c(1e-4, 1), tol = 1e-4)$root time_cens <- rexp(n_obs, rate = lambda_c)  time   <- pmin(time_event, time_cens) status <- as.integer(time_event <= time_cens) if (requireNamespace(\"bigmemory\", quietly = TRUE)) {   library(bigmemory)   big_dir <- tempfile(\"bigPLScox-\")   dir.create(big_dir)   if(file.exists(paste(big_dir,\"X.bin\",sep=\"/\"))){unlink(paste(big_dir,\"X.bin\",sep=\"/\"))}   if(file.exists(paste(big_dir,\"X.desc\",sep=\"/\"))){unlink(paste(big_dir,\"X.desc\",sep=\"/\"))}   X_big <- bigmemory::as.big.matrix(     X_dense,     backingpath = big_dir,     backingfile = \"X.bin\",     descriptorfile = \"X.desc\"   )   X_big[1:6, 1:6] } #>            [,1]       [,2]       [,3]       [,4]       [,5]       [,6] #> [1,]  0.9819694  1.1785102  0.8893563  0.4103456  0.8595229  1.2643346 #> [2,]  0.4687150  0.3552132  0.1072107  0.7865815  0.6736797  0.9825877 #> [3,] -0.1079713 -0.9804778 -1.7053786 -0.3227459 -0.6558693  0.4394022 #> [4,] -0.2128782  0.1114703 -0.8085431 -0.7675984 -0.3685458 -0.7628635 #> [5,]  1.1580985  1.0561296  1.1652026  1.5047814  0.3721924  1.1937471 #> [6,]  1.2923548  1.2431242  1.1954762  1.7104007  1.7505597  0.3548417"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"dense-matrix-solvers","dir":"Articles","previous_headings":"","what":"Dense-matrix solvers","title":"Fast big-memory workflows with bigPLScox","text":"legacy solver big_pls_cox() performs component extraction R fitting Cox model. new big_pls_cox_fast() backend exposes arguments runs entirely C++ substantial speed-. summary() method reports key diagnostics, including final Cox coefficients number predictors retained per component.","code":"fit_legacy <- big_pls_cox(   X = X_dense,   time = time,   status = status,   ncomp = k_true ) fit_fast_dense <- big_pls_cox_fast(   X = X_dense,   time = time,   status = status,   ncomp = k_true )  list(   legacy = head(fit_legacy$scores),   fast = head(fit_fast_dense$scores) ) #> $legacy #>            [,1]         [,2]       [,3] #> [1,]  0.9629914 -0.167053846  0.7375230 #> [2,]  0.2108181 -0.770048070 -0.7462166 #> [3,] -0.6636008  0.469979735 -0.5996875 #> [4,] -0.4659735  0.004452889 -0.5171283 #> [5,]  1.1370381 -1.060165048  0.4919368 #> [6,]  1.1498123  0.643174881 -2.0723580 #>  #> $fast #>            [,1]        [,2]        [,3] #> [1,]  0.9687369  0.08567234  0.55026138 #> [2,]  0.2084113 -0.27560071 -0.81298189 #> [3,] -0.6452360  0.17006440 -0.59713551 #> [4,] -0.3704446 -1.74944701 -0.56995206 #> [5,]  1.1710374 -0.97228981 -0.09285005 #> [6,]  1.1309082  1.29090796 -1.67416198  list(   legacy = apply(fit_legacy$scores, 2, var),   fast = apply(fit_fast_dense$scores, 2, var) ) #> $legacy #> [1] 1 1 1 #>  #> $fast #> [1] 1 1 1 summary(fit_fast_dense) #> $n #> [1] 5000 #>  #> $p #> [1] 100 #>  #> $ncomp #> [1] 3 #>  #> $keepX #> [1] 0 0 0 #>  #> $center #>   [1]  2.798955e-03 -9.107153e-03 -2.635946e-03 -4.943362e-03 -7.487132e-03 #>   [6]  1.688500e-03  1.210463e-02 -3.535210e-03  7.937559e-03 -5.111552e-03 #>  [11]  2.432002e-02  2.761799e-02  1.006852e-02  1.894906e-02  5.913826e-03 #>  [16]  1.760013e-02  2.038917e-02  1.990905e-02  8.037810e-03  1.348481e-02 #>  [21] -8.386266e-04 -1.395535e-02  1.267194e-03  4.733988e-03 -3.000423e-03 #>  [26]  4.522036e-03  1.537932e-02  7.581824e-03  1.149183e-02  8.462248e-05 #>  [31]  5.932423e-03 -1.466198e-02 -1.034713e-02 -1.481074e-02 -2.251482e-02 #>  [36]  1.509019e-02  7.071338e-03  1.671894e-03 -5.115363e-04  7.012307e-03 #>  [41]  1.064288e-02  9.916201e-03 -6.026108e-03  5.773966e-03  4.633769e-03 #>  [46]  2.618328e-02 -1.435784e-02 -5.742304e-03 -1.915827e-02  8.912658e-03 #>  [51]  9.885805e-04 -2.480366e-02 -2.473665e-02  1.140294e-02 -1.765096e-03 #>  [56]  1.098523e-02  1.313620e-02  1.197506e-02  1.582672e-02 -1.068739e-02 #>  [61]  2.012116e-02 -2.190880e-03 -1.949041e-02  1.068698e-02  2.140322e-03 #>  [66] -1.930552e-02 -8.015752e-03  4.882372e-03  9.592623e-03  6.027325e-03 #>  [71]  1.753572e-02 -7.224351e-03  3.237467e-02  2.087540e-02 -1.771835e-02 #>  [76]  1.911843e-02  4.837475e-03 -4.556118e-03 -3.789627e-03 -1.290946e-02 #>  [81] -2.352335e-03 -1.463869e-02 -6.529425e-03 -2.007038e-04 -2.049618e-02 #>  [86]  9.593425e-03 -4.618771e-03 -3.091546e-02 -4.459583e-03  1.441065e-02 #>  [91]  1.209319e-02 -1.910077e-02 -2.138175e-03 -8.270438e-03 -6.362283e-04 #>  [96]  1.212042e-02  1.317364e-02  6.920960e-03 -2.154896e-02 -7.828461e-03 #>  #> $scale #>   [1] 0.9910953 0.9879135 0.9801627 0.9805454 0.9825838 0.9796072 0.9916807 #>   [8] 0.9639126 0.9752288 0.9795114 1.0061235 1.0183937 1.0153322 1.0055659 #>  [15] 0.9999027 0.9982914 1.0180898 0.9965759 0.9989057 0.9980811 0.9831231 #>  [22] 0.9932899 0.9880039 0.9783728 0.9910691 0.9997550 0.9942396 0.9809138 #>  [29] 0.9849191 0.9897065 0.9945993 1.0059848 1.0222768 1.0053630 0.9941951 #>  [36] 1.0161263 0.9891056 0.9935245 1.0022409 1.0132022 1.0015934 1.0014491 #>  [43] 0.9971142 0.9969146 1.0076407 1.0089492 0.9954433 1.0043024 1.0001044 #>  [50] 1.0135577 0.9882588 0.9739312 1.0097109 0.9841654 1.0101256 1.0137299 #>  [57] 1.0081388 0.9964486 0.9813350 0.9899351 0.9940586 1.0100280 0.9865722 #>  [64] 1.0140406 1.0073922 0.9988660 0.9999025 0.9958502 0.9915252 1.0199301 #>  [71] 0.9953438 1.0018892 1.0034691 1.0040947 1.0079260 0.9916430 1.0128318 #>  [78] 1.0173742 1.0159493 0.9991616 1.0117705 1.0176843 1.0043697 0.9917577 #>  [85] 1.0073844 0.9954760 0.9968360 0.9983667 0.9877749 0.9831503 1.0071013 #>  [92] 1.0195985 1.0051072 0.9875478 1.0110776 0.9969945 0.9953462 0.9948409 #>  [99] 0.9953168 0.9914863 #>  #> $cox #> Call: #> survival::coxph(formula = survival::Surv(time, status) ~ ., data = scores_df,  #>     ties = \"efron\", x = FALSE) #>  #>   n= 5000, number of events= 3250  #>  #>           coef exp(coef) se(coef)      z Pr(>|z|)     #> comp1  1.01373   2.75587  0.02115  47.94   <2e-16 *** #> comp2 -0.41079   0.66313  0.01792 -22.92   <2e-16 *** #> comp3  0.20389   1.22617  0.01804  11.30   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>       exp(coef) exp(-coef) lower .95 upper .95 #> comp1    2.7559     0.3629    2.6440    2.8725 #> comp2    0.6631     1.5080    0.6402    0.6868 #> comp3    1.2262     0.8155    1.1836    1.2703 #>  #> Concordance= 0.765  (se = 0.004 ) #> Likelihood ratio test= 2757  on 3 df,   p=<2e-16 #> Wald test            = 2669  on 3 df,   p=<2e-16 #> Score (logrank) test = 2680  on 3 df,   p=<2e-16 #>  #>  #> attr(,\"class\") #> [1] \"summary.big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"switching-to-file-backed-matrices","dir":"Articles","previous_headings":"","what":"Switching to file-backed matrices","title":"Fast big-memory workflows with bigPLScox","text":"working big.matrix, function operates shared memory pointer without copying data back R. ideal datasets fit entirely RAM. resulting scores, loadings, centring parameters mirror dense fit, simplifies debugging incremental model building.","code":"if (exists(\"X_big\")) {   fit_fast_big <- big_pls_cox_fast(     X = X_big,     time = time,     status = status,     ncomp = k_true   )   summary(fit_fast_big) } #> $n #> [1] 5000 #>  #> $p #> [1] 100 #>  #> $ncomp #> [1] 3 #>  #> $keepX #> [1] 0 0 0 #>  #> $center #>   [1]  2.798955e-03 -9.107153e-03 -2.635946e-03 -4.943362e-03 -7.487132e-03 #>   [6]  1.688500e-03  1.210463e-02 -3.535210e-03  7.937559e-03 -5.111552e-03 #>  [11]  2.432002e-02  2.761799e-02  1.006852e-02  1.894906e-02  5.913826e-03 #>  [16]  1.760013e-02  2.038917e-02  1.990905e-02  8.037810e-03  1.348481e-02 #>  [21] -8.386266e-04 -1.395535e-02  1.267194e-03  4.733988e-03 -3.000423e-03 #>  [26]  4.522036e-03  1.537932e-02  7.581824e-03  1.149183e-02  8.462248e-05 #>  [31]  5.932423e-03 -1.466198e-02 -1.034713e-02 -1.481074e-02 -2.251482e-02 #>  [36]  1.509019e-02  7.071338e-03  1.671894e-03 -5.115363e-04  7.012307e-03 #>  [41]  1.064288e-02  9.916201e-03 -6.026108e-03  5.773966e-03  4.633769e-03 #>  [46]  2.618328e-02 -1.435784e-02 -5.742304e-03 -1.915827e-02  8.912658e-03 #>  [51]  9.885805e-04 -2.480366e-02 -2.473665e-02  1.140294e-02 -1.765096e-03 #>  [56]  1.098523e-02  1.313620e-02  1.197506e-02  1.582672e-02 -1.068739e-02 #>  [61]  2.012116e-02 -2.190880e-03 -1.949041e-02  1.068698e-02  2.140322e-03 #>  [66] -1.930552e-02 -8.015752e-03  4.882372e-03  9.592623e-03  6.027325e-03 #>  [71]  1.753572e-02 -7.224351e-03  3.237467e-02  2.087540e-02 -1.771835e-02 #>  [76]  1.911843e-02  4.837475e-03 -4.556118e-03 -3.789627e-03 -1.290946e-02 #>  [81] -2.352335e-03 -1.463869e-02 -6.529425e-03 -2.007038e-04 -2.049618e-02 #>  [86]  9.593425e-03 -4.618771e-03 -3.091546e-02 -4.459583e-03  1.441065e-02 #>  [91]  1.209319e-02 -1.910077e-02 -2.138175e-03 -8.270438e-03 -6.362283e-04 #>  [96]  1.212042e-02  1.317364e-02  6.920960e-03 -2.154896e-02 -7.828461e-03 #>  #> $scale #>   [1] 0.9910953 0.9879135 0.9801627 0.9805454 0.9825838 0.9796072 0.9916807 #>   [8] 0.9639126 0.9752288 0.9795114 1.0061235 1.0183937 1.0153322 1.0055659 #>  [15] 0.9999027 0.9982914 1.0180898 0.9965759 0.9989057 0.9980811 0.9831231 #>  [22] 0.9932899 0.9880039 0.9783728 0.9910691 0.9997550 0.9942396 0.9809138 #>  [29] 0.9849191 0.9897065 0.9945993 1.0059848 1.0222768 1.0053630 0.9941951 #>  [36] 1.0161263 0.9891056 0.9935245 1.0022409 1.0132022 1.0015934 1.0014491 #>  [43] 0.9971142 0.9969146 1.0076407 1.0089492 0.9954433 1.0043024 1.0001044 #>  [50] 1.0135577 0.9882588 0.9739312 1.0097109 0.9841654 1.0101256 1.0137299 #>  [57] 1.0081388 0.9964486 0.9813350 0.9899351 0.9940586 1.0100280 0.9865722 #>  [64] 1.0140406 1.0073922 0.9988660 0.9999025 0.9958502 0.9915252 1.0199301 #>  [71] 0.9953438 1.0018892 1.0034691 1.0040947 1.0079260 0.9916430 1.0128318 #>  [78] 1.0173742 1.0159493 0.9991616 1.0117705 1.0176843 1.0043697 0.9917577 #>  [85] 1.0073844 0.9954760 0.9968360 0.9983667 0.9877749 0.9831503 1.0071013 #>  [92] 1.0195985 1.0051072 0.9875478 1.0110776 0.9969945 0.9953462 0.9948409 #>  [99] 0.9953168 0.9914863 #>  #> $cox #> Call: #> survival::coxph(formula = survival::Surv(time, status) ~ ., data = scores_df,  #>     ties = \"efron\", x = FALSE) #>  #>   n= 5000, number of events= 3250  #>  #>           coef exp(coef) se(coef)      z Pr(>|z|)     #> comp1  1.01373   2.75587  0.02115  47.94   <2e-16 *** #> comp2 -0.41079   0.66313  0.01792 -22.92   <2e-16 *** #> comp3  0.20389   1.22617  0.01804  11.30   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>       exp(coef) exp(-coef) lower .95 upper .95 #> comp1    2.7559     0.3629    2.6440    2.8725 #> comp2    0.6631     1.5080    0.6402    0.6868 #> comp3    1.2262     0.8155    1.1836    1.2703 #>  #> Concordance= 0.765  (se = 0.004 ) #> Likelihood ratio test= 2757  on 3 df,   p=<2e-16 #> Wald test            = 2669  on 3 df,   p=<2e-16 #> Score (logrank) test = 2680  on 3 df,   p=<2e-16 #>  #>  #> attr(,\"class\") #> [1] \"summary.big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"gradient-descent-for-streaming-data","dir":"Articles","previous_headings":"","what":"Gradient descent for streaming data","title":"Fast big-memory workflows with bigPLScox","text":"SGD solver trades small amount accuracy drastically reduced memory usage. Provide big.matrix object along desired number components.","code":"if (exists(\"X_big\")) {   fit_gd <- big_pls_cox_gd(     X = X_big,     time = time,     status = status,     ncomp = k_true,     max_iter = 2000,     learning_rate = 0.05,     tol = 1e-8   )   str(fit_gd) } #> List of 18 #>  $ coefficients  : num [1:3] NaN NaN NaN #>  $ loglik        : num NaN #>  $ iterations    : int 2000 #>  $ converged     : logi TRUE #>  $ scores        : num [1:5000, 1:3] 2.572 0.551 -1.708 -0.979 3.117 ... #>  $ loadings      : num [1:100, 1:3] 0.31 0.312 0.309 0.306 0.309 ... #>  $ weights       : num [1:100, 1:3] 0.337 0.336 0.327 0.252 0.225 ... #>  $ center        : num [1:100] 0.0028 -0.00911 -0.00264 -0.00494 -0.00749 ... #>  $ scale         : num [1:100] 0.991 0.988 0.98 0.981 0.983 ... #>  $ keepX         : int [1:3] 0 0 0 #>  $ time          : num [1:5000] 0.406 21.13 32.775 11.871 1.618 ... #>  $ status        : num [1:5000] 1 1 1 1 1 1 1 1 1 0 ... #>  $ loglik_trace  : num -Inf #>  $ gradnorm_trace: num 1974 #>  $ step_trace    : num 0.05 #>  $ coef_trace    :List of 1 #>   ..$ : num [1:3] -95.3 -12.9 22.4 #>  $ eta_trace     :List of 1 #>   ..$ : num [1:5000] 442 263 562 507 264 ... #>  $ cox_fit       :List of 19 #>   ..$ coefficients     : Named num [1:3] 0.41 0.401 -0.256 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ var              : num [1:3, 1:3] 6.81e-05 2.49e-05 -1.28e-05 2.49e-05 3.26e-04 ... #>   ..$ loglik           : num [1:2] -25089 -23511 #>   ..$ score            : num 3010 #>   ..$ iter             : int 4 #>   ..$ linear.predictors: num [1:5000] 1.357 0.395 -1.168 -0.73 1.939 ... #>   ..$ residuals        : Named num [1:5000] 0.904 -0.542 0.508 0.705 0.385 ... #>   .. ..- attr(*, \"names\")= chr [1:5000] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : Named num [1:3] 4.86e-16 9.02e-18 5.17e-18 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ method           : chr \"efron\" #>   ..$ n                : int 5000 #>   ..$ nevent           : num 3250 #>   ..$ terms            :Classes 'terms', 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \"variables\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1 #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   .. .. .. .. ..$ : chr \"fit$scores\" #>   .. .. ..- attr(*, \"term.labels\")= chr \"fit$scores\" #>   .. .. ..- attr(*, \"specials\")=Dotted pair list of 5 #>   .. .. .. ..$ strata : NULL #>   .. .. .. ..$ tt     : NULL #>   .. .. .. ..$ frailty: NULL #>   .. .. .. ..$ ridge  : NULL #>   .. .. .. ..$ pspline: NULL #>   .. .. ..- attr(*, \"order\")= int 1 #>   .. .. ..- attr(*, \"intercept\")= num 1 #>   .. .. ..- attr(*, \"response\")= int 1 #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x12fd64cf8>  #>   .. .. ..- attr(*, \"predvars\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"nmatrix.2\" \"nmatrix.3\" #>   .. .. .. ..- attr(*, \"names\")= chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   ..$ assign           :List of 1 #>   .. ..$ fit$scores: int [1:3] 1 2 3 #>   ..$ wald.test        : num 2953 #>   ..$ concordance      : Named num [1:7] 7091764 2032858 0 0 0 ... #>   .. ..- attr(*, \"names\")= chr [1:7] \"concordant\" \"discordant\" \"tied.x\" \"tied.y\" ... #>   ..$ y                : 'Surv' num [1:5000, 1:2] 4.06e-01  2.11e+01  3.28e+01  1.19e+01  1.62e+00  1.58e+01  3.13e+00  1.41e+01  2.57e+01  1.04e+01+ ... #>   .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. ..$ : chr [1:5000] \"1\" \"2\" \"3\" \"4\" ... #>   .. .. ..$ : chr [1:2] \"time\" \"status\" #>   .. ..- attr(*, \"type\")= chr \"right\" #>   ..$ timefix          : logi TRUE #>   ..$ formula          :Class 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x12fd64cf8>  #>   ..$ call             : language survival::coxph(formula = survival::Surv(time, status) ~ fit$scores, ties = \"efron\",      x = FALSE) #>   ..- attr(*, \"class\")= chr \"coxph\" #>  - attr(*, \"class\")= chr \"big_pls_cox_gd\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"comparing-the-latent-subspaces","dir":"Articles","previous_headings":"","what":"Comparing the latent subspaces","title":"Fast big-memory workflows with bigPLScox","text":"Component bases unique orthogonal rotations. Comparing linear predictors generated solver verifies span subspace.","code":"if (exists(\"fit_fast_dense\") && exists(\"fit_gd\")) {   eta_fast_dense <- drop(fit_fast_dense$scores %*% fit_fast_dense$cox_fit$coefficients)   eta_fast_big <- drop(fit_fast_big$scores %*% fit_fast_big$cox_fit$coefficients)   eta_gd <- drop(fit_gd$scores %*% fit_gd$cox_fit$coefficients)    list(     correlation_fast_dense_big = cor(eta_fast_dense, eta_fast_big),     correlation_fast_dense_gd = cor(eta_fast_dense, eta_gd),     concordance = c(       fast_dense = survival::concordance(survival::Surv(time, status) ~ eta_fast_dense)$concordance,       fast_big = survival::concordance(survival::Surv(time, status) ~ eta_fast_big)$concordance,       gd = survival::concordance(survival::Surv(time, status) ~ eta_gd)$concordance     )   ) } #> $correlation_fast_dense_big #> [1] 1 #>  #> $correlation_fast_dense_gd #> [1] 0.9513594 #>  #> $concordance #> fast_dense   fast_big         gd  #>  0.2353796  0.2353796  0.2227882"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"predictions-on-new-data","dir":"Articles","previous_headings":"","what":"Predictions on new data","title":"Fast big-memory workflows with bigPLScox","text":"Use predict() type = \"components\" obtain latent scores new observations. Supplying explicit centring scaling parameters ensures consistent projections across solvers.","code":"X_new <- matrix(rnorm(10 * n_pred), nrow = 10)  scores_new <- predict(   fit_fast_dense,   newdata = X_new,   type = \"components\" )  risk_new <- predict(   fit_fast_dense,   newdata = X_new,   type = \"risk\" )  list(scores = scores_new, risk = risk_new) #> $scores #>             [,1]       [,2]       [,3] #>  [1,]  0.9413055 -0.4530476  0.4629985 #>  [2,] -1.8731842 -0.3093188 -1.3624374 #>  [3,]  0.4330174 -0.2484830 -0.8217942 #>  [4,] -0.2370948 -0.3728287  0.7543484 #>  [5,] -0.4305562  1.9710283 -1.7651233 #>  [6,] -1.3884892  0.8314400  1.0017241 #>  [7,]  1.2894199 -0.2111777 -0.2832022 #>  [8,]  0.6056929  1.0050582  0.3722255 #>  [9,]  0.3515327 -0.6484128  0.8089135 #> [10,]  0.3083559 -1.5642579  0.8323470 #>  #> $risk #>  [1] 3.4374924 0.1287814 1.4527807 1.0688777 0.2006806 0.2133421 3.8043108 #>  [8] 1.3192201 2.1982308 3.0798433"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"timing-snapshot","dir":"Articles","previous_headings":"","what":"Timing snapshot","title":"Fast big-memory workflows with bigPLScox","text":"bench package provides lightweight instrumentation comparing solvers. chunk contrasts classical implementation, fast backend, SGD routine simulated dataset.","code":"if (requireNamespace(\"bench\", quietly = TRUE) && exists(\"X_big\")) {   bench_res <- bench::mark(     big_pls = big_pls_cox(X_dense, time, status, ncomp = k_true),     fast_dense = big_pls_cox_fast(X_dense, time, status, ncomp = k_true),     fast_big = big_pls_cox_fast(X_big, time, status, ncomp = k_true),     gd = big_pls_cox_gd(X_big, time, status, ncomp = k_true, max_iter = 1500),     iterations = 30,     check = FALSE   )   bench_res$expression <- names(bench_res$expression)   bench_res[, c(\"expression\", \"median\", \"itr/sec\", \"mem_alloc\")] } #> # A tibble: 4 × 4 #>   expression   median `itr/sec` mem_alloc #>   <chr>      <bch:tm>     <dbl> <bch:byt> #> 1 big_pls     153.8ms      6.52    9.37MB #> 2 fast_dense   21.3ms     47.2    17.02MB #> 3 fast_big     15.1ms     65.9     7.47MB #> 4 gd             41ms     23.9    11.54MB if (exists(\"bench_res\")) {   plot(bench_res, type = \"ridge\") }"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"cleaning-up-backing-files","dir":"Articles","previous_headings":"","what":"Cleaning up backing files","title":"Fast big-memory workflows with bigPLScox","text":"File-backed matrices can deleted analysis complete. production workflows typically keep descriptor (.desc) file alongside binary matrix later reuse.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"cleaning-up","dir":"Articles","previous_headings":"","what":"Cleaning up","title":"Fast big-memory workflows with bigPLScox","text":"Temporary backing files can removed analysis. production pipelines typically keep descriptor file alongside binary data.","code":"if (exists(\"X_big\")) {   rm(X_big)   file.remove(file.path(big_dir, \"X.bin\"))   file.remove(file.path(big_dir, \"X.desc\"))   unlink(big_dir, recursive = TRUE) }"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"further-resources","dir":"Articles","previous_headings":"","what":"Further resources","title":"Fast big-memory workflows with bigPLScox","text":"introductory vignette demonstrates combine fast backend matrix-based modelling functions deviance residual utilities. vignette(\"bigPLScox-benchmarking\", package = \"bigPLScox\") provides reproducible benchmark includes survival::coxph() coxgpls(). help pages (?big_pls_cox_fast, ?big_pls_cox_gd) describe tuning parameters detail, including keepX component-wise sparsity.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"why-bigplscox","dir":"Articles","previous_headings":"","what":"Why bigPLScox?","title":"Getting started with bigPLScox","text":"bigPLScox implements Partial Least Squares (PLS) extensions Cox proportional hazards model remain stable high-dimensional survival settings. package now ships three complementary engines: coxgpls() – classical matrix-based estimator optional sparse grouped variants (e.g. coxsgpls(), coxspls_sgpls()). big_pls_cox_fast() – new Armadillo backend produces variance-one components supports dense matrices bigmemory::big.matrix objects interface. big_pls_cox_gd() – stochastic gradient descent solver streams data disk converges quickly even subset predictors remains active step. Together deviance-residual solvers cross-validation helpers, functions cover common modelling workflows. vignette walks workflows using bundled allelotyping dataset.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"loading-the-example-data","dir":"Articles","previous_headings":"","what":"Loading the example data","title":"Getting started with bigPLScox","text":"original factor-based design matrix also available wish leverage formula interface.","code":"library(bigPLScox)  data(micro.censure) data(Xmicro.censure_compl_imp)  Y_all <- micro.censure$survyear[1:80] status_all <- micro.censure$DC[1:80] X_all <- apply(   as.matrix(Xmicro.censure_compl_imp),   MARGIN = 2,   FUN = as.numeric )[1:80, ]  set.seed(2024) train_id <- 1:60 test_id <- 61:80  X_train <- X_all[train_id, ] X_test <- X_all[test_id, ] Y_train <- Y_all[train_id] Y_test <- Y_all[test_id] status_train <- status_all[train_id] status_test <- status_all[test_id] X_train_raw <- Xmicro.censure_compl_imp[train_id, ] X_test_raw <- Xmicro.censure_compl_imp[test_id, ]"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"inspecting-deviance-residuals","dir":"Articles","previous_headings":"","what":"Inspecting deviance residuals","title":"Getting started with bigPLScox","text":"Deviance residuals can reveal problematic observations components extracted. helper computeDR() exposes R C++ engine; latter substantially faster powers new fast PLS routines.","code":"residuals_overview <- computeDR(Y_train, status_train, plot = TRUE) eta_null <- rep(0, length(Y_train)) head(residuals_overview) #>          1          2          3          4          5          6  #> -1.3771591 -0.5360370 -0.2693493 -0.3994329 -0.8040940 -0.3994329  if (requireNamespace(\"bench\", quietly = TRUE)) {   benchmark_dr <- bench::mark(     survival = computeDR(Y_train, status_train, engine = \"survival\"),     cpp = computeDR(Y_train, status_train, engine = \"cpp\", eta = eta_null),     iterations = 10,     check = FALSE   )   benchmark_dr } #> # A tibble: 2 × 6 #>   expression      min   median `itr/sec` mem_alloc `gc/sec` #>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #> 1 survival    837.6µs    892µs     1052.     169KB        0 #> 2 cpp          89.6µs     95µs     9305.     163KB        0  all.equal(   as.numeric(computeDR(Y_train, status_train, engine = \"survival\")),   as.numeric(computeDR(Y_train, status_train, engine = \"cpp\", eta = eta_null)),   tolerance = 1e-7 ) #> [1] TRUE"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"matrix-based-plscox-models","dir":"Articles","previous_headings":"","what":"Matrix-based PLS–Cox models","title":"Getting started with bigPLScox","text":"matrix interface mimics survival::coxph() augmenting predictor space latent components. users start coxgpls() cross-validation helper cv.coxgpls(). formula interface accepts data frames containing predictors along survival outcomes.","code":"set.seed(123) cox_pls_fit <- coxgpls(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,   ind.block.x = c(3, 10, 20) ) cox_pls_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>          coef exp(coef) se(coef)      z        p #> dim.1 -0.7368    0.4786   0.1162 -6.340  2.3e-10 #> dim.2 -0.5256    0.5912   0.1382 -3.804 0.000142 #> dim.3 -0.3314    0.7179   0.1199 -2.763 0.005720 #> dim.4 -0.2883    0.7495   0.1092 -2.641 0.008272 #> dim.5 -0.4002    0.6702   0.1435 -2.788 0.005298 #> dim.6 -0.2696    0.7636   0.1239 -2.176 0.029529 #>  #> Likelihood ratio test=60.94  on 6 df, p=2.906e-11 #> n= 60, number of events= 60 cox_pls_fit_formula <- coxgpls(   ~ ., Y_train, status_train,   ncomp = 6,   ind.block.x = c(3, 10, 20),   dataXplan = data.frame(X_train_raw) ) cox_pls_fit_formula #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>           coef exp(coef) se(coef)      z       p #> dim.1 -0.82612   0.43775  0.31903 -2.589 0.00961 #> dim.2 -0.79075   0.45350  0.39461 -2.004 0.04508 #> dim.3 -0.89888   0.40703  0.30294 -2.967 0.00301 #> dim.4  0.02354   1.02382  0.29663  0.079 0.93675 #> dim.5 -0.40714   0.66555  0.40456 -1.006 0.31423 #> dim.6 -0.53689   0.58456  0.38554 -1.393 0.16374 #>  #> Likelihood ratio test=19.59  on 6 df, p=0.00328 #> n= 60, number of events= 11"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"cross-validation","dir":"Articles","previous_headings":"Matrix-based PLS–Cox models","what":"Cross-validation","title":"Getting started with bigPLScox","text":"Repeated cross-validation stabilises choice latent components. returned object records optimal number components diagnostic curves.  Use selected number components refit deviance-residual solver robustness check. Sparse structured sparse variants (coxsgpls(), coxspls_sgpls()) share workflow additional arguments control number selected predictors per component (keepX) penalty strength.","code":"set.seed(123456) cv_results <- suppressWarnings(cv.coxgpls(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) )) #> CV Fold 1  #> CV Fold 2  #> CV Fold 3  #> CV Fold 4  #> CV Fold 5 cv_results #> $nt #> [1] 6 #>  #> $cv.error10 #> [1] 0.5000000 0.5492633 0.4897065 0.5589258 0.6112917 0.6294183 0.6482323 #>  #> $cv.se10 #> [1] 0.00000000 0.03211886 0.04830433 0.06137605 0.05429528 0.04481718 0.04814978 #>  #> $folds #> $folds$`1` #>  [1] 60 45  3 57 21 15 35 22 51 12 20 13 #>  #> $folds$`2` #>  [1] 42 54 50 28  1 41  6 18 44  8 27 25 #>  #> $folds$`3` #>  [1] 59 36 55 52 24 46 37 19  4 47 33  5 #>  #> $folds$`4` #>  [1] 49 38 30  2 34 48 53 31 11 56 26 39 #>  #> $folds$`5` #>  [1]  7 10 23 16 14 58 29  9 43 17 40 32 #>  #>  #> $lambda.min10 #> [1] 6 #>  #> $lambda.1se10 #> [1] 0 set.seed(123456) cox_pls_dr <- coxgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = cv_results$nt,   ind.block.x = c(3, 10, 20) ) cox_pls_dr #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7329    2.0812   0.1120 6.545 5.95e-11 #> dim.2 0.6418    1.8999   0.1456 4.409 1.04e-05 #> dim.3 0.3467    1.4144   0.1080 3.210  0.00133 #> dim.4 0.4266    1.5320   0.1554 2.745  0.00605 #> dim.5 0.3694    1.4468   0.1453 2.542  0.01101 #> dim.6 0.2884    1.3343   0.1095 2.633  0.00847 #>  #> Likelihood ratio test=63.84  on 6 df, p=7.442e-12 #> n= 60, number of events= 60"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"fast-solvers-for-medium-sized-data","dir":"Articles","previous_headings":"","what":"Fast solvers for medium-sized data","title":"Getting started with bigPLScox","text":"new big_pls_cox_fast() routine exposes identical arguments dense matrices big.matrix objects. moderate data serves drop-replacement original R implementation big_pls_cox(). Predictions rely predict() interface used classical function. comparison, legacy solver still available. C++ backend usually reduces runtime order magnitude delivering components scaled variance one.","code":"fast_fit_dense <- big_pls_cox_fast(   X = X_train,   time = Y_train,   status = status_train,   ncomp = 4 ) summary(fast_fit_dense) #> $n #> [1] 60 #>  #> $p #> [1] 40 #>  #> $ncomp #> [1] 4 #>  #> $keepX #> [1] 0 0 0 0 #>  #> $center #>  [1]  0.4666667  0.4500000  0.4166667  0.5333333  0.5000000  0.5166667 #>  [7]  0.4833333  0.4000000  0.3833333  0.4500000  0.5166667  0.5166667 #> [13]  0.5500000  0.3666667  0.4333333  0.5333333  0.4833333  0.5166667 #> [19]  0.5500000  0.5166667  0.4333333  0.5666667  0.4000000  0.3833333 #> [25]  0.5166667  0.5166667  0.5666667  0.5333333  0.4666667  0.4500000 #> [31]  0.5500000  0.5500000  0.4500000  0.6333333 62.4622365  1.6833333 #> [37]  2.3833333  0.5166667  0.2500000  2.2666667 #>  #> $scale #>  [1]  0.5030977  0.5016921  0.4971671  0.5030977  0.5042195  0.5039393 #>  [7]  0.5039393  0.4940322  0.4903014  0.5016921  0.5039393  0.5039393 #> [13]  0.5016921  0.4859611  0.4997174  0.5030977  0.5039393  0.5039393 #> [19]  0.5016921  0.5039393  0.4997174  0.4997174  0.4940322  0.4903014 #> [25]  0.5039393  0.5039393  0.4997174  0.5030977  0.5030977  0.5016921 #> [31]  0.5016921  0.5016921  0.5016921  0.4859611 14.6024282  0.7008873 #> [37]  0.9404591  0.7917299  0.4366669  1.2604367 #>  #> $cox #> Call: #> survival::coxph(formula = survival::Surv(time, status) ~ ., data = scores_df,  #>     ties = \"efron\", x = FALSE) #>  #>   n= 60, number of events= 11  #>  #>          coef exp(coef) se(coef)      z Pr(>|z|)    #> comp1 -1.4836    0.2268   0.5002 -2.966  0.00301 ** #> comp2  1.3937    4.0299   0.5081  2.743  0.00609 ** #> comp3 -1.4271    0.2400   0.6997 -2.040  0.04138 *  #> comp4  0.9357    2.5490   0.5119  1.828  0.06755 .  #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>       exp(coef) exp(-coef) lower .95 upper .95 #> comp1    0.2268     4.4088    0.0851    0.6045 #> comp2    4.0299     0.2481    1.4887   10.9090 #> comp3    0.2400     4.1668    0.0609    0.9458 #> comp4    2.5490     0.3923    0.9347    6.9518 #>  #> Concordance= 0.962  (se = 0.015 ) #> Likelihood ratio test= 40.45  on 4 df,   p=3e-08 #> Wald test            = 15.58  on 4 df,   p=0.004 #> Score (logrank) test = 38.25  on 4 df,   p=1e-07 #>  #>  #> attr(,\"class\") #> [1] \"summary.big_pls_cox\" linear_predictor_fast <- predict(fast_fit_dense, newdata = X_test, type = \"link\") head(linear_predictor_fast) #> [1]  3.3499156 -0.8685314  8.6594617 -6.5718861  2.0102711 -2.1990051 legacy_fit_dense <- big_pls_cox(   X = X_train,   time = Y_train,   status = status_train,   ncomp = 4 ) legacy_fit_dense$cox_fit #> $coefficients #> [1]  6.200427  3.171981 -2.748535  1.293296 #>  #> $var #>           [,1]       [,2]       [,3]       [,4] #> [1,]  5.821149  2.4185955 -2.3040552  1.0187707 #> [2,]  2.418596  1.6445800 -1.1764804  0.5610664 #> [3,] -2.304055 -1.1764804  1.2404846 -0.5308908 #> [4,]  1.018771  0.5610664 -0.5308908  0.3210964 #>  #> $loglik #> [1] -33.823093  -6.374114 #>  #> $score #> [1] 34.35164 #>  #> $iter #> [1] 8 #>  #> $linear.predictors #>  [1] -12.57620642  -0.80958795   3.92609801   2.60017390   1.76853806 #>  [6]  -3.36295838  -1.07944356  10.31904141  -3.64756309  -2.89617173 #> [11]  10.99977612  -3.67120048   0.19277160  -4.93349776   0.72346177 #> [16]  -2.96898338 -11.92153226 -16.36665206   7.29677779  -6.25230861 #> [21]  -7.44252580  -3.35748178   0.89833874  -0.03190649 -14.18767386 #> [26]  -5.70848324  10.05566087   2.33425751   1.44427382  -9.42823092 #> [31]  16.81484345  -8.16109725  -1.01887152   1.67809982   9.52923393 #> [36]  -0.81577205  13.21271969   4.03431692  -8.22578371   8.37431879 #> [41]   8.42795290   2.19412589  -1.95037872   2.94403579  -3.81221056 #> [46]  -0.29923400 -13.50366653   1.71522979   6.77552365  -1.04786702 #> [51]  -1.05373010   3.52071260   4.14906575  13.53253117  16.06054363 #> [56]  -9.18209817 -14.09511037   6.91845019   0.66507554   0.70227868 #>  #> $residuals #>             1             2             3             4             5  #> -9.951099e-06 -1.028552e-05 -3.995987e-06 -2.023840e-05 -5.242897e-03  #>             6             7             8             9            10  #> -5.204999e-08 -5.106679e-07  2.996282e-01 -6.021565e-07 -1.784430e-09  #>            11            12            13            14            15  #>  9.535666e-01 -2.005207e-09 -1.822446e-06 -2.171991e-04 -6.660185e-08  #>            16            17            18            19            20  #> -1.659120e-09 -1.535926e-10 -1.172164e-13 -3.196396e-01 -5.809057e-05  #>            21            22            23            24            25  #> -1.824357e-09 -2.701177e-08 -3.690443e-06 -8.662599e-04 -2.078836e-08  #>            26            27            28            29            30  #> -1.071835e-10 -7.252299e-02 -3.214496e-05 -6.370523e-06 -6.337423e-12  #>            31            32            33            34            35  #> -5.817400e-01 -6.599430e-09 -8.343257e-06 -1.307490e-03 -1.851665e-02  #>            36            37            38            39            40  #> -3.955667e-04 -7.043898e-01 -1.305893e-03 -8.647257e-12 -5.820366e-02  #>            41            42            43            44            45  #> -1.477421e-04 -2.073589e-04 -2.137451e-07 -1.698570e-02 -7.139517e-10  #>            46            47            48            49            50  #> -1.810061e-04 -4.119846e-08 -1.730902e-05 -1.316762e-03 -1.056724e-02  #>            51            52            53            54            55  #> -8.511766e-05 -1.970571e-02 -9.524699e-05 -1.325008e-01  6.950025e-01  #>            56            57            58            59            60  #> -2.377340e-09 -2.280448e-08 -3.265394e-05 -4.494326e-05 -1.805098e-03  #>  #> $means #> [1]  3.330669e-17 -4.070818e-17 -4.996004e-17  3.700743e-18 #>  #> $method #> [1] \"efron\" #>  #> $class #> [1] \"coxph\""},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"scaling-up-with-big-memory-matrices","dir":"Articles","previous_headings":"","what":"Scaling up with big-memory matrices","title":"Getting started with bigPLScox","text":"dataset exceeds RAM capacity, convert bigmemory::big.matrix. fast backend natively operates resulting pointer without copying data. big_pls_cox_gd() particularly useful streamed data number active predictors per component restricted via keepX.","code":"if (requireNamespace(\"bigmemory\", quietly = TRUE)) {   library(bigmemory)   X_big_train <- bigmemory::as.big.matrix(X_train)   X_big_test <- bigmemory::as.big.matrix(X_test)    fast_fit_big <- big_pls_cox_fast(     X = X_big_train,     time = Y_train,     status = status_train,     ncomp = 4   )    gd_fit <- big_pls_cox_gd(     X = X_big_train,     time = Y_train,     status = status_train,     ncomp = 4,     max_iter = 2000   )    risk_table <- data.frame(     subject = seq_along(test_id),     fast_dense = predict(fast_fit_dense, newdata = X_test, type = \"link\"),     fast_big = predict(fast_fit_big, newdata = X_big_test, type = \"link\"),     gd = predict(gd_fit, newdata = X_big_test, type = \"link\")   )    apply(     risk_table[-1],     2,     function(lp) {       survival::concordance(survival::Surv(Y_test, status_test) ~ lp)$concordance     }   ) } #> fast_dense   fast_big         gd  #>  0.4418605  0.4418605  0.2790698"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"predictions-and-evaluation","dir":"Articles","previous_headings":"","what":"Predictions and evaluation","title":"Getting started with bigPLScox","text":"solvers return latent scores loadings can reused plotting external validation. Use predict(..., type = \"components\") extract scores directly. concordance index provides quick check predictive ability test set.","code":"if (exists(\"fast_fit_dense\")) {   component_scores <- predict(fast_fit_dense, newdata = X_test, type = \"components\")   head(component_scores) } #>             [,1]        [,2]       [,3]       [,4] #> [1,] -0.61328247  1.45903382 -0.2024545  0.1256753 #> [2,] -0.14585655 -0.89077212 -0.3630109 -0.3863126 #> [3,] -2.49681489  1.07906464 -1.7437503  1.0288135 #> [4,] -0.01412341 -2.48245825  1.7023219 -0.7517977 #> [5,] -0.56984205 -0.10012954 -1.0183793 -0.1591913 #> [6,]  0.49642902 -0.09180402  0.5767821 -0.5465379 if (exists(\"fast_fit_dense\")) {   concordance_fast <- survival::concordance(     survival::Surv(Y_test, status_test) ~ linear_predictor_fast   )$concordance   concordance_fast } #> [1] 0.4418605"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"dk-splines-extension","dir":"Articles","previous_headings":"","what":"DK-splines extension","title":"Getting started with bigPLScox","text":"flexible baseline hazards coxDKgplsDR() estimator augments PLS components DK-splines. interface mirrors previous functions. Cross-validation available DK-splines estimator well.","code":"cox_DKsplsDR_fit <- coxDKgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,   validation = \"CV\",   ind.block.x = c(3, 10, 20),   verbose = FALSE ) cox_DKsplsDR_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>           coef exp(coef) se(coef)     z        p #> dim.1   4.8792  131.5255   0.7348 6.640 3.14e-11 #> dim.2   4.3106   74.4853   0.8523 5.058 4.25e-07 #> dim.3   4.3799   79.8304   1.0374 4.222 2.42e-05 #> dim.4   3.1313   22.9036   0.9043 3.463 0.000535 #> dim.5   1.9561    7.0716   0.7031 2.782 0.005400 #> dim.6   1.9467    7.0054   0.7344 2.651 0.008031 #>  #> Likelihood ratio test=77.54  on 6 df, p=1.151e-14 #> n= 60, number of events= 60 set.seed(2468) cv_coxDKgplsDR_res <- suppressWarnings(cv.coxDKgplsDR(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) )) #> Kernel :  rbfdot  #> Estimated_sigma  0.01258323  #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01471071  #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.0127949  #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.0122611  #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01289496  #> CV Fold 5 cv_coxDKgplsDR_res #> $nt #> [1] 6 #>  #> $cv.error10 #> [1] 0.5000000 0.5658906 0.6356608 0.6374963 0.6100371 0.6307320 0.5694802 #>  #> $cv.se10 #> [1] 0.00000000 0.02591444 0.03982352 0.03646931 0.03407857 0.04124367 0.03676530 #>  #> $folds #> $folds$`1` #>  [1] 44 16 27 26 55 20 49 14  6 47 18  7 #>  #> $folds$`2` #>  [1] 58  8  2 17  3 15 52 43 56 11 29 59 #>  #> $folds$`3` #>  [1] 51 13 57 46 45 32 19  5 36 33 10 28 #>  #> $folds$`4` #>  [1] 21 50 38 60 53 42 23 31 12 24  1 25 #>  #> $folds$`5` #>  [1] 22 39 35 54  4 30 34 48 37 40  9 41 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting started with bigPLScox","text":"vignette(\"bigPLScox\", package = \"bigPLScox\") dives deeper fast big-memory backends shows reconcile dense streaming implementations. vignette(\"bigPLScox-benchmarking\", package = \"bigPLScox\") demonstrates reproducible benchmarking workflow contrasts classical, fast, gradient-descent solvers survival::coxph(). reference documentation (help(\"big_pls_cox_fast\"), etc.) details every argument return value modelling functions discussed .","code":""},{"path":"https://fbertran.github.io/bigPLScox/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer, author. Myriam Maumy-Bertrand. Author.","code":""},{"path":"https://fbertran.github.io/bigPLScox/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frederic Bertrand Myriam Maumy (2025). Partial Least Squares Cox Models Big Matrices, R package version 0.8.0. Maumy, M. Bertrand, F. (2023). PLS models extension big data. Conference presentation Joint Statistical Meetings (JSM 2023), Toronto, Ontario, Canada, Aug 5–10, 2023. Maumy, M. Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. Poster BioC2023: Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA, Aug 2–4, 2023. doi:10.7490/f1000research.1119546.1.","code":"@Manual{,   title = {Partial Least Squares for Cox Models with Big Matrices},   author = {Frederic Bertrand and Myriam Maumy},   publisher = {manual},   year = {2025},   note = {R package version 0.8.0},   url = {https://fbertran.github.io/bigPLScox/}, } @Misc{,   title = {PLS models and their extension for big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at the Joint Statistical Meetings (JSM 2023)},   address = {Toronto, Ontario, Canada},   note = {Aug 5–10, 2023}, } @Misc{,   title = {bigPLS: Fitting and cross-validating PLS-based Cox models to censored big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at BioC2023: The Bioconductor Annual Conference},   address = {Dana-Farber Cancer Institute, Boston, MA, USA},   note = {Aug 2–4, 2023},   doi = {10.7490/f1000research.1119546.1},   url = {https://doi.org/10.7490/f1000research.1119546.1}, }"},{"path":[]},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"frédéric-bertrand-and-myriam-maumy-bertrand","dir":"","previous_headings":"","what":"Frédéric Bertrand and Myriam Maumy-Bertrand","title":"Partial Least Squares for Cox Models with Big Matrices","text":"https://doi.org/10.32614/CRAN.package.bigPLScox bigPLScox provides Partial Least Squares (PLS) methods tailored Cox proportional hazards models large, high-dimensional feature matrices. package works directly bigmemory objects, enabling native C++ accelerators iterative algorithms run without loading full dataset memory. addition classical coxgpls() solver, package contains accelerated variants, cross-validation helpers, model diagnostics. Generalised PLS Cox regression via coxgpls() support grouped predictors. Sparse structured sparse extensions (coxsgpls(), coxspls_sgpls()). Deviance-residual estimators (coxgplsDR(), coxsgplsDR()) robust fits. Cross-validation helpers (cv.coxgpls(), cv.coxsgpls(), …) select number latent components. Dataset generators, diagnostics computeDR() quick residual exploration. High-performance deviance residuals via computeDR(engine = \"cpp\") -memory big-memory workflows. Sparse, group-sparse, stochastic gradient variants able consume file-backed big.matrix objects leveraging foreach parallelism. Interfaces big-memory data big_pls_cox() big_pls_cox_gd(). GPU support available current release; ongoing development focuses improving multi-core CPU back-end instead. Additional articles available vignettes/ directory: Getting started bigPLScox — walkthrough core modelling, cross-validation, diagnostic helpers. Overview bigPLScox — tour main modelling functions practical guidance choosing estimators. Big-memory workflows bigPLScox — guidance using bigmemory matrices parallel back-ends. Benchmarking bigPLScox — reproducible performance comparisons using bench package. Standalone benchmarking scripts complement vignette live inst/benchmarks/. documentation website examples maintained Frédéric Bertrand Myriam Maumy. Conference highlight. Maumy, M. Bertrand, F. (2023). “PLS models extension big data”. Conference presentation Joint Statistical Meetings (JSM 2023), Toronto, Ontario, Canada, Aug 5–10, 2023. Conference highlight. Maumy, M. Bertrand, F. (2023). “bigPLS: Fitting cross-validating PLS-based Cox models censored big data”. Poster BioC2023: Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA, Aug 2–4, 2023. doi:10.7490/f1000research.1119546.1.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"key-features","dir":"","previous_headings":"","what":"Key features","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Scalable Cox-PLS solvers (coxgpls(), coxgplsDR()) operate big matrices stored disk. Cross-validation tooling select optimal number PLS components time-dependent performance metrics. Model diagnostics deviance residual visualisation computeDR(). Benchmark scripts inst/benchmarks/ quantify runtime trade-offs available solvers. Comprehensive vignette (vignettes/bigPLScox.Rmd) showing complete modelling workflow.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partial Least Squares for Cox Models with Big Matrices","text":"can install released version bigPLScox CRAN : can install development version bigPLScox GitHub :","code":"install.packages(\"bigPLScox\") # install.packages(\"devtools\") devtools::install_github(\"fbertran/bigPLScox\")"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"learning-materials","dir":"","previous_headings":"","what":"Learning materials","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Browse Getting started vignette vignette(\"getting-started\",   package = \"bigPLScox\") worked example. Explore vignette(\"bigPLScox\", package = \"bigPLScox\") big-memory workflows streaming solvers. Consult function reference https://fbertran.github.io/bigPLScox/. Run benchmarking scripts inst/benchmarks/ compare solver performance simulated data.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"release-highlights","dir":"","previous_headings":"","what":"Release highlights","title":"Partial Least Squares for Cox Models with Big Matrices","text":"full changelog lives NEWS.md. Recent releases include: 0.6.0 — C++ deviance residuals benchmarking helpers, prediction wrappers big_pls_cox()/big_pls_cox_gd(), new component selection utilities. 0.5.0 — pkgdown documentation refresh, reproducible benchmarking scripts, expanded vignettes covering large-scale workflows.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Partial Least Squares for Cox Models with Big Matrices","text":"following example demonstrates typical workflow subset allelotyping dataset bundled package. Chunks evaluated default README rendered locally, can toggled knitr::opts_chunk$set(eval = FALSE) faster builds. Fit Cox-PLS model six components inspect fit summary: Visualise deviance residuals assess baseline model fit verify agreement R C++ engines: plot chunk unnamed-chunk-5 Cross-validate number components re-fit using deviance residual solver comparison: Explore alternative estimators coxgplsDR() deviance-residual fitting coxsgpls() sparse component selection. Refer package reference full list available models helper functions.","code":"library(bigPLScox) data(micro.censure) data(Xmicro.censure_compl_imp) Y_train <- micro.censure$survyear[1:80] status_train <- micro.censure$DC[1:80] X_train <- Xmicro.censure_compl_imp[1:80, ] set.seed(123) cox_pls_fit <- coxgpls(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cox_pls_fit #> Error: object 'cox_pls_fit' not found residuals_overview <- computeDR(Y_train, status_train, plot = TRUE) head(residuals_overview) #>          1          2          3          4          5          6  #> -1.4843296 -0.5469540 -0.2314550 -0.3400301 -0.9763372 -0.3866766  cpp_residuals <- computeDR(   Y_train,   status_train,   engine = \"cpp\",   eta = predict(cox_pls_fit, type = \"link\") ) #> Error: object 'cox_pls_fit' not found stopifnot(all.equal(residuals_overview, cpp_residuals, tolerance = 1e-7)) #> Error: object 'cpp_residuals' not found set.seed(123) cv_results <- cv.coxgpls(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cv_results$opt_nt #> Error: object 'cv_results' not found cox_pls_dr <- coxgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = cv_results$opt_nt,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cox_pls_dr #> Error: object 'cox_pls_dr' not found"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"benchmarking","dir":"","previous_headings":"","what":"Benchmarking","title":"Partial Least Squares for Cox Models with Big Matrices","text":"provide reproducible benchmarks compare coxgpls() big-memory solvers survival::coxph(). Start Benchmarking bigPLScox vignette interactive tour. command-line experiments, execute scripts inst/benchmarks/ installing optional dependencies listed Suggests DESCRIPTION file. script accepts environment variables (example, bigPLScox.benchmark.n, bigPLScox.benchmark.p, bigPLScox.benchmark.ncomp) control simulation size. Results stored inst/benchmarks/results/ time-stamped filenames traceability.","code":"Rscript inst/benchmarks/cox-benchmark.R Rscript inst/benchmarks/cox_pls_benchmark.R Rscript inst/benchmarks/benchmark_bigPLScox.R"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"vignettes-and-documentation","dir":"","previous_headings":"","what":"Vignettes and documentation","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Four vignettes ship package: Getting started bigPLScox – end--end introduction covering data preparation, fitting, validation workflows. Overview bigPLScox – high-level description modelling functions typical use cases. Big-memory workflows bigPLScox – instructions working bigmemory matrices streaming solvers. Benchmarking bigPLScox – guidance evaluating performance baseline Cox implementations using bench package. full reference documentation pkgdown website available https://fbertran.github.io/bigPLScox/.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug reports and feature requests","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Bug reports feature requests can filed issue tracker. Please make sure new code comes unit tests reproducible examples applicable.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputed Microsat features — Xmicro.censure_compl_imp","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"dataset provides imputed microsat specifications. Imputations computed using Multivariate Imputation Chained Equations (MICE) using predictive mean matching numeric columns, logistic regression imputation binary data factors 2 levels polytomous regression imputation categorical data .e. factors three levels.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"data frame 117 observations following 40 variables. D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"","code":"# \\donttest{ data(Xmicro.censure_compl_imp) X_train_micro <- Xmicro.censure_compl_imp[1:80,] X_test_micro <- Xmicro.censure_compl_imp[81:117,] rm(X_train_micro,X_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/align_big_plscox.html","id":null,"dir":"Reference","previous_headings":"","what":"Align a GD fit to a PLS fit (optional refit) — align_big_plscox","title":"Align a GD fit to a PLS fit (optional refit) — align_big_plscox","text":"Align GD fit PLS fit (optional refit)","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/align_big_plscox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Align a GD fit to a PLS fit (optional refit) — align_big_plscox","text":"","code":"align_big_plscox(fit_gd, fit_pls, time, status, rotate = TRUE, refit = TRUE)"},{"path":"https://fbertran.github.io/bigPLScox/reference/align_big_plscox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Align a GD fit to a PLS fit (optional refit) — align_big_plscox","text":"fit_gd object big_pls_cox_gd() fit_pls object big_pls_cox() time, status Surv parts used refit rotate logical; Procrustes-rotate GD scores PLS basis refit logical; refit Cox model rotated GD scores","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/align_big_plscox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Align a GD fit to a PLS fit (optional refit) — align_big_plscox","text":"fit_gd $scores/$coefficients/$cox_fit possibly updated","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bigPLScox-package — bigPLScox-package","title":"bigPLScox-package — bigPLScox-package","text":"Provides Partial least squares Regression regular, generalized linear Cox models big data. allows missing data explanatory variables. Repeated k-fold cross-validation models using various criteria. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bigPLScox-package — bigPLScox-package","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS binary classification survival analysis. BMC Bioinformatics, 16, 211.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bigPLScox-package — bigPLScox-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy-Bertrand myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bigPLScox-package — bigPLScox-package","text":"","code":"set.seed(314) library(bigPLScox) data(sim_data) head(sim_data) #>                    status         X1         X2         X3        X4         X5 #> 0.0013236229370777      1  0.5448667 -0.9205711  1.1017160 1.3558567  1.4346174 #> 0.193665925040523       1 -0.5641483  0.2733279  0.9731780 1.1232252  0.2652977 #> 0.0167866701431944      1  1.4921118  0.2598002 -1.5436997 0.1165158  1.2208183 #> 0.0584127055299712      1 -0.6430141 -0.9807448 -1.2294945 0.8006227  1.5492078 #> 0.732960708716205       1  0.1876928 -1.2571263  0.9016827 1.3562191 -1.6809553 #> 0.508483386474255       0 -0.6141516 -0.8162560  0.2633415 0.4188066  0.2791399 #>                            X6         X7         X8          X9        X10 #> 0.0013236229370777 -0.8727406  1.5161252  0.7801527 -0.53617252 -0.6990319 #> 0.193665925040523   1.5046047  0.9096495 -1.2200395 -1.57280359  0.8347194 #> 0.0167866701431944 -0.6451659  1.2515692  0.5867273 -0.20080821  0.7492891 #> 0.0584127055299712  1.2557210  0.6188920  0.7123894 -0.67379538 -1.2377412 #> 0.732960708716205   0.7304366 -1.1223302  0.9633307  0.14016470 -0.9996676 #> 0.508483386474255  -0.0538974 -0.1410697 -0.8637916  0.01669784  1.5589135"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"Performs stochastic gradient descent optimisation large-scale survival models removing observations missing values.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"","code":"bigSurvSGD.na.omit(   formula = survival::Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   features.mean = NULL,   features.sd = NULL,   opt.method = \"AMSGrad\",   beta.init = NULL,   beta.type = \"averaged\",   lr.const = 0.12,   lr.tau = 0.5,   strata.size = 20,   batch.size = 1,   num.epoch = 100,   b1 = 0.9,   b2 = 0.99,   eps = 1e-08,   inference.method = \"plugin\",   num.boot = 1000,   num.epoch.boot = 100,   boot.method = \"SGD\",   lr.const.boot = 0.12,   lr.tau.boot = 0.5,   num.sample.strata = 1000,   sig.level = 0.05,   beta0 = 0,   alpha = NULL,   lambda = NULL,   nlambda = 100,   num.strata.lambda = 10,   lambda.scale = 1,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"float\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"formula Model formula describing survival outcome set predictors include optimisation. data Input data set connection big-memory backed design matrix contains variables referenced formula. norm.method Normalization strategy applied feature matrix optimisation, example centring standardising columns. features.mean Optional pre-computed column means used normalising features repeated fits can reuse shared statistics. features.sd Optional pre-computed column standard deviations used concert features.mean scaling predictors. opt.method Gradient based optimisation routine employ, vanilla SGD adaptive methods like Adam. beta.init Vector starting values regression coefficients supplied warm-starting optimisation. beta.type Indicator controlling beta.init interpreted, example whether coefficients correspond original normalised scale. lr.const Base learning-rate constant used stochastic gradient descent routine. lr.tau Learning-rate decay horizon damping factor moderates step size schedule. strata.size Number observations drawn per stratum building mini-batches optimisation loop. batch.size Total number observations assembled stochastic gradient batch. num.epoch Number passes training data used optimisation. b1 First exponential moving-average rate used adaptive methods Adam smooth gradients. b2 Second exponential moving-average rate used adaptive methods smooth squared gradients. eps Numerical stabilisation constant added denominators updating adaptive moments. inference.method Inference approach requested fitting, example naive asymptotics bootstrap resampling. num.boot Number bootstrap replicates draw inference.method relies resampling. num.epoch.boot Number optimisation epochs run within bootstrap replicate. boot.method Type bootstrap scheme apply, ordinary stratified resampling. lr.const.boot Learning-rate constant used bootstrap refits. lr.tau.boot Learning-rate decay factor applied bootstrap refits. num.sample.strata Number strata sampled without replacement bootstrap iteration stratified resampling selected. sig.level Significance level used constructing confidence intervals hypothesis tests. beta0 Optional vector coefficients null hypothesis performing hypothesis tests. alpha Elastic-net mixing parameter controlling relative weight \\(\\ell_1\\) \\(\\ell_2\\) regularisation penalties. lambda Sequence regularisation strengths supplied explicitly penalised estimation. nlambda Number automatically generated lambda values grid produced internally. num.strata.lambda Number strata used tuning lambda via cross-validation search procedures. lambda.scale Scale lambda grid generated, example logarithmic linear spacing. parallel.flag Logical flag enabling parallel computation gradients bootstrap replicates. num.cores Number processing cores use parallel execution enabled. bigmemory.flag Logical flag indicating whether intermediate matrices stored using bigmemory backed objects. num.rows.chunk Row chunk size use streaming data -disk matrix representation. col.names Optional character vector column names associated feature matrix. type Type survival model fit, example Cox proportional hazards accelerated failure time variants.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"fitted model object storing learned coefficients, optimisation metadata, requested inference summaries. coef: Log hazards ratio. inference used, returns vector estimated coefficients: inference used, returns matrix including estimates confidence intervals coefficients. case penalization, resturns matrix columns corresponding lambdas. coef.exp: Exponentiated version coef (hazards ratio). lambda: Returns lambda(s) used penalizarion. alpha: Returns alpha used penalizarion. features.mean: Returns means features, given calculated features.sd: Returns standard deviations features, given calculated.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"","code":"# \\donttest{ data(micro.censure, package = \"bigPLScox\") surv_data <- stats::na.omit(micro.censure[, c(\"survyear\", \"DC\", \"sexe\", \"Agediag\")]) # Increase num.epoch and num.boot for real use fit <- bigSurvSGD.na.omit(    survival::Surv(survyear, DC) ~ .,    data = surv_data,    norm.method = \"standardize\",    opt.method = \"adam\",    batch.size = 16,    num.epoch = 2,  ) #> Warning: Strata size times batch size is greater than number of observations. #>  This package resizes them to strata size = 20 and batch size = 4 # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"Compute Partial Least Squares (PLS) components tailored Cox proportional hazards models predictors stored big.matrix bigmemory package.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"","code":"big_pls_cox(   X,   time,   status,   ncomp = 2L,   control = survival::coxph.control(),   keepX = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"X numeric matrix bigmemory::big.matrix object containing predictors. time Numeric vector survival times. status Integer (0/1) vector event indicators. ncomp Number latent components compute. control Optional list passed survival::coxph.control. keepX Optional integer vector specifying number variables retain (naive sparsity) component. value zero keeps predictors. single integer supplied recycled across components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"list computed scores, loadings, weights, scaling information fitted Cox model returned survival::coxph.fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"function standardises predictor column, iteratively builds latent scores using martingale residuals Cox fits, deflates predictors without materialising full design matrix memory. -memory file-backed bigmemory matrices supported.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660 Bertrand, F., Bastien, P., Meyer, N., & Maumy-Bertrand, M. (2014). PLS models censored data. Proceedings UseR! 2014 (p. 152).","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"","code":"if (requireNamespace(\"survival\", quietly = TRUE)) {   set.seed(1)   X <- matrix(rnorm(100), nrow = 20)   time <- rexp(20)   status <- rbinom(20, 1, 0.5)   fit <- big_pls_cox(X, time, status, ncomp = 2)   str(fit) } #> List of 9 #>  $ scores  : num [1:20, 1:2] 0.275 0.244 -1.069 1.455 -0.324 ... #>  $ loadings: num [1:5, 1:2] 0.792 0.1 0.273 0.253 -0.777 ... #>  $ weights : num [1:5, 1:2] 0.681 0.273 0.248 0.117 -0.622 ... #>  $ center  : num [1:5] 0.19052 -0.00647 0.1388 0.10174 0.11985 #>  $ scale   : num [1:5] 0.913 0.871 0.81 1.05 0.911 #>  $ cox_fit :List of 10 #>   ..$ coefficients     : num [1:2] 0.867 0.231 #>   ..$ var              : num [1:2, 1:2] 0.1691 0.0584 0.0584 0.2252 #>   ..$ loglik           : num [1:2] -18.5 -15.8 #>   ..$ score            : num 4.82 #>   ..$ iter             : int 4 #>   ..$ linear.predictors: num [1:20] 0.0329 0.0502 -0.7536 1.4699 -0.5345 ... #>   ..$ residuals        : Named num [1:20] -0.26 -0.125 -0.504 0.837 0.921 ... #>   .. ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : num [1:2] 1.67e-17 -3.33e-17 #>   ..$ method           : chr \"efron\" #>   ..$ class            : chr \"coxph\" #>  $ keepX   : int [1:2] 0 0 #>  $ time    : num [1:20] 0.7632 1.5727 1.8356 0.0372 0.1256 ... #>  $ status  : num [1:20] 0 1 0 1 1 1 0 0 0 1 ... #>  - attr(*, \"class\")= chr \"big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","title":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","text":"Compute PLS components Cox models, using fast C++ backend -memory matrices bigmemory::big.matrix objects.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","text":"","code":"big_pls_cox_fast(   X,   time,   status,   ncomp = 2L,   control = survival::coxph.control(),   keepX = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","text":"X numeric matrix bigmemory::big.matrix object containing predictors. time Numeric vector survival times. status Integer (0/1) vector event indicators. ncomp Number latent components compute. control Optional list passed survival::coxph.control. keepX Optional integer vector specifying number variables retain (naive sparsity) component. value zero keeps predictors. single integer supplied recycled across components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","text":"list computed scores, loadings, weights, scaling information fitted Cox model returned survival::coxph.fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_fast.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares Components for Cox Models (fast backend) — big_pls_cox_fast","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660 Bertrand, F., Bastien, P., Meyer, N., & Maumy-Bertrand, M. (2014). PLS models censored data. Proceedings UseR! 2014 (p. 152).","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"Fits Cox proportional hazards regression model using gradient-descent optimizer implemented C++. function operates directly bigmemory::big.matrix object avoid materialising large design matrices memory.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"","code":"big_pls_cox_gd(   X,   time,   status,   ncomp = NULL,   max_iter = 500L,   tol = 1e-06,   learning_rate = 0.01,   keepX = NULL,   coxfit = TRUE )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"X bigmemory::big.matrix containing design matrix (rows observations). time numeric vector follow-times length equal number rows X. status numeric integer vector length time containing event indicators (1 event, 0 censoring). ncomp integer giving number components (columns) use X. Defaults min(5, ncol(X)). max_iter Maximum number gradient-descent iterations (default 500). tol Convergence tolerance Euclidean distance successive coefficient vectors. learning_rate Step size used gradient-descent updates. keepX Optional integer vector describing number predictors retain per component (naive sparsity). value zero keeps predictors. coxfit Optional Boolean fit Cox model extracted components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"list components: coefficients: Estimated Cox regression coefficients latent scores. loglik: Final partial log-likelihood value. iterations: Number gradient-descent iterations performed. converged: Logical flag indicating whether convergence achieved. scores: Matrix latent score vectors (one column per component). loadings: Matrix loading vectors associated component. weights: Matrix PLS weight vectors. center: Column means used centre predictors. scale: Column scales (standard deviations) used standardise predictors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660 Bertrand, F., Bastien, P., Meyer, N., & Maumy-Bertrand, M. (2014). PLS models censored data. Proceedings UseR! 2014 (p. 152).","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"","code":"library(bigmemory) set.seed(1) n <- 50 p <- 10 X <- bigmemory::as.big.matrix(matrix(rnorm(n * p), n, p)) time <- rexp(n, rate = 0.1) status <- rbinom(n, 1, 0.7) fit <- big_pls_cox_gd(X, time, status, ncomp = 3, max_iter = 200) str(fit) #> List of 18 #>  $ coefficients  : num [1:3] 0.593 0.165 0.314 #>  $ loglik        : num -104 #>  $ iterations    : int 200 #>  $ converged     : logi TRUE #>  $ scores        : num [1:50, 1:3] 0.0513 1.555 -1.1934 0.7405 -1.9847 ... #>  $ loadings      : num [1:10, 1:3] 0.3689 -0.0474 0.5673 0.1476 0.4647 ... #>  $ weights       : num [1:10, 1:3] 0.5334 -0.1685 0.4853 0.0962 0.3655 ... #>  $ center        : num [1:10] 0.1004 0.1173 -0.1525 0.0769 -0.0313 ... #>  $ scale         : num [1:10] 0.831 0.969 0.9 1.009 1.095 ... #>  $ keepX         : int [1:3] 0 0 0 #>  $ time          : num [1:50] 0.6162 3.6972 12.2628 0.271 0.0901 ... #>  $ status        : num [1:50] 1 1 0 1 0 1 1 1 1 1 ... #>  $ loglik_trace  : num [1:34] -107 -106 -105 -105 -105 ... #>  $ gradnorm_trace: num [1:34] 19.64 13.12 9.08 6.5 4.8 ... #>  $ step_trace    : num [1:34] 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 ... #>  $ coef_trace    :List of 34 #>   ..$ : num [1:3] 0.1642 0.0805 0.0716 #>   ..$ : num [1:3] 0.277 0.127 0.121 #>   ..$ : num [1:3] 0.356 0.153 0.156 #>   ..$ : num [1:3] 0.413 0.167 0.184 #>   ..$ : num [1:3] 0.455 0.174 0.207 #>   ..$ : num [1:3] 0.486 0.177 0.225 #>   ..$ : num [1:3] 0.51 0.177 0.24 #>   ..$ : num [1:3] 0.528 0.177 0.253 #>   ..$ : num [1:3] 0.541 0.176 0.263 #>   ..$ : num [1:3] 0.552 0.175 0.272 #>   ..$ : num [1:3] 0.56 0.174 0.279 #>   ..$ : num [1:3] 0.567 0.172 0.285 #>   ..$ : num [1:3] 0.572 0.171 0.29 #>   ..$ : num [1:3] 0.576 0.17 0.295 #>   ..$ : num [1:3] 0.579 0.17 0.298 #>   ..$ : num [1:3] 0.582 0.169 0.301 #>   ..$ : num [1:3] 0.584 0.168 0.303 #>   ..$ : num [1:3] 0.586 0.168 0.305 #>   ..$ : num [1:3] 0.587 0.167 0.307 #>   ..$ : num [1:3] 0.588 0.167 0.308 #>   ..$ : num [1:3] 0.589 0.167 0.309 #>   ..$ : num [1:3] 0.59 0.166 0.31 #>   ..$ : num [1:3] 0.59 0.166 0.311 #>   ..$ : num [1:3] 0.591 0.166 0.311 #>   ..$ : num [1:3] 0.591 0.166 0.312 #>   ..$ : num [1:3] 0.592 0.166 0.312 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.165 0.313 #>   ..$ : num [1:3] 0.592 0.165 0.314 #>   ..$ : num [1:3] 0.593 0.165 0.314 #>   ..$ : num [1:3] 0.593 0.165 0.314 #>  $ eta_trace     :List of 34 #>   ..$ : num [1:50] -0.1661 0.1968 0.2283 0.0614 0.3025 ... #>   ..$ : num [1:50] -0.268 0.324 0.354 0.105 0.503 ... #>   ..$ : num [1:50] -0.326 0.406 0.414 0.138 0.64 ... #>   ..$ : num [1:50] -0.358 0.458 0.435 0.163 0.737 ... #>   ..$ : num [1:50] -0.373 0.492 0.434 0.183 0.808 ... #>   ..$ : num [1:50] -0.378 0.514 0.423 0.198 0.861 ... #>   ..$ : num [1:50] -0.377 0.529 0.407 0.21 0.902 ... #>   ..$ : num [1:50] -0.373 0.537 0.389 0.219 0.933 ... #>   ..$ : num [1:50] -0.367 0.543 0.371 0.226 0.958 ... #>   ..$ : num [1:50] -0.361 0.546 0.355 0.232 0.977 ... #>   ..$ : num [1:50] -0.355 0.548 0.341 0.236 0.992 ... #>   ..$ : num [1:50] -0.35 0.55 0.328 0.24 1.005 ... #>   ..$ : num [1:50] -0.345 0.55 0.317 0.243 1.015 ... #>   ..$ : num [1:50] -0.34 0.55 0.307 0.245 1.023 ... #>   ..$ : num [1:50] -0.337 0.55 0.299 0.247 1.029 ... #>   ..$ : num [1:50] -0.333 0.55 0.293 0.249 1.035 ... #>   ..$ : num [1:50] -0.33 0.55 0.287 0.25 1.039 ... #>   ..$ : num [1:50] -0.328 0.55 0.282 0.251 1.042 ... #>   ..$ : num [1:50] -0.326 0.549 0.278 0.252 1.045 ... #>   ..$ : num [1:50] -0.324 0.549 0.275 0.252 1.047 ... #>   ..$ : num [1:50] -0.323 0.549 0.272 0.253 1.049 ... #>   ..$ : num [1:50] -0.322 0.549 0.27 0.253 1.051 ... #>   ..$ : num [1:50] -0.321 0.549 0.268 0.254 1.052 ... #>   ..$ : num [1:50] -0.32 0.548 0.267 0.254 1.053 ... #>   ..$ : num [1:50] -0.319 0.548 0.266 0.254 1.054 ... #>   ..$ : num [1:50] -0.319 0.548 0.265 0.255 1.055 ... #>   ..$ : num [1:50] -0.318 0.548 0.264 0.255 1.055 ... #>   ..$ : num [1:50] -0.318 0.548 0.263 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>  $ cox_fit       :List of 19 #>   ..$ coefficients     : Named num [1:3] 0.376 -0.323 -0.199 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ var              : num [1:3, 1:3] 0.03725 -0.00601 0.00358 -0.00601 0.0223 ... #>   ..$ loglik           : num [1:2] -110 -106 #>   ..$ score            : num 7.83 #>   ..$ iter             : int 4 #>   ..$ linear.predictors: num [1:50] -0.399 0.338 -1.056 1.072 -0.37 ... #>   ..$ residuals        : Named num [1:50] 0.938 0.4757 -0.2709 0.899 -0.0117 ... #>   .. ..- attr(*, \"names\")= chr [1:50] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : Named num [1:3] 4.44e-18 1.02e-16 8.88e-18 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ method           : chr \"efron\" #>   ..$ n                : int 50 #>   ..$ nevent           : num 37 #>   ..$ terms            :Classes 'terms', 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \"variables\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1 #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   .. .. .. .. ..$ : chr \"fit$scores\" #>   .. .. ..- attr(*, \"term.labels\")= chr \"fit$scores\" #>   .. .. ..- attr(*, \"specials\")=Dotted pair list of 5 #>   .. .. .. ..$ strata : NULL #>   .. .. .. ..$ tt     : NULL #>   .. .. .. ..$ frailty: NULL #>   .. .. .. ..$ ridge  : NULL #>   .. .. .. ..$ pspline: NULL #>   .. .. ..- attr(*, \"order\")= int 1 #>   .. .. ..- attr(*, \"intercept\")= num 1 #>   .. .. ..- attr(*, \"response\")= int 1 #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x11ee33350>  #>   .. .. ..- attr(*, \"predvars\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"nmatrix.2\" \"nmatrix.3\" #>   .. .. .. ..- attr(*, \"names\")= chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   ..$ assign           :List of 1 #>   .. ..$ fit$scores: int [1:3] 1 2 3 #>   ..$ wald.test        : num 7.52 #>   ..$ concordance      : Named num [1:7] 589 313 0 0 0 ... #>   .. ..- attr(*, \"names\")= chr [1:7] \"concordant\" \"discordant\" \"tied.x\" \"tied.y\" ... #>   ..$ y                : 'Surv' num [1:50, 1:2]  0.6162   3.6972  12.2628+  0.2710   0.0901+  1.5697   6.7861   3.0889   0.5886   2.0551  ... #>   .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. ..$ : chr [1:50] \"1\" \"2\" \"3\" \"4\" ... #>   .. .. ..$ : chr [1:2] \"time\" \"status\" #>   .. ..- attr(*, \"type\")= chr \"right\" #>   ..$ timefix          : logi TRUE #>   ..$ formula          :Class 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x11ee33350>  #>   ..$ call             : language survival::coxph(formula = survival::Surv(time, status) ~ fit$scores, ties = \"efron\",      x = FALSE) #>   ..- attr(*, \"class\")= chr \"coxph\" #>  - attr(*, \"class\")= chr \"big_pls_cox_gd\" head(fit$scores) #>             [,1]       [,2]       [,3] #> [1,]  0.05129539  0.7550799  0.8793004 #> [2,]  1.55497806  0.3715325  0.6353775 #> [3,] -1.19340964  0.4907382  2.2626350 #> [4,]  0.74046728 -2.1053220 -0.5759915 #> [5,] -1.98468237 -0.8043244 -0.5814998 #> [6,]  0.42019957  1.5593684  0.5762548"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform new data to PLS–Cox scores — big_pls_cox_transform","title":"Transform new data to PLS–Cox scores — big_pls_cox_transform","text":"Project new observations onto previously fitted PLS–Cox components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform new data to PLS–Cox scores — big_pls_cox_transform","text":"","code":"big_pls_cox_transform(   X,   means,   sds,   weights,   loadings,   comps = seq_len(ncol(weights)) )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform new data to PLS–Cox scores — big_pls_cox_transform","text":"X New data: numeric matrix bigmemory::big.matrix. means Column means used center original predictors. sds Column standard deviations used scale original predictors. weights PLS weight matrix (p x ncomp) fitted model. loadings PLS loading matrix (p x ncomp) fitted model. comps Integer vector component indices return (1-based).","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform new data to PLS–Cox scores — big_pls_cox_transform","text":"numeric matrix scores one row per observation X one column per requested component.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"methods extend base matrix multiplication operator (%*%) group generic Arithmetic big.matrix objects can interoperate base R matrices numeric scalars using high-performance routines provided bigalgebra.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"# S4 method for class 'big.matrix,big.matrix' x %*% y  # S4 method for class 'matrix,big.matrix' x %*% y  # S4 method for class 'big.matrix,matrix' x %*% y  # S4 method for class 'big.matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,matrix' Arith(e1, e2)  # S4 method for class 'matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'numeric,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,numeric' Arith(e1, e2)"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"x, y Matrix operands supplied either big.matrix instances base R matrices, depending method signature. e1, e2 Numeric operands, may big.matrix objects, base R matrices, numeric scalars depending method signature.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"Matrix multiplications dispatch bigalgebra::dgemm(), mixed arithmetic matrices relies bigalgebra::daxpy(), scalar/matrix combinations use bigalgebra::dadd() appropriate.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"if (requireNamespace(\"bigmemory\", quietly = TRUE) &&     requireNamespace(\"bigalgebra\", quietly = TRUE)) {   x <- bigmemory::big.matrix(2, 2, init = 1)   y <- bigmemory::big.matrix(2, 2, init = 2)   x %*% y   x + y   x * 3 } #> An object of class \"big.matrix\" #> Slot \"address\": #> <pointer: 0x105573410> #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Scaled Design Matrices for Big Survival Models — bigscale","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"Prepares large-scale feature matrix stochastic gradient descent byapplying optional normalisation, stratified sampling, batching rules.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"","code":"bigscale(   formula = survival::Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   strata.size = 20,   batch.size = 1,   features.mean = NULL,   features.sd = NULL,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"short\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"formula formula used extract outcome predictors included scaled design matrix. data Input data source containing variables referenced formula. norm.method Normalisation strategy (example centring standardising columns) applied feature matrix. strata.size Number observations retain stratum constructing stratified batches. batch.size Total size mini-batch produced scaling routine. features.mean Optional vector column means can reused normalise multiple data sets consistent manner. features.sd Optional vector column standard deviations pairs features.mean scaling. parallel.flag Logical flag signalling whether scaling work parallelised across cores. num.cores Number processor cores allocated parallel.flag TRUE. bigmemory.flag Logical flag specifying whether intermediate results stored bigmemory-backed matrices. num.rows.chunk Chunk size used streaming data -disk objects memory. col.names Optional character vector assigning column names generated design matrix. type Type model preprocessing target prepared, survival regression.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"scaled design matrix scaler class along metadata describing transformation applied. time.indices: indices time variable cens.indices: indices censored variables features.indices: indices features time.sd: standard deviation time variable time.mean: mean time variable features.sd: standard deviation features features.mean: mean features nr: number rows nc: number columns col.names: columns names","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"","code":"data(micro.censure, package = \"bigPLScox\") surv_data <- stats::na.omit(   micro.censure[, c(\"survyear\", \"DC\", \"sexe\", \"Agediag\")] ) scaled <- bigscale(   survival::Surv(survyear, DC) ~ .,   data = surv_data,   norm.method = \"standardize\",   batch.size = 16 ) #> Warning: Strata size times batch size is greater than number of observations. #>  This package resizes them to strata size = 20 and batch size = 4"},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":null,"dir":"Reference","previous_headings":"","what":"Information criteria for component selection — component_information","title":"Information criteria for component selection — component_information","text":"Computes log-likelihood, AIC BIC values nested models using latent components estimated big_pls_cox() big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information criteria for component selection — component_information","text":"","code":"component_information(object, max_comp = ncol(object$scores))  # S3 method for class 'big_pls_cox' component_information(object, max_comp = ncol(object$scores))  # S3 method for class 'big_pls_cox_gd' component_information(object, max_comp = ncol(object$scores))  select_ncomp(object, criterion = c(\"AIC\", \"BIC\", \"loglik\"), ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information criteria for component selection — component_information","text":"object fitted object class big_pls_cox big_pls_cox_gd. max_comp Maximum number components consider. Defaults components stored model. criterion Criterion optimise: \"AIC\", \"BIC\" \"loglik\". ... Passed component_information().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information criteria for component selection — component_information","text":"data frame columns ncomp, loglik, AIC, BIC. list table information criteria recommended number components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute deviance residuals — computeDR","title":"Compute deviance residuals — computeDR","text":"function computes deviance residuals null Cox model. default delegates survival::coxph(), high-performance C++ engine also available large -memory bigmemory::big.matrix design matrices.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute deviance residuals — computeDR","text":"","code":"computeDR(   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleY = TRUE,   plot = FALSE,   engine = c(\"survival\", \"cpp\", \"qcpp\"),   method = c(\"efron\", \"breslow\"),   X = NULL,   coef = NULL,   eta = NULL,   center = NULL,   scale = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute deviance residuals — computeDR","text":"time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleY time values standardized ? plot survival function plotted ? engine Either \"survival\" (default) call survival::coxph() \"cpp\" use C++ implementation. method Tie handling use engine = \"cpp\": either \"efron\" (default) \"breslow\". X Optional design matrix used compute linear predictor engine = \"cpp\". Supports base matrices, data frames, bigmemory::big.matrix objects. coef Optional coefficient vector associated X engine = \"cpp\". eta Optional precomputed linear predictor passed directly C++ engine. center, scale Optional centring scaling vectors applied X computing linear predictor C++ engine.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute deviance residuals — computeDR","text":"Residuals null model fit. engine = \"cpp\", returned vector attributes \"martingale\", \"cumhaz\", \"linear_predictor\".","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute deviance residuals — computeDR","text":"Bastien, P., Bertrand, F., Meyer, N., Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS binary classification survival analysis. BMC Bioinformatics, 16, 211. Therneau, T.M., Grambsch, P.M. (2000). Modeling Survival Data: Extending Cox Model. Springer.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute deviance residuals — computeDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute deviance residuals — computeDR","text":"","code":"data(micro.censure, package = \"bigPLScox\")  Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  Y_DR <- computeDR(Y_train_micro,C_train_micro) Y_DR <- computeDR(Y_train_micro,C_train_micro,plot=TRUE)   Y_cpp <- computeDR(   Y_train_micro,   C_train_micro,   engine = \"cpp\",   eta = rep(0, length(Y_train_micro)) )  Y_qcpp <- computeDR(   Y_train_micro,   C_train_micro,   engine = \"qcpp\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"coxDKgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE : cox_DKgplsDR Final Cox-model. allres=TRUE : tt_DKgplsDR PLSR components. cox_DKgplsDR Final Cox-model. DKgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKgplsDR_fit=coxDKgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.905e+00 1.826e+01 1.113e+00 2.609 0.00908 #> dim.2 8.230e+00 3.753e+03 2.644e+00 3.113 0.00185 #> dim.3 5.686e+00 2.946e+02 1.980e+00 2.871 0.00409 #> dim.4 1.612e+01 1.000e+07 5.265e+00 3.061 0.00221 #> dim.5 3.837e+00 4.636e+01 2.043e+00 1.878 0.06035 #> dim.6 1.068e+01 4.339e+04 4.067e+00 2.626 0.00864 #>  #> Likelihood ratio test=66.84  on 6 df, p=1.812e-12 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.967e+00 1.943e+01 1.133e+00 2.619 0.00883 #> dim.2 8.682e+00 5.895e+03 2.786e+00 3.116 0.00183 #> dim.3 6.189e+00 4.876e+02 2.172e+00 2.850 0.00437 #> dim.4 1.699e+01 2.397e+07 5.557e+00 3.058 0.00223 #> dim.5 4.000e+00 5.461e+01 2.091e+00 1.913 0.05577 #> dim.6 1.087e+01 5.273e+04 4.052e+00 2.683 0.00729 #>  #> Likelihood ratio test=68.27  on 6 df, p=9.266e-13 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.917e+00 1.849e+01 1.117e+00 2.611 0.00903 #> dim.2 8.339e+00 4.183e+03 2.677e+00 3.115 0.00184 #> dim.3 5.806e+00 3.322e+02 2.025e+00 2.867 0.00415 #> dim.4 1.634e+01 1.244e+07 5.337e+00 3.061 0.00220 #> dim.5 3.877e+00 4.827e+01 2.055e+00 1.887 0.05916 #> dim.6 1.073e+01 4.576e+04 4.062e+00 2.642 0.00825 #>  #> Likelihood ratio test=67.2  on 6 df, p=1.531e-12 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"coxDKsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE : cox_DKsgplsDR Final Cox-model. allres=TRUE : tt_DKsgplsDR PLSR components. cox_DKsgplsDR Final Cox-model. DKsgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKsgplsDR_fit=coxDKsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKsgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.307e+00 2.731e+01 1.233e+00 2.682 0.007313 #> dim.2 9.671e+00 1.586e+04 2.898e+00 3.337 0.000847 #> dim.3 8.225e+00 3.734e+03 2.957e+00 2.782 0.005409 #> dim.4 1.423e+01 1.510e+06 4.651e+00 3.059 0.002218 #> dim.5 4.081e+00 5.918e+01 2.194e+00 1.860 0.062949 #> dim.6 7.068e+00 1.174e+03 2.951e+00 2.395 0.016601 #>  #> Likelihood ratio test=66.51  on 6 df, p=2.121e-12 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKsgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.733e+00 4.182e+01 1.335e+00 2.796 0.005169 #> dim.2 1.032e+01 3.046e+04 3.115e+00 3.314 0.000919 #> dim.3 8.932e+00 7.567e+03 3.241e+00 2.756 0.005852 #> dim.4 1.454e+01 2.062e+06 4.727e+00 3.076 0.002098 #> dim.5 4.844e+00 1.269e+02 2.314e+00 2.093 0.036361 #> dim.6 6.079e+00 4.366e+02 2.659e+00 2.286 0.022228 #>  #> Likelihood ratio test=68.4  on 6 df, p=8.691e-13 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKsgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.346e+00 2.838e+01 1.247e+00 2.682 0.007315 #> dim.2 9.675e+00 1.592e+04 2.893e+00 3.345 0.000823 #> dim.3 7.870e+00 2.619e+03 2.889e+00 2.724 0.006450 #> dim.4 1.366e+01 8.541e+05 4.443e+00 3.074 0.002112 #> dim.5 4.079e+00 5.909e+01 2.128e+00 1.917 0.055277 #> dim.6 6.653e+00 7.753e+02 2.885e+00 2.306 0.021109 #>  #> Likelihood ratio test=66.31  on 6 df, p=2.334e-12 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,coxDKsgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"coxDKspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ? alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value controlling maximal penalty considered sgPLS estimating sparse group loadings. Defaults 10^5.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE : cox_DKspls_sgplsDR Final Cox-model. allres=TRUE : tt_DKspls_sgplsDR PLSR components. cox_DKspls_sgplsDR Final Cox-model. DKspls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(X_train_micro,Y_train_micro, C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.595e+00 3.643e+01 1.303e+00 2.759 0.005800 #> dim.2 1.014e+01 2.537e+04 3.047e+00 3.328 0.000875 #> dim.3 8.615e+00 5.511e+03 3.136e+00 2.747 0.006011 #> dim.4 1.426e+01 1.565e+06 4.641e+00 3.074 0.002115 #> dim.5 4.642e+00 1.037e+02 2.267e+00 2.047 0.040625 #> dim.6 6.228e+00 5.067e+02 2.715e+00 2.294 0.021812 #>  #> Likelihood ratio test=67.76  on 6 df, p=1.174e-12 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~X_train_micro,Y_train_micro, C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.256e+00 2.594e+01 1.225e+00 2.659 0.007847 #> dim.2 9.555e+00 1.412e+04 2.855e+00 3.347 0.000818 #> dim.3 7.948e+00 2.831e+03 2.856e+00 2.783 0.005386 #> dim.4 1.404e+01 1.258e+06 4.579e+00 3.067 0.002160 #> dim.5 4.028e+00 5.615e+01 2.173e+00 1.854 0.063745 #> dim.6 7.231e+00 1.382e+03 3.030e+00 2.387 0.016993 #>  #> Likelihood ratio test=66.1  on 6 df, p=2.567e-12 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~.,Y_train_micro,C_train_micro, ncomp=6,dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),  alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.207e+00 2.469e+01 1.170e+00 2.739 0.006153 #> dim.2 9.160e+00 9.506e+03 2.728e+00 3.357 0.000787 #> dim.3 6.938e+00 1.030e+03 2.434e+00 2.850 0.004368 #> dim.4 1.364e+01 8.376e+05 4.398e+00 3.101 0.001928 #> dim.5 3.808e+00 4.507e+01 2.219e+00 1.716 0.086097 #> dim.6 7.262e+00 1.425e+03 3.073e+00 2.363 0.018125 #>  #> Likelihood ratio test=64.67  on 6 df, p=5.029e-12 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_DKspls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox deviance residuals via C++ backends — cox_deviance_residuals","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"Compute martingale deviance residuals Cox models without materialising intermediate survival fits R. functions rely dedicated C++ implementations operate either -memory vectors bigmemory::big.matrix objects enable streaming computations large datasets.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"","code":"cox_deviance_residuals(time, status, weights = NULL)  cox_deviance_details(time, status, weights = NULL)  cox_deviance_residuals_big(X, time_col, status_col, weights = NULL)  cox_partial_deviance_big(X, coef, time, status)  benchmark_deviance_residuals(time, status, iterations = 25, methods = list())"},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"time Numeric vector follow-times. status Numeric integer vector length time giving event indicators (1 event, 0 censoring). weights Optional non-negative case weights. supplied must length time. X bigmemory::big.matrix storing survival information column-wise. time_col, status_col Integer indices pointing columns X contain follow-time event indicator respectively. coef Numeric vector regression coefficients used evaluate partial log-likelihood deviance big.matrix design. iterations Number iterations used bench::mark benchmarking residual computations. methods Optional named list alternative residual implementations compare benchmark_deviance_residuals.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"cox_deviance_residuals() cox_deviance_residuals_big() return numeric vector deviance residuals. cox_deviance_details() returns list cumulative hazard, martingale, deviance residuals. cox_partial_deviance_big() returns list containing partial log-likelihood, deviance, evaluated linear predictor. benchmark_deviance_residuals() returns tibble::tibble.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"cox_deviance_residuals() operates standard R vectors matches output residuals(coxph(...), type = \"deviance\") right-censored data without ties. cox_deviance_residuals_big() keeps computation C++ reading directly big.matrix, avoiding extra copies. cox_partial_deviance_big() evaluates partial log-likelihood deviance given coefficient vector big design matrix. useful selecting number latent components via information criteria. benchmark_deviance_residuals() compares dedicated C++ implementation reference approaches (example, survival package) using bench::mark. function returns tibble iteration statistics.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cox_deviance_residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox deviance residuals via C++ backends — cox_deviance_residuals","text":"","code":"if (requireNamespace(\"survival\", quietly = TRUE)) {   set.seed(123)   time <- rexp(50)   status <- rbinom(50, 1, 0.6)   dr_cpp <- cox_deviance_residuals(time, status)   dr_surv <- residuals(survival::coxph(survival::Surv(time, status) ~ 1),                        type = \"deviance\")   all.equal(unname(dr_cpp), unname(dr_surv), tolerance = 1e-6) } #> [1] TRUE"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components — coxgpls","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"coxgpls(Xplan, ...)  # S3 method for class 'formula' coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. missing, every predictor placed group. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE : cox_gpls Final Cox-model. allres=TRUE : tt_gpls PLSR components. cox_gpls Final Cox-model. gpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgpls_fit=coxgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17  (coxgpls_fit=coxgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17  (ccoxgpls_fit=coxgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"coxgplsDR(Xplan, ...)  # S3 method for class 'formula' coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE : cox_gplsDR Final Cox-model. allres=TRUE : tt_gplsDR PLSR components. cox_gplsDR Final Cox-model. gplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgplsDR_fit=coxgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"coxsgpls(Xplan, ...)  # S3 method for class 'formula' coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE : cox_sgpls Final Cox-model. allres=TRUE : tt_sgpls PLSR components. cox_sgpls Final Cox-model. sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgpls_fit=coxsgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgpls_sgfit) #> Warning: object 'cox_sgpls_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"coxsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE : cox_sgplsDR Final Cox-model. allres=TRUE : tt_sgplsDR PLSR components. cox_sgplsDR Final Cox-model. sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgplsDR_fit=coxsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgplsDR_sgfit) #> Warning: object 'cox_sgplsDR_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"coxspls_sgpls(Xplan, ...)  # S3 method for class 'formula' coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value controlling maximal penalty considered sgPLS estimating sparse group loadings. Defaults 10^5.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE : cox_spls_sgpls Final Cox-model. allres=TRUE : tt_spls_sgpls PLSR components. cox_spls_sgpls Final Cox-model. spls_sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgpls_fit=coxspls_sgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"coxspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value giving upper bound regularized regression penalty used sgPLS. Defaults 10\\(^5\\). plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE : cox_spls_sgplsDR Final Cox-model. allres=TRUE : tt_spls_sgplsDR PLSR components. cox_spls_sgplsDR Final Cox-model. spls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","title":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","text":"Performs K-fold cross-validation models fitted big_pls_cox() big_pls_cox_gd(). routine mirrors behaviour cross-validation helpers available original plsRcox package operating big.matrix inputs.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","text":"","code":"cv.big_pls_cox(   data,   nfold = 5L,   nt = 5L,   keepX = NULL,   givefold,   allCVcrit = FALSE,   times.auc = NULL,   times.prederr = NULL,   method = c(\"efron\", \"breslow\"),   verbose = TRUE,   ... )  cv.big_pls_cox_gd(   data,   nfold = 5L,   nt = NULL,   keepX = NULL,   givefold,   allCVcrit = FALSE,   times.auc = NULL,   times.prederr = NULL,   method = c(\"efron\", \"breslow\"),   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","text":"data list entries x, time status matching arguments big_pls_cox() big_pls_cox_gd(). x can either numeric matrix/data frame bigmemory::big.matrix. nfold Integer giving number folds use. nt Number latent components evaluate. keepX Optional integer vector passed modelling function enforce naive sparsity (see big_pls_cox()). givefold Optional list fold indices. supplied, must contain nfold integer vectors whose union seq_len(nrow(data$x)). allCVcrit Logical; FALSE (default) recommended integrated AUC computed survivalROC returned. TRUE, 13 additional criteria plsRcox also evaluated. times.auc Optional time grid used time-dependent AUC computations. Defaults equally spaced grid zero maximum observed time. times.prederr Optional time grid used prediction error curves. Defaults grid times.auc without last ten evaluation points avoid instabilities. method Ties handling method passed survival::coxph. verbose Logical; print progress information. ... Additional arguments forwarded underlying modelling function.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.big_pls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","text":"list containing cross-validation summaries. allCVcrit = FALSE, list holds nt Number components assessed. cv.error10 Mean iAUC survivalROC across folds 0 nt components. cv.se10 Estimated standard errors cv.error10. folds Fold assignments. lambda.min10 Component minimising cross-validated error. lambda.1se10 Largest component within one standard error optimum. allCVcrit = TRUE, full set 14 criteria (log partial likelihood, iAUC variants Brier scores) returned together associated standard errors one-standard-error selections.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.big_pls_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation for big-memory PLS-Cox models — cv.big_pls_cox","text":"function returns cross-validated estimates component (including null model) using either big_pls_cox() big_pls_cox_gd(), depending engine argument. implementation reuses internal indicators (getIndicCV, getIndicCViAUCSurvROCTest) provide consistent metrics legacy plsRcox helpers.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"function cross-validates coxDKgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"cv.coxDKgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"data list three items: x explanatory variables passed coxDKgplsDR's Xplan argument, time passed coxDKgplsDR's time argument, status coxDKgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKgplsDR.res=cv.coxDKgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=2)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6381540 0.6963262 #>  #> $cv.se10 #> [1] 0.00000000 0.03036225 0.02912723 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"function cross-validates coxDKsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"cv.coxDKsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"data list three items: x explanatory variables passed coxDKsgplsDR's Xplan argument, time passed coxDKsgplsDR's time argument, status coxDKsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  # \\donttest{ #Should be run with a higher value of nt (at least 10) cv.coxDKsgplsDR.res=cv.coxDKsgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),  alpha.x = rep(0.95, 6),nt=3,plot.it = FALSE) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5  cv.coxDKsgplsDR.res #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6530362 0.7257771 0.6553724 #>  #> $cv.se10 #> [1] 0.00000000 0.03313505 0.03135189 0.04381849 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>  # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"function cross-validates coxDKspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"cv.coxDKspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"data list three items: x explanatory variables passed coxDKspls_sgplsDR's Xplan argument, time passed coxDKspls_sgplsDR's time argument, status coxDKspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKspls_sgplsDR.res=cv.coxDKspls_sgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 3),nt=3)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6530362 0.7257771 0.6553724 #>  #> $cv.se10 #> [1] 0.00000000 0.03313505 0.03135189 0.04381849 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"function cross-validates coxgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"cv.coxgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgpls.res=cv.coxgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.5225223 0.6037656 0.5639968 #>  #> $cv.se10 #> [1] 0.00000000 0.05032449 0.04012942 0.03493106 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"function cross-validates coxgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"cv.coxgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgplsDR.res=cv.coxgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6786893 0.6913293 0.6485690 #>  #> $cv.se10 #> [1] 0.00000000 0.04017423 0.02726346 0.03897730 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"function cross-validates coxsgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"cv.coxsgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"data list three items: x explanatory variables passed coxsgpls's Xplan argument, time passed coxsgpls's time argument, status coxsgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgpls.res=cv.coxsgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"function cross-validates coxsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"cv.coxsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"data list three items: x explanatory variables passed coxsgplsDR's Xplan argument, time passed coxsgplsDR's time argument, status coxsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgplsDR.res=cv.coxsgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=2)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6856847 0.6944862 #>  #> $cv.se10 #> [1] 0.00000000 0.03282521 0.03554813 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"function cross-validates coxspls_sgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"cv.coxspls_sgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"data list three items: x explanatory variables passed coxspls_sgpls's Xplan argument, time passed coxspls_sgpls's time argument, status coxspls_sgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgpls.res=cv.coxspls_sgpls(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"function cross-validates coxspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"cv.coxspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"data list three items: x explanatory variables passed coxspls_sgplsDR's Xplan argument, time passed coxspls_sgplsDR's time argument, status coxspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgplsDR.res=cv.coxspls_sgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated survival dataset for Cox models — dCox_sim","title":"Simulated survival dataset for Cox models — dCox_sim","text":"dCox_sim dataset contains simulated survival times, censoring indicators two binary covariates demonstrating Cox-related procedures included bigPLScox.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated survival dataset for Cox models — dCox_sim","text":"data frame 10000 observations following 5 variables. id observation identifier time simulated survival time status event indicator (1 = event, 0 = censored) x.1 first binary covariate x.2 second binary covariate","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated survival dataset for Cox models — dCox_sim","text":"","code":"# \\donttest{ data(dCox_sim) with(dCox_sim, table(status)) #> status #>    0    1  #> 5612 4388  # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"Function dataCox generaters random survivaldata Weibull distribution (parameters lambda rho given input x data, model coefficients beta censoring rate censoring comes exponential distribution parameter cens.rate.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"dataCox(n, lambda, rho, x, beta, cens.rate)"},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"n Number observations generate. lambda lambda parameter Weibull distribution. rho rho parameter Weibull distribution. x data.frame input data generate survival times . beta True model coefficients. cens.rate Parameter exponential distribution, responsible censoring.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"data.frame containing columns: id integer. time survival times. status observation status (event occured (1) (0)). x data.frame input data generate survival times .","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"observation true survival time generated censroing time. censoring time less survival time, survival time returned status observations set 0 means observation censored time. survival time less censoring time, observation true survival time returned status observation set 1 means event noticed.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"http://onlinelibrary.wiley.com/doi/10.1002/sim.2059/abstract Generating survival times simulate Cox proportional hazards models, 2005 Ralf Bender, Thomas Augustin, Maria Blettner.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"# \\donttest{ x <- matrix(sample(0:1, size = 20000, replace = TRUE), ncol = 2) dCox <- dataCox(10^4, lambda = 3, rho = 2, x, beta = c(1,3), cens.rate = 5)  # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/gd_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","title":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","text":"Extract Diagnostics big_pls_cox_gd Model","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/gd_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","text":"","code":"gd_diagnostics(object)"},{"path":"https://fbertran.github.io/bigPLScox/reference/gd_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","text":"object model returned big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/gd_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","text":"list log-likelihood, step sizes, gradient norms.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/gd_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Diagnostics from a big_pls_cox_gd Model — gd_diagnostics","text":"","code":"library(bigmemory) set.seed(1) n <- 50 p <- 10 X <- bigmemory::as.big.matrix(matrix(rnorm(n * p), n, p)) time <- rexp(n, rate = 0.1) status <- rbinom(n, 1, 0.7) fit <- big_pls_cox_gd(X, time, status, ncomp = 3, max_iter = 200) str(fit) #> List of 18 #>  $ coefficients  : num [1:3] 0.593 0.165 0.314 #>  $ loglik        : num -104 #>  $ iterations    : int 200 #>  $ converged     : logi TRUE #>  $ scores        : num [1:50, 1:3] 0.0513 1.555 -1.1934 0.7405 -1.9847 ... #>  $ loadings      : num [1:10, 1:3] 0.3689 -0.0474 0.5673 0.1476 0.4647 ... #>  $ weights       : num [1:10, 1:3] 0.5334 -0.1685 0.4853 0.0962 0.3655 ... #>  $ center        : num [1:10] 0.1004 0.1173 -0.1525 0.0769 -0.0313 ... #>  $ scale         : num [1:10] 0.831 0.969 0.9 1.009 1.095 ... #>  $ keepX         : int [1:3] 0 0 0 #>  $ time          : num [1:50] 0.6162 3.6972 12.2628 0.271 0.0901 ... #>  $ status        : num [1:50] 1 1 0 1 0 1 1 1 1 1 ... #>  $ loglik_trace  : num [1:34] -107 -106 -105 -105 -105 ... #>  $ gradnorm_trace: num [1:34] 19.64 13.12 9.08 6.5 4.8 ... #>  $ step_trace    : num [1:34] 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 ... #>  $ coef_trace    :List of 34 #>   ..$ : num [1:3] 0.1642 0.0805 0.0716 #>   ..$ : num [1:3] 0.277 0.127 0.121 #>   ..$ : num [1:3] 0.356 0.153 0.156 #>   ..$ : num [1:3] 0.413 0.167 0.184 #>   ..$ : num [1:3] 0.455 0.174 0.207 #>   ..$ : num [1:3] 0.486 0.177 0.225 #>   ..$ : num [1:3] 0.51 0.177 0.24 #>   ..$ : num [1:3] 0.528 0.177 0.253 #>   ..$ : num [1:3] 0.541 0.176 0.263 #>   ..$ : num [1:3] 0.552 0.175 0.272 #>   ..$ : num [1:3] 0.56 0.174 0.279 #>   ..$ : num [1:3] 0.567 0.172 0.285 #>   ..$ : num [1:3] 0.572 0.171 0.29 #>   ..$ : num [1:3] 0.576 0.17 0.295 #>   ..$ : num [1:3] 0.579 0.17 0.298 #>   ..$ : num [1:3] 0.582 0.169 0.301 #>   ..$ : num [1:3] 0.584 0.168 0.303 #>   ..$ : num [1:3] 0.586 0.168 0.305 #>   ..$ : num [1:3] 0.587 0.167 0.307 #>   ..$ : num [1:3] 0.588 0.167 0.308 #>   ..$ : num [1:3] 0.589 0.167 0.309 #>   ..$ : num [1:3] 0.59 0.166 0.31 #>   ..$ : num [1:3] 0.59 0.166 0.311 #>   ..$ : num [1:3] 0.591 0.166 0.311 #>   ..$ : num [1:3] 0.591 0.166 0.312 #>   ..$ : num [1:3] 0.592 0.166 0.312 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.166 0.313 #>   ..$ : num [1:3] 0.592 0.165 0.313 #>   ..$ : num [1:3] 0.592 0.165 0.314 #>   ..$ : num [1:3] 0.593 0.165 0.314 #>   ..$ : num [1:3] 0.593 0.165 0.314 #>  $ eta_trace     :List of 34 #>   ..$ : num [1:50] -0.1661 0.1968 0.2283 0.0614 0.3025 ... #>   ..$ : num [1:50] -0.268 0.324 0.354 0.105 0.503 ... #>   ..$ : num [1:50] -0.326 0.406 0.414 0.138 0.64 ... #>   ..$ : num [1:50] -0.358 0.458 0.435 0.163 0.737 ... #>   ..$ : num [1:50] -0.373 0.492 0.434 0.183 0.808 ... #>   ..$ : num [1:50] -0.378 0.514 0.423 0.198 0.861 ... #>   ..$ : num [1:50] -0.377 0.529 0.407 0.21 0.902 ... #>   ..$ : num [1:50] -0.373 0.537 0.389 0.219 0.933 ... #>   ..$ : num [1:50] -0.367 0.543 0.371 0.226 0.958 ... #>   ..$ : num [1:50] -0.361 0.546 0.355 0.232 0.977 ... #>   ..$ : num [1:50] -0.355 0.548 0.341 0.236 0.992 ... #>   ..$ : num [1:50] -0.35 0.55 0.328 0.24 1.005 ... #>   ..$ : num [1:50] -0.345 0.55 0.317 0.243 1.015 ... #>   ..$ : num [1:50] -0.34 0.55 0.307 0.245 1.023 ... #>   ..$ : num [1:50] -0.337 0.55 0.299 0.247 1.029 ... #>   ..$ : num [1:50] -0.333 0.55 0.293 0.249 1.035 ... #>   ..$ : num [1:50] -0.33 0.55 0.287 0.25 1.039 ... #>   ..$ : num [1:50] -0.328 0.55 0.282 0.251 1.042 ... #>   ..$ : num [1:50] -0.326 0.549 0.278 0.252 1.045 ... #>   ..$ : num [1:50] -0.324 0.549 0.275 0.252 1.047 ... #>   ..$ : num [1:50] -0.323 0.549 0.272 0.253 1.049 ... #>   ..$ : num [1:50] -0.322 0.549 0.27 0.253 1.051 ... #>   ..$ : num [1:50] -0.321 0.549 0.268 0.254 1.052 ... #>   ..$ : num [1:50] -0.32 0.548 0.267 0.254 1.053 ... #>   ..$ : num [1:50] -0.319 0.548 0.266 0.254 1.054 ... #>   ..$ : num [1:50] -0.319 0.548 0.265 0.255 1.055 ... #>   ..$ : num [1:50] -0.318 0.548 0.264 0.255 1.055 ... #>   ..$ : num [1:50] -0.318 0.548 0.263 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.056 ... #>   ..$ : num [1:50] -0.317 0.548 0.262 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>   ..$ : num [1:50] -0.317 0.548 0.261 0.255 1.057 ... #>  $ cox_fit       :List of 19 #>   ..$ coefficients     : Named num [1:3] 0.376 -0.323 -0.199 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ var              : num [1:3, 1:3] 0.03725 -0.00601 0.00358 -0.00601 0.0223 ... #>   ..$ loglik           : num [1:2] -110 -106 #>   ..$ score            : num 7.83 #>   ..$ iter             : int 4 #>   ..$ linear.predictors: num [1:50] -0.399 0.338 -1.056 1.072 -0.37 ... #>   ..$ residuals        : Named num [1:50] 0.938 0.4757 -0.2709 0.899 -0.0117 ... #>   .. ..- attr(*, \"names\")= chr [1:50] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : Named num [1:3] 4.44e-18 1.02e-16 8.88e-18 #>   .. ..- attr(*, \"names\")= chr [1:3] \"fit$scores1\" \"fit$scores2\" \"fit$scores3\" #>   ..$ method           : chr \"efron\" #>   ..$ n                : int 50 #>   ..$ nevent           : num 37 #>   ..$ terms            :Classes 'terms', 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \"variables\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1 #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   .. .. .. .. ..$ : chr \"fit$scores\" #>   .. .. ..- attr(*, \"term.labels\")= chr \"fit$scores\" #>   .. .. ..- attr(*, \"specials\")=Dotted pair list of 5 #>   .. .. .. ..$ strata : NULL #>   .. .. .. ..$ tt     : NULL #>   .. .. .. ..$ frailty: NULL #>   .. .. .. ..$ ridge  : NULL #>   .. .. .. ..$ pspline: NULL #>   .. .. ..- attr(*, \"order\")= int 1 #>   .. .. ..- attr(*, \"intercept\")= num 1 #>   .. .. ..- attr(*, \"response\")= int 1 #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x15729f040>  #>   .. .. ..- attr(*, \"predvars\")= language list(survival::Surv(time, status), fit$scores) #>   .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"nmatrix.2\" \"nmatrix.3\" #>   .. .. .. ..- attr(*, \"names\")= chr [1:2] \"survival::Surv(time, status)\" \"fit$scores\" #>   ..$ assign           :List of 1 #>   .. ..$ fit$scores: int [1:3] 1 2 3 #>   ..$ wald.test        : num 7.52 #>   ..$ concordance      : Named num [1:7] 589 313 0 0 0 ... #>   .. ..- attr(*, \"names\")= chr [1:7] \"concordant\" \"discordant\" \"tied.x\" \"tied.y\" ... #>   ..$ y                : 'Surv' num [1:50, 1:2]  0.6162   3.6972  12.2628+  0.2710   0.0901+  1.5697   6.7861   3.0889   0.5886   2.0551  ... #>   .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. ..$ : chr [1:50] \"1\" \"2\" \"3\" \"4\" ... #>   .. .. ..$ : chr [1:2] \"time\" \"status\" #>   .. ..- attr(*, \"type\")= chr \"right\" #>   ..$ timefix          : logi TRUE #>   ..$ formula          :Class 'formula'  language survival::Surv(time, status) ~ fit$scores #>   .. .. ..- attr(*, \".Environment\")=<environment: 0x15729f040>  #>   ..$ call             : language survival::coxph(formula = survival::Surv(time, status) ~ fit$scores, ties = \"efron\",      x = FALSE) #>   ..- attr(*, \"class\")= chr \"coxph\" #>  - attr(*, \"class\")= chr \"big_pls_cox_gd\" head(fit$scores) #>             [,1]       [,2]       [,3] #> [1,]  0.05129539  0.7550799  0.8793004 #> [2,]  1.55497806  0.3715325  0.6353775 #> [3,] -1.19340964  0.4907382  2.2626350 #> [4,]  0.74046728 -2.1053220 -0.5759915 #> [5,] -1.98468237 -0.8043244 -0.5814998 #> [6,]  0.42019957  1.5593684  0.5762548 gd_diagnostics(fit) #> $iterations #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #> [26] 26 27 28 29 30 31 32 33 34 #>  #> $loglik #>  [1] -107.4934 -106.0417 -105.3363 -104.9694 -104.7673 -104.6505 -104.5806 #>  [8] -104.5376 -104.5105 -104.4932 -104.4820 -104.4747 -104.4699 -104.4667 #> [15] -104.4646 -104.4632 -104.4623 -104.4617 -104.4612 -104.4610 -104.4608 #> [22] -104.4607 -104.4606 -104.4605 -104.4605 -104.4605 -104.4604 -104.4604 #> [29] -104.4604 -104.4604 -104.4604 -104.4604 -104.4604 -104.4604 #>  #> $step_sizes #>  [1] 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 #> [16] 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 #> [31] 0.01 0.01 0.01 0.01 #>  #> $gradient_norm #>  [1] 19.63944657 13.11786163  9.07850891  6.50457374  4.80243720  3.63347855 #>  [7]  2.80236962  2.19350938  1.73626282  1.38595625  1.11333127  0.89856489 #> [13]  0.72779353  0.59103873  0.48093518  0.39192874  0.31975620  0.26109807 #> [19]  0.21334004  0.17440475  0.14263008  0.11667896  0.09547146  0.07813253 #> [25]  0.06395148  0.05234997  0.04285675  0.03508740  0.02872806  0.02352228 #> [31]  0.01926048  0.01577125  0.01291441  0.01057524 #>  #> $coef_trace #> $coef_trace[[1]] #> [1] 0.16421316 0.08047458 0.07161472 #>  #> $coef_trace[[2]] #> [1] 0.2765372 0.1273370 0.1205539 #>  #> $coef_trace[[3]] #> [1] 0.3557522 0.1533339 0.1564856 #>  #> $coef_trace[[4]] #> [1] 0.4129008 0.1670958 0.1843350 #>  #> $coef_trace[[5]] #> [1] 0.4548639 0.1738622 0.2066881 #>  #> $coef_trace[[6]] #> [1] 0.4861190 0.1767049 0.2249980 #>  #> $coef_trace[[7]] #> [1] 0.5096775 0.1774018 0.2401584 #>  #> $coef_trace[[8]] #> [1] 0.5276170 0.1769738 0.2527735 #>  #> $coef_trace[[9]] #> [1] 0.5413997 0.1760027 0.2632879 #>  #> $coef_trace[[10]] #> [1] 0.5520722 0.1748156 0.2720502 #>  #> $coef_trace[[11]] #> [1] 0.5603937 0.1735920 0.2793444 #>  #> $coef_trace[[12]] #> [1] 0.5669221 0.1724262 0.2854077 #>  #> $coef_trace[[13]] #> [1] 0.5720717 0.1713632 0.2904396 #>  #> $coef_trace[[14]] #> [1] 0.5761532 0.1704203 0.2946091 #>  #> $coef_trace[[15]] #> [1] 0.5794018 0.1695992 0.2980590 #>  #> $coef_trace[[16]] #> [1] 0.5819973 0.1688933 0.3009097 #>  #> $coef_trace[[17]] #> [1] 0.5840776 0.1682923 0.3032625 #>  #> $coef_trace[[18]] #> [1] 0.5857497 0.1677842 0.3052023 #>  #> $coef_trace[[19]] #> [1] 0.5870972 0.1673571 0.3068002 #>  #> $coef_trace[[20]] #> [1] 0.5881853 0.1669996 0.3081155 #>  #> $coef_trace[[21]] #> [1] 0.5890657 0.1667014 0.3091973 #>  #> $coef_trace[[22]] #> [1] 0.5897791 0.1664535 0.3100866 #>  #> $coef_trace[[23]] #> [1] 0.5903581 0.1662477 0.3108173 #>  #> $coef_trace[[24]] #> [1] 0.5908286 0.1660774 0.3114174 #>  #> $coef_trace[[25]] #> [1] 0.5912113 0.1659366 0.3119101 #>  #> $coef_trace[[26]] #> [1] 0.5915228 0.1658203 0.3123144 #>  #> $coef_trace[[27]] #> [1] 0.5917767 0.1657245 0.3126461 #>  #> $coef_trace[[28]] #> [1] 0.5919836 0.1656455 0.3129182 #>  #> $coef_trace[[29]] #> [1] 0.5921525 0.1655805 0.3131413 #>  #> $coef_trace[[30]] #> [1] 0.5922903 0.1655270 0.3133243 #>  #> $coef_trace[[31]] #> [1] 0.5924029 0.1654831 0.3134743 #>  #> $coef_trace[[32]] #> [1] 0.5924948 0.1654470 0.3135972 #>  #> $coef_trace[[33]] #> [1] 0.5925700 0.1654173 0.3136980 #>  #> $coef_trace[[34]] #> [1] 0.5926314 0.1653930 0.3137806 #>  #>  #> $eta_trace #> $eta_trace[[1]] #>  [1] -0.166115322  0.196759266  0.228348102  0.061369147  0.302494016 #>  [6] -0.152281413  0.075280736 -0.024216386  0.095666552 -0.599992756 #> [11] -0.012646621  0.073557107 -0.085061215  0.434738180  0.043161018 #> [16]  0.005556341 -0.113198975  0.030816465  0.022368047 -0.312071792 #> [21]  0.297205125  0.188253141  0.219700345  0.295935488  0.202914257 #> [26] -0.291756313 -0.111514708 -0.102162451 -0.065754548  0.330749155 #> [31] -0.029895907 -0.009991695 -0.292704956  0.145662414 -0.031905221 #> [36]  0.115709160  0.235760133 -0.022576559 -0.051750505 -0.125440259 #> [41]  0.046968082 -0.247416540 -0.074575125  0.132158958  0.114966412 #> [46]  0.101365930 -0.089079893 -0.237144550 -0.432282562 -0.315927307 #>  #> $eta_trace[[2]] #>  [1] -0.267665643  0.323769051  0.353900620  0.105426920  0.502685269 #>  [6] -0.259470830  0.129131413 -0.030356682  0.155955318 -1.009008857 #> [11] -0.013535185  0.112062111 -0.135577406  0.717123339  0.070788388 #> [16]  0.005236327 -0.180084204  0.056231263  0.030449233 -0.535184303 #> [21]  0.486637099  0.316135289  0.357530434  0.493507773  0.348983206 #> [26] -0.502610097 -0.184584765 -0.167662517 -0.094292728  0.553916398 #> [31] -0.037255577 -0.011594425 -0.476221190  0.248936644 -0.053606320 #> [36]  0.185499442  0.384235908 -0.036565443 -0.089680864 -0.203624016 #> [41]  0.075668322 -0.412954363 -0.106199912  0.216337773  0.186811404 #> [46]  0.171347416 -0.132756665 -0.402833847 -0.721360903 -0.523619618 #>  #> $eta_trace[[3]] #>  [1] -0.326314794  0.405602779  0.413563582  0.138341501  0.639847800 #>  [6] -0.339290369  0.168886914 -0.025646470  0.192784649 -1.298951789 #> [11] -0.006739947  0.129919622 -0.162567971  0.902021303  0.089868444 #> [16]  0.004758411 -0.218329825  0.079394234  0.030515520 -0.703238897 #> [21]  0.608861345  0.405194446  0.446609343  0.631653772  0.459008946 #> [26] -0.661919524 -0.235308043 -0.207540330 -0.099916825  0.709582779 #> [31] -0.030802472 -0.009355378 -0.593744997  0.324940931 -0.068161929 #> [36]  0.225770764  0.478766512 -0.043693885 -0.117573462 -0.253132055 #> [41]  0.093105790 -0.527316216 -0.113258415  0.271625606  0.230620373 #> [46]  0.219311676 -0.149528730 -0.523032714 -0.920381608 -0.664810395 #>  #> $eta_trace[[4]] #>  [1] -0.357823027  0.458396456  0.434590600  0.163424583  0.737076977 #>  [6] -0.400890972  0.198666385 -0.015811002  0.214534739 -1.510882759 #> [11]  0.003881279  0.136776271 -0.174641995  1.024476260  0.104126066 #> [16]  0.006323391 -0.239706004  0.100766107  0.026947455 -0.833574565 #> [21]  0.689351985  0.468415587  0.506770511  0.732369728  0.543822605 #> [26] -0.784918902 -0.272567556 -0.230230232 -0.093493971  0.821255552 #> [31] -0.017673147 -0.006075635 -0.671683913  0.382041353 -0.077725547 #> [36]  0.247929306  0.540288602 -0.045959144 -0.137847259 -0.285455393 #> [41]  0.103796185 -0.608645298 -0.108482433  0.309436456  0.256733976 #> [46]  0.251699558 -0.152226338 -0.612341742 -1.061066960 -0.764174179 #>  #> $eta_trace[[5]] #>  [1] -0.372654066  0.492476379  0.434264600  0.182758098  0.808064162 #>  [6] -0.449490677  0.221160226 -0.004260495  0.226754358 -1.669475008 #> [11]  0.015813410  0.138152421 -0.177705210  1.106514085  0.115443384 #> [16]  0.010141557 -0.251314688  0.120210001  0.022157957 -0.936367423 #> [21]  0.743557565  0.513995333  0.549300400  0.808289609  0.610049432 #> [26] -0.881000453 -0.301197023 -0.241754027 -0.081628627  0.903223727 #> [31] -0.002213311 -0.003035225 -0.725385950  0.425500565 -0.083849740 #> [36]  0.259216641  0.581353754 -0.045072162 -0.152396217 -0.307315629 #> [41]  0.110445705 -0.667917478 -0.098993946  0.336353147  0.271812849 #> [46]  0.273178978 -0.148274593 -0.679801351 -1.162790937 -0.836294110 #>  #> $eta_trace[[6]] #>  [1] -0.3775185962  0.5144383510  0.4229545252  0.1977747652  0.8611655465 #>  [6] -0.4883576679  0.2382559989  0.0072069232  0.2330371625 -1.7903082760 #> [11]  0.0276256412  0.1370161504 -0.1756008009  1.1620587948  0.1247752021 #> [16]  0.0156652470 -0.2573170716  0.1375812685  0.0173276918 -1.0182646941 #> [21]  0.7808697076  0.5472879071  0.5806240007  0.8669680332  0.6621845016 #> [26] -0.9566044922 -0.3239045648 -0.2462458561 -0.0679928163  0.9645146288 #> [31]  0.0132323961 -0.0006736213 -0.7637612793  0.4588877564 -0.0876400964 #> [36]  0.2640971199  0.6094712818 -0.0423178431 -0.1627194083 -0.3226264983 #> [41]  0.1146506489 -0.7119969207 -0.0883998972  0.3562028737  0.2800677170 #> [46]  0.2871176570 -0.1416625820 -0.7313833258 -1.2377561210 -0.8900070687 #>  #> $eta_trace[[7]] #>  [1] -0.376649008  0.528519652  0.406693907  0.209508632  0.901664326 #>  [6] -0.519705325  0.251320611  0.017746070  0.235689303 -1.883660228 #> [11]  0.038587867  0.134897791 -0.170757827  1.200022628  0.132627439 #> [16]  0.022194612 -0.260130952  0.152850573  0.012963077 -1.083942154 #> [21]  0.807083822  0.571883696  0.604476707  0.913145930  0.703465247 #> [26] -1.016410666 -0.342288043 -0.246475209 -0.054495725  1.011039115 #> [31]  0.027527916  0.000962334 -0.792073249  0.484729659 -0.089872187 #> [36]  0.265293418  0.629193467 -0.038592928 -0.169972990 -0.333698804 #> [41]  0.117355371 -0.745324279 -0.078360356  0.371268022  0.284147781 #> [46]  0.295913202 -0.134417604 -0.771206840 -1.293888604 -0.930849194 #>  #> $eta_trace[[8]] #>  [1] -0.372681440  0.537462480  0.388895068  0.218724863  0.933023369 #>  [6] -0.545124372  0.261358092  0.027034935  0.236181969 -1.956566128 #> [11]  0.048385610  0.132550237 -0.164674931  1.226188102  0.139292330 #> [16]  0.029118704 -0.261158563  0.166095153  0.009227972 -1.136849613 #> [21]  0.825845973  0.590240116  0.623103641  0.949949738  0.736301908 #> [26] -1.063923875 -0.357354618 -0.244261865 -0.042044594  1.046790937 #> [31]  0.040215137  0.001980118 -0.813515295  0.504860404 -0.091082812 #> [36]  0.264455761  0.643333707 -0.034490727 -0.175025891 -0.341928540 #> [41]  0.119124272 -0.770864190 -0.069523291  0.382957490  0.285717763 #> [46]  0.301250460 -0.127499082 -0.802198218 -1.336484194 -0.962414074 #>  #> $eta_trace[[9]] #>  [1] -0.367234026  0.543053569  0.371412942  0.225997568  0.957592122 #>  [6] -0.565807462  0.269111133  0.035022118  0.235447292 -2.013991849 #> [11]  0.056937528  0.130317921 -0.158250709  1.244356265  0.144960811 #> [16]  0.035984004 -0.261212690  0.177462671  0.006125004 -1.179609853 #> [21]  0.839498539  0.604067072  0.637912681  0.979540188  0.762523034 #> [26] -1.101812252 -0.369786509 -0.240778409 -0.030998261  1.074542658 #> [31]  0.051195687  0.002527239 -0.830090131  0.520632418 -0.091638900 #> [36]  0.262576940  0.653669888 -0.030384072 -0.178517789 -0.348183722 #> [41]  0.120299344 -0.790652646 -0.062040499  0.392176564  0.285821899 #> [46]  0.304299362 -0.121305123 -0.826480343 -1.369171641 -0.987117580 #>  #> $eta_trace[[10]] #>  [1] -0.361279062  0.546463421  0.355188727  0.231761319  0.977015917 #>  [6] -0.582675137  0.275131547  0.041785668  0.234069794 -2.059532425 #> [11]  0.064285470  0.128337128 -0.152001864  1.257055579  0.149774775 #> [16]  0.042490602 -0.260763446  0.187137738  0.003589766 -1.214255310 #> [21]  0.849578736  0.614570815  0.649830494  1.003473666  0.783532100 #> [26] -1.132126681 -0.380078171 -0.236762636 -0.021427249  1.096264367 #> [31]  0.060549503  0.002742264 -0.843101395  0.533053902 -0.091788127 #> [36]  0.260246764  0.661352574 -0.026492622 -0.180912125 -0.353022176 #> [41]  0.121091128 -0.806123263 -0.055840110  0.399532288  0.285112216 #> [46]  0.305863120 -0.115950228 -0.845617643 -1.394493481 -1.006638239 #>  #> $eta_trace[[11]] #>  [1] -0.355381172  0.548461653  0.340635194  0.236347269  0.992479715 #>  [6] -0.596451914  0.279830915  0.047457110  0.232410087 -2.095845192 #> [11]  0.070530553  0.126642426 -0.146205141  1.265985951  0.153850505 #> [16]  0.048463400 -0.260081023  0.195317593  0.001537297 -1.242380964 #> [21]  0.857116643  0.622612507  0.659498145  1.022910307  0.800415130 #> [26] -1.156454278 -0.388608236 -0.232663827 -0.013259321  1.113384129 #> [31]  0.068434952  0.002737960 -0.853431249  0.542882956 -0.091695391 #> [36]  0.257807939  0.667144607 -0.022933273 -0.182540512 -0.356815205 #> [41]  0.121631455 -0.818307749 -0.050764768  0.405449081  0.283992069 #> [46]  0.306486907 -0.111413828 -0.860777571 -1.414266479 -1.022177361 #>  #> $eta_trace[[12]] #>  [1] -0.3498495395  0.5495551463  0.3278661540  0.2400092490  1.0048575906 #>  [6] -0.6077155155  0.2835174947  0.0521821877  0.2306849514 -2.1249282394 #> [11]  0.0757971027  0.1252219766 -0.1409889630  1.2723010130  0.1572886842 #> [16]  0.0538191504 -0.2593185176  0.2021964184 -0.0001165843 -1.2652495708 #> [21]  0.8628163353  0.6288135676  0.6673800236  1.0387383746  0.8140179503 #> [26] -1.1760300924 -0.3956782324 -0.2287422936 -0.0063591567  1.1269549388 #> [31]  0.0750357363  0.0025990384 -0.8616994389  0.5506939329 -0.0914687126 #> [36]  0.2554518764  0.6715638684 -0.0197562475 -0.1836379381 -0.3598187418 #> [41]  0.1220043156 -0.8279626890 -0.0466381161  0.4102350833  0.2827068883 #> [46]  0.3065362226 -0.1076177275 -0.8728406036 -1.4298113363 -1.0346170145 #>  #> $eta_trace[[13]] #>  [1] -0.3448352154  0.5500775706  0.3168325627  0.2429429274  1.0148072458 #>  [6] -0.6169306475  0.2864232401  0.0561017526  0.2290192801 -2.1483052203 #> [11]  0.0802130181  0.1240454843 -0.1363922524  1.2767901370  0.1601784336 #> [16]  0.0585374432 -0.2585602579  0.2079561795 -0.0014467156 -1.2838673761 #> [21]  0.8671680050  0.6336268612  0.6738257795  1.0516517512  0.8250030249 #> [26] -1.1918200592 -0.4015343344 -0.2251365242 -0.0005708291  1.1377646610 #> [31]  0.0805339956  0.0023856797 -0.8683562472  0.5569250356 -0.0911774284 #> [36]  0.2532778544  0.6749698676 -0.0169701615 -0.1843696227 -0.3622150193 #> [41]  0.1222641287 -0.8356519299 -0.0432941775  0.4141212142  0.2814018927 #> [46]  0.3062526674 -0.1044651550 -0.8824769610 -1.4421027023 -1.0446188572 #>  #> $eta_trace[[14]] #>  [1] -0.340393264  0.550247909  0.307402761  0.245299973  1.022831643 #>  [6] -0.624473311  0.288723604  0.059343415  0.227479829 -2.167151531 #> [11]  0.083899661  0.123077763 -0.132401948  1.279997362  0.162598915 #> [16]  0.062637958 -0.257850190  0.212761948 -0.002516182 -1.299040234 #> [21]  0.870518715  0.637385492  0.679106598  1.062200394  0.833891866 #> [26] -1.204583263 -0.406380390 -0.221908095  0.004260472  1.146410216 #> [31]  0.085097753  0.002138690 -0.873738229  0.561912833 -0.090864844 #> [36]  0.251329687  0.677617312 -0.014559008 -0.184850982 -0.364137542 #> [41]  0.122446718 -0.841801493 -0.040588237  0.417284890  0.280158995 #> [46]  0.305793203 -0.101859465 -0.890201070 -1.451869376 -1.052687918 #>  #> $eta_trace[[15]] #>  [1] -0.336522331  0.550209020  0.299409273  0.247198590  1.029320435 #>  [6] -0.630648946  0.290552048  0.062018770  0.226097144 -2.182382620 #> [11]  0.086967164  0.122284897 -0.128976707  1.282300032  0.164620080 #> [16]  0.066163822 -0.257208681  0.216760129 -0.003376667 -1.311416081 #> [21]  0.873117935  0.640336636  0.683437330  1.070824673  0.841096961 #> [26] -1.214918962 -0.410386389 -0.219071440  0.008278105  1.153348742 #> [31]  0.088876026  0.001884474 -0.878102693  0.565917495 -0.090556956 #> [36]  0.249618515  0.679689973 -0.012493398 -0.185162195 -0.365686466 #> [41]  0.122576005 -0.846737043 -0.038398987  0.419864998  0.279020483 #> [46]  0.305257526 -0.099712286 -0.896410753 -1.459662622 -1.059215060 #>  #> $eta_trace[[16]] #>  [1] -0.333189667  0.550053199  0.292675547  0.248731390  1.034578628 #>  [6] -0.635706346  0.292010694  0.064223383  0.224879761 -2.194717148 #> [11]  0.089512770  0.121636687 -0.126061669  1.283961352  0.166303217 #> [16]  0.069170058 -0.256642517  0.220078466 -0.004069856 -1.321517563 #> [21]  0.875147427  0.642665251  0.686990665  1.077879721  0.846945982 #> [26] -1.223302282 -0.413694466 -0.216613361  0.011609803  1.158933572 #> [31]  0.091997895  0.001639181 -0.881649805  0.569141362 -0.090268416 #> [36]  0.248136957  0.681322580 -0.010737802 -0.185358671 -0.366938370 #> [41]  0.122668174 -0.850710006 -0.036626897  0.421971746  0.278004246 #> [46]  0.304707005 -0.097946351 -0.901415763 -1.465903636 -1.064506126 #>  #> $eta_trace[[17]] #>  [1] -0.330346788  0.549839199  0.287030670  0.249971294  1.038846941 #>  [6] -0.639848545  0.293178146  0.066038025  0.223823366 -2.204723018 #> [11]  0.091620802  0.121107310 -0.123597447  1.285165850  0.167701551 #> [16]  0.071715933 -0.256150890  0.222827065 -0.004629097 -1.329767372 #> [21]  0.876741234  0.644510845  0.689906706  1.083653341  0.851700250 #> [26] -1.230111438 -0.416423489 -0.214505650  0.014366733  1.163439982 #> [31]  0.094573505  0.001411912 -0.884537315  0.571742708 -0.090006580 #> [36]  0.246867849  0.682615292 -0.009255074 -0.185478517 -0.367952689 #> [41]  0.122734289 -0.853916137 -0.035191261  0.423693425  0.277113545 #> [46]  0.304177665 -0.096495780 -0.905458764 -1.470917077 -1.068802505 #>  #> $eta_trace[[18]] #>  [1] -0.327939072  0.549603603  0.282316899  0.250975984  1.042316599 #>  [6] -0.643241445  0.294115265  0.067530389  0.222916629 -2.212851478 #> [11]  0.093363473  0.120675169 -0.121525414  1.286043503  0.168860908 #> [16]  0.073860143 -0.255728978  0.225099943 -0.005080972 -1.336508107 #> [21]  0.877999279  0.645979447  0.692299780  1.088379549  0.855568914 #> [26] -1.235648599 -0.418672764 -0.212713081  0.016644179  1.167083911 #> [31]  0.096695908  0.001207077 -0.886890735  0.573845993 -0.089774216 #> [36]  0.245789584  0.683643471 -0.008009141 -0.185547794 -0.368776076 #> [41]  0.122781994 -0.856508941 -0.034027025  0.425101244  0.276343257 #> [46]  0.303689041 -0.095305230 -0.908730922 -1.474955131 -1.072296014 #>  #> $eta_trace[[19]] #>  [1] -0.325911480  0.549368434  0.278392951  0.251791287  1.045140311 #>  [6] -0.646020725  0.294869438  0.068756881  0.222144883 -2.219462732 #> [11]  0.094802068  0.120322426 -0.119790630  1.286686260  0.169820448 #> [16]  0.075657983 -0.255370072  0.226976796 -0.005446645 -1.342017945 #> [21]  0.878996781  0.647152219  0.694263502  1.092249067  0.858719891 #> [26] -1.240155978 -0.420525109 -0.211198351  0.018522969  1.170035747 #> [31]  0.098443179  0.001026082 -0.888810626  0.575549566 -0.089571320 #> [36]  0.244879304  0.684464416 -0.006966498 -0.185584226 -0.369445479 #> [41]  0.122816609 -0.858609529 -0.033081893  0.426252891  0.275683824 #> [46]  0.303250146 -0.094328624 -0.911383579 -1.478215018 -1.075139900 #>  #> $eta_trace[[20]] #>  [1] -0.3242117879  0.5491462372  0.2751348161  0.2524537480  1.0474405438 #>  [6] -0.6482974189  0.2954777607  0.0697643257  0.2214923712 -2.2248454279 #> [11]  0.0959882478  0.1200344539 -0.1183432830  1.2871594447  0.1706134240 #> [16]  0.0771598589 -0.2550668264  0.2285247876 -0.0057429827 -1.3465230939 #> [21]  0.8797908537  0.6480917072  0.6958746766  1.0954175749  0.8612883735 #> [26] -1.2438282916 -0.4220494640 -0.2099250089  0.0200711637  1.1724306269 #> [31]  0.0998804946  0.0008684911 -0.8903779653  0.5769314887 -0.0893962955 #> [36]  0.2441147360  0.6851220914 -0.0060969229 -0.1855997788 -0.3699903493 #> [41]  0.1228418628 -0.8603139578 -0.0323138517  0.4271952583  0.2751237141 #> [46]  0.3028634696 -0.0935278110 -0.9135370757 -1.4808518898 -1.0774571199 #>  #> $eta_trace[[21]] #>  [1] -0.3227922546  0.5489434848  0.2724352080  0.2529926108  1.0493158459 #>  [6] -0.6501624274  0.2959694190  0.0705914795  0.2209435886 -2.2292316249 #> [11]  0.0969653374  0.1197993031 -0.1171392186  1.2875096539  0.1712679099 #> [16]  0.0784106728 -0.2548119706  0.2298002556 -0.0059834439 -1.3502077237 #> [21]  0.8804252143  0.6488464168  0.6971963808  1.0980122849  0.8633834661 #> [26] -1.2468224797 -0.4233031042 -0.2088590723  0.0213457647  1.1743761990 #> [31]  0.1010620748  0.0007328152 -0.8916582087  0.5780539643 -0.0892467212 #> [36]  0.2434751813  0.6856504977 -0.0053737133 -0.1856024615 -0.3704342878 #> [41]  0.1228603882 -0.8616987531 -0.0316891271  0.4279665385  0.2746509134 #> [46]  0.3025276284 -0.0928713193 -0.9152874756 -1.4829884386 -1.0793466717 #>  #> $eta_trace[[22]] #>  [1] -0.3216103117  0.5487628290  0.2702022883  0.2534313507  1.0508457439 #>  [6] -0.6516901903  0.2963674798  0.0712703603  0.2204840199 -2.2328084003 #> [11]  0.0977695257  0.1196072311 -0.1161399296  1.2877702597  0.1718075017 #> [16]  0.0794497528 -0.2545986933  0.2308502785 -0.0061787936 -1.3532219297 #> [21]  0.8809335624  0.6494541818  0.6982804396  1.1001372256  0.8650934074 #> [26] -1.2492653163 -0.4243335322 -0.2079698218  0.0223943181  1.1759585422 #> [31]  0.1020328947  0.0006170288 -0.8927044092  0.5789667357 -0.0891198333 #> [36]  0.2429419842  0.6860761129 -0.0047736301 -0.1855975775 -0.3707962800 #> [41]  0.1228740520 -0.8628251151 -0.0311805389  0.4285978894  0.2742537948 #> [46]  0.3022390872 -0.0923332402 -0.9167117233 -1.4847221297 -1.0808884821 #>  #> $eta_trace[[23]] #>  [1] -0.3206286727  0.5486045972  0.2683580778  0.2537888610  1.0520945620 #>  [6] -0.6529416789  0.2966902514  0.0718273772  0.2201005085 -2.2357269207 #> [11]  0.0984309430  0.1194503007 -0.1153122367  1.2879652616  0.1722519528 #> [16]  0.0803111105 -0.2544208257  0.2317140738 -0.0063376602 -1.3556881395 #> [21]  0.8813420467  0.6499446713  0.6991694366  1.1018775100  0.8664896891 #> [26] -1.2512594083 -0.4251800799 -0.2072300731  0.0232563583  1.1772467131 #> [31]  0.1028301832  0.0005189032 -0.8935596581  0.5797097050 -0.0890128208 #> [36]  0.2424986785  0.6864196834 -0.0042766780 -0.1855885875 -0.3710916472 #> [41]  0.1228841854 -0.8637421499 -0.0307661784  0.4291147560  0.2739215889 #> [46]  0.3019932683 -0.0918922770 -0.9178716345 -1.4861306981 -1.0821472292 #>  #> $eta_trace[[24]] #>  [1] -0.3198151030  0.5484677680  0.2668367811  0.2540803841  1.0531144276 #>  [6] -0.6539668388  0.2969523204  0.0722842876  0.2197813906 -2.2381095754 #> [11]  0.0989746108  0.1193220471 -0.1146278148  1.2881119909  0.1726177452 #> [16]  0.0810238715 -0.2542729073  0.2324242268 -0.0064669760 -1.3577062811 #> [21]  0.8816710770  0.6503412660  0.6998983586  1.1033027997  0.8676303247 #> [26] -1.2528879420 -0.4258752674 -0.2066161418  0.0239646759  1.1782962697 #> [31]  0.1034847041  0.0004362099 -0.8942590106  0.5803149688 -0.0889229979 #> [36]  0.2421309489  0.6866975522 -0.0038658041 -0.1855777061 -0.3713327842 #> [41]  0.1228917424 -0.8644893715 -0.0304283580  0.4295379333  0.2736446042 #> [46]  0.3017852414 -0.0915309407 -0.9188170000 -1.4872763580 -1.0831753501 #>  #> $eta_trace[[25]] #>  [1] -0.3191420118  0.5483506029  0.2655831600  0.2543182418  1.0539476521 #>  [6] -0.6548065865  0.2971653474  0.0726590001  0.2195164906 -2.2400556206 #> [11]  0.0994212631  0.1192172033 -0.1140626572  1.2882230174  0.1729185932 #> [16]  0.0816127852 -0.2541501820  0.2330077537 -0.0065723223 -1.3593579642 #> [21]  0.8819366696  0.6506624725  0.7004959447  1.1044701235  0.8685624530 #> [26] -1.2542184564 -0.4264459484 -0.2061076322  0.0245464139  1.1791520192 #> [31]  0.1040218441  0.0003668391 -0.8948310198  0.5808084068 -0.0888478950 #> [36]  0.2418264912  0.6869226552 -0.0035265661 -0.1855663115 -0.3715297385 #> [41]  0.1228974095 -0.8650986526 -0.0301527750  0.4298844253  0.2734142928 #> [46]  0.3016101393 -0.0912348782 -0.9195880153 -1.4882090537 -1.0840154233 #>  #> $eta_trace[[26]] #>  [1] -0.318585966  0.548251045  0.264551026  0.254512413  1.054628625 #>  [6] -0.655494443  0.297338683  0.072966244  0.219297037 -2.241645666 #> [11]  0.099788052  0.119131477 -0.113596534  1.288307498  0.173165882 #> [16]  0.082098753 -0.254048557  0.233487013 -0.006658202 -1.360709869 #> [21]  0.882151454  0.650922998  0.700985796  1.105426176  0.869324420 #> [26] -1.255305854 -0.426914273 -0.205687139  0.025024004  1.179850175 #> [31]  0.104462529  0.000308862 -0.895298965  0.581210930 -0.088785300 #> [36]  0.241574821  0.687105274 -0.003246801 -0.185555227 -0.371690668 #> [41]  0.122901683 -0.865595757 -0.029927846  0.430168142  0.273223226 #> [46]  0.301463393 -0.090992315 -0.920217194 -1.488968985 -1.084702067 #>  #> $eta_trace[[27]] #>  [1] -0.318127187  0.548166965  0.263701883  0.254670992  1.055185328 #>  [6] -0.656057872  0.297479843  0.073218126  0.219115540 -2.242945258 #> [11]  0.100089144  0.119061367 -0.113212479  1.288372134  0.173369043 #> [16]  0.082499337 -0.253964540  0.233880481 -0.006728255 -1.361816499 #> [21]  0.882325432  0.651134574  0.701387290  1.106209197  0.869947451 #> [26] -1.256194814 -0.427298493 -0.205339912  0.025415959  1.180420056 #> [31]  0.104823990  0.000260557 -0.895681841  0.581539465 -0.088733268 #> [36]  0.241367066  0.687253612 -0.003016310 -0.185544910 -0.371822204 #> [41]  0.122904924 -0.866001547 -0.029744178  0.430400464  0.273065017 #> [46]  0.301340850 -0.090793596 -0.920730879 -1.489588585 -1.085263460 #>  #> $eta_trace[[28]] #>  [1] -0.317749061  0.548096309  0.263003735  0.254800551  1.055640552 #>  [6] -0.656519372  0.297594888  0.073424593  0.218965646 -2.244007746 #> [11]  0.100336226  0.119004019 -0.112896311  1.288421855  0.173535879 #> [16]  0.082829238 -0.253895177  0.234203406 -0.006785429 -1.362722418 #> [21]  0.882466556  0.651306586  0.701716330  1.106850500  0.870456992 #> [26] -1.256921728 -0.427613639 -0.205053526  0.025737539  1.180885442 #> [31]  0.105120408  0.000220414 -0.895995155  0.581807735 -0.088690111 #> [36]  0.241195758  0.687374234 -0.002826574 -0.185535585 -0.371929747 #> [41]  0.122907396 -0.866332943 -0.029594143  0.430590707  0.272934227 #> [46]  0.301238821 -0.090630803 -0.921150449 -1.490094069 -1.085722556 #>  #> $eta_trace[[29]] #>  [1] -0.3174376897  0.5480371725  0.2624300446  0.2549064352  1.0560128743 #>  [6] -0.6568973762  0.2976887083  0.0735938123  0.2188420016 -2.2448765942 #> [11]  0.1005389315  0.1189571029 -0.1126362219  1.2884603026  0.1736728335 #> [16]  0.0831007133 -0.2538379774  0.2344683564 -0.0068321123 -1.3634640726 #> [21]  0.8825811743  0.6514465674  0.7019859661  1.1073757328  0.8708737941 #> [26] -1.2575162579 -0.4278720734 -0.2048175562  0.0260013159  1.1812656382 #> [31]  0.1053634432  0.0001871259 -0.8962515750  0.5820268814 -0.0886543831 #> [36]  0.2410546404  0.6874724118 -0.0026705007 -0.1855273291 -0.3720176919 #> [41]  0.1229092908 -0.8666036876 -0.0294715407  0.4307464961  0.2728262488 #> [46]  0.3011540812 -0.0904974483 -0.9214932692 -1.4905066693 -1.0860980711 #>  #> $eta_trace[[30]] #>  [1] -0.3171814854  0.5479878423  0.2619588464  0.2549929957  1.0563174463 #>  [6] -0.6572069854  0.2977652637  0.0737324893  0.2187401140 -2.2455872376 #> [11]  0.1007051899  0.1189187154 -0.1124223972  1.2884901828  0.1737852220 #> [16]  0.0833239620 -0.2537908547  0.2346856867 -0.0068702450 -1.3640712778 #> [21]  0.8826743647  0.6515605767  0.7022069060  1.1078059006  0.8712147914 #> [26] -1.2580026016 -0.4280839648 -0.2046232940  0.0262176316  1.1815763431 #> [31]  0.1055626773  0.0001595721 -0.8964614517  0.5822059610 -0.0886248508 #> [36]  0.2409384879  0.6875523862 -0.0025421954 -0.1855201296 -0.3720896260 #> [41]  0.1229107516 -0.8668249531 -0.0293713258  0.4308740721  0.2727372065 #> [46]  0.3010838465 -0.0903882116 -0.9217734673 -1.4908436028 -1.0864052741 #>  #> $eta_trace[[31]] #>  [1] -0.3169708121  0.5479468060  0.2615719849  0.2550637756  1.0565666350 #>  [6] -0.6574605708  0.2978277612  0.0738461260  0.2186562277 -2.2461685835 #> [11]  0.1008415264  0.1188873026 -0.1122467015  1.2885135163  0.1738774255 #> [16]  0.0835074458 -0.2537520661  0.2348639166 -0.0069014042 -1.3645684272 #> [21]  0.8827502050  0.6516535002  0.7023879312  1.1081582078  0.8714938090 #> [26] -1.2584005065 -0.4282576680 -0.2044634842  0.0263949930  1.1818303306 #> [31]  0.1057259823  0.0001367997 -0.8966332473  0.5823523421 -0.0886004722 #> [36]  0.2408429511  0.6876175785 -0.0024367736 -0.1855139232 -0.3721484738 #> [41]  0.1229118833 -0.8670058330 -0.0292893896  0.4309785459  0.2726638509 #> [46]  0.3010257348 -0.0902987341 -0.9220025435 -1.4911188519 -1.0866566288 #>  #> $eta_trace[[32]] #>  [1] -0.3167976758  0.5479127479  0.2612544750  0.2551216639  1.0567705381 #>  [6] -0.6576682667  0.2978788037  0.0739392364  0.2185872134 -2.2466442273 #> [11]  0.1009533063  0.1188615946 -0.1121024019  1.2885318204  0.1739530511 #> [16]  0.0836581737 -0.2537201603  0.2350100534 -0.0069268725 -1.3649754823 #> [21]  0.8828119761  0.6517292853  0.7025362434  1.1084467453  0.8717221393 #> [26] -1.2587260975 -0.4284000463 -0.2043320987  0.0265403918  1.1820380050 #> [31]  0.1058598219  0.0001180034 -0.8967738810  0.5824720254 -0.0885803706 #> [36]  0.2407644183  0.6876707535 -0.0023501931 -0.1855086207 -0.3721966230 #> [41]  0.1229127645 -0.8671537343 -0.0292223836  0.4310641017  0.2726034685 #> [46]  0.3009777243 -0.0902254438 -0.9221898679 -1.4913437843 -1.0868623138 #>  #> $eta_trace[[33]] #>  [1] -0.3166554568  0.5478845364  0.2609939615  0.2551690171  1.0569374042 #>  [6] -0.6578383750  0.2979205059  0.0740155229  0.2185304706 -2.2470334377 #> [11]  0.1010449385  0.1188405534 -0.1119839345  1.2885462402  0.1740150665 #> [16]  0.0837819409 -0.2536939321  0.2351298564 -0.0069476948 -1.3653087798 #> [21]  0.8828623240  0.6517911266  0.7026577475  1.1086830542  0.8719090092 #> [26] -1.2589925468 -0.4285167350 -0.2042241398  0.0266595713  1.1822078474 #> [31]  0.1059695012  0.0001025061 -0.8968890118  0.5825699017 -0.0885638114 #> [36]  0.2406998963  0.6877141496 -0.0022791142 -0.1855041224 -0.3722360236 #> [41]  0.1229134539 -0.8672746949 -0.0291675769  0.4311341655  0.2725538003 #> [46]  0.3009381084 -0.0901654138 -0.9223430807 -1.4915276506 -1.0870306449 #>  #> $eta_trace[[34]] #>  [1] -0.3165386826  0.5478612059  0.2607802679  0.2552077583  1.0570739739 #>  [6] -0.6579776963  0.2979545878  0.0740780215  0.2184838425 -2.2473519561 #> [11]  0.1011200444  0.1188233307 -0.1118867079  1.2885576452  0.1740659122 #> [16]  0.0838835331 -0.2536723824  0.2352280571 -0.0069647223 -1.3655816909 #> [21]  0.8829033866  0.6518416136  0.7027572844  1.1088765874  0.8720619603 #> [26] -1.2592106182 -0.4286123596 -0.2041354711  0.0267572479  1.1823467748 #> [31]  0.1060593737  0.0000897408 -0.8969832691  0.5826499592 -0.0885501816 #> [36]  0.2406469090  0.6877495814 -0.0022207809 -0.1855003280 -0.3722682687 #> [41]  0.1229139955 -0.8673736401 -0.0291227411  0.4311915427  0.2725129700 #> [46]  0.3009054541 -0.0901162460 -0.9224684150 -1.4916779855 -1.0871684184 #>  #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLScox.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal bigPLScox functions — internal-bigPLScox","title":"Internal bigPLScox functions — internal-bigPLScox","text":"called user.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLScox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal bigPLScox functions — internal-bigPLScox","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLScox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Internal bigPLScox functions — internal-bigPLScox","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsat features and survival times — micro.censure","title":"Microsat features and survival times — micro.censure","text":"dataset provides Microsat specifications survival times.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsat features and survival times — micro.censure","text":"data frame 117 observations following 43 variables. numpat factor levels B1006 B1017 B1028 B1031 B1046 B1059 B1068 B1071 B1102 B1115 B1124 B1139 B1157 B1161 B1164 B1188 B1190 B1192 B1203 B1211 B1221 B1225 B1226 B1227 B1237 B1251 B1258 B1266 B1271 B1282 B1284 B1285 B1286 B1287 B1290 B1292 B1298 B1302 B1304 B1310 B1319 B1327 B1353 B1357 B1363 B1368 B1372 B1373 B1379 B1388 B1392 B1397 B1403 B1418 B1421t1 B1421t2 B1448 B1451 B1455 B1460 B1462 B1466 B1469 B1493 B1500 B1502 B1519 B1523 B1529 B1530 B1544 B1548 B500 B532 B550 B558 B563 B582 B605 B609 B634 B652 B667 B679 B701 B722 B728 B731 B736 B739 B744 B766 B771 B777 B788 B800 B836 B838 B841 B848 B871 B873 B883 B889 B912 B924 B925 B927 B938 B952 B954 B955 B968 B972 B976 B982 B984 D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4 survyear numeric vector DC numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsat features and survival times — micro.censure","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, #' Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Microsat features and survival times — micro.censure","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Microsat features and survival times — micro.censure","text":"","code":"# \\donttest{ data(micro.censure) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80] Y_test_micro <- micro.censure$survyear[81:117] C_test_micro <- micro.censure$DC[81:117] rm(Y_train_micro,C_train_micro,Y_test_micro,C_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":null,"dir":"Reference","previous_headings":"","what":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"Loads previously scaled design matrix continues stochastic gradient optimisation subset variables.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"","code":"partialbigSurvSGDv0(   name.col,   datapath,   ncores = 1,   resBigscale,   bigmemory.flag = FALSE,   parallel.flag = FALSE,   inf.mth = \"none\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"name.col Character vector containing column names included partial fit. datapath File system path connection big-memory backing file scaled design matrix stored. ncores Number processor cores allocated partial fitting procedure. Defaults 1. resBigscale Result object returned bigscale containing scaling statistics reused. default helper reuses globally cached resultsBigscale object created bigscale. bigmemory.flag Logical flag determining whether big-memory backed matrices used loading updating design matrix. Defaults FALSE. parallel.flag Logical flag toggling use parallelised stochastic gradient updates. Defaults FALSE. inf.mth Inference method requested partial fit, \"none\", \"asymptotic\", bootstrap summaries. Defaults \"none\".","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"Either numeric vector log hazard-ratio coefficients , inference requested, matrix whose columns correspond inferred coefficient summaries penalisation setting.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"","code":"# \\donttest{ data(micro.censure, package = \"bigPLScox\") surv_data <- stats::na.omit(   micro.censure[, c(\"survyear\", \"DC\", \"sexe\", \"Agediag\")] ) scaled <- bigscale(   survival::Surv(survyear, DC) ~ .,   data = surv_data,   norm.method = \"standardize\",   batch.size = 16 ) #> Warning: Strata size times batch size is greater than number of observations. #>  This package resizes them to strata size = 20 and batch size = 4 datapath <- tempfile(fileext = \".csv\") utils::write.csv(surv_data, datapath, row.names = FALSE)  continued <- partialbigSurvSGDv0(   name.col = c(\"Agediag\", \"sexe\"),   datapath = datapath,   ncores = 1,   resBigscale = scaled,   bigmemory.flag = FALSE,   parallel.flag = FALSE,   inf.mth = \"none\" ) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for big_pls_cox objects — plot.big_pls_cox","title":"Plot method for big_pls_cox objects — plot.big_pls_cox","text":"Plot method big_pls_cox objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for big_pls_cox objects — plot.big_pls_cox","text":"","code":"# S3 method for class 'big_pls_cox' plot(   x,   which = c(\"scores\", \"loadings\", \"risk_groups\"),   comps = c(1, 2),   groups = NULL,   breaks = 3,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for big_pls_cox objects — plot.big_pls_cox","text":"x big_pls_cox object. Type plot: \"scores\", \"loadings\", \"risk_groups\". comps Components use (\"scores\" \"loadings\"). groups Optional grouping factor scores plot; NULL status available, groups derived event status. breaks Number risk groups \"risk_groups\" (default 3). ... graphical arguments (passed base plotting functions).","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for big_pls_cox_gd objects — plot.big_pls_cox_gd","title":"Plot method for big_pls_cox_gd objects — plot.big_pls_cox_gd","text":"Plot method big_pls_cox_gd objects Basic diagnostic plots big_pls_cox_gd","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for big_pls_cox_gd objects — plot.big_pls_cox_gd","text":"","code":"# S3 method for class 'big_pls_cox_gd' plot(x, what = c(\"loglik\", \"gradient\", \"steps\", \"coef\", \"risk\", \"all\"), ...)  # S3 method for class 'big_pls_cox_gd' plot(x, what = c(\"loglik\", \"gradient\", \"steps\", \"coef\", \"risk\", \"all\"), ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/plot.big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for big_pls_cox_gd objects — plot.big_pls_cox_gd","text":"x big_pls_cox object. Character string specifying plot. Typically \"scores\", \"loadings\" \"coefficients\". ... graphical arguments (passed base plotting functions).","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"Predict method big-memory PLS-Cox models","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"","code":"# S3 method for class 'big_pls_cox' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"object model fitted big_pls_cox(). newdata Optional matrix, data frame bigmemory::big.matrix containing predictors project latent space. NULL training scores used. type Type prediction: \"link\" linear predictor, \"risk\" \"response\" exponential linear predictor, \"components\" obtain latent scores. comps Integer vector indicating components use. Defaults available components. coef Optional coefficient vector overriding fitted Cox model coefficients. ... Unused.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"Depending type, either numeric vector predictions matrix component scores.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660 Bertrand, F., Bastien, P., Meyer, N., & Maumy-Bertrand, M. (2014). PLS models censored data. Proceedings UseR! 2014 (p. 152).","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions for fast big PLS–Cox fits — predict.big_pls_cox_fast","title":"Predictions for fast big PLS–Cox fits — predict.big_pls_cox_fast","text":"Predictions fast big PLS–Cox fits","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions for fast big PLS–Cox fits — predict.big_pls_cox_fast","text":"","code":"# S3 method for class 'big_pls_cox_fast' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions for fast big PLS–Cox fits — predict.big_pls_cox_fast","text":"object object class \"big_pls_cox_fast\". newdata Optional matrix big.matrix predictors. type Type prediction: \"link\", \"risk\", \"response\", \"components\". comps Optional components use. Defaults . coef Optional coefficient vector. Defaults object$coefficients. ... Ignored.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for big_pls_cox_gd — predict.big_pls_cox_gd","title":"Predict method for big_pls_cox_gd — predict.big_pls_cox_gd","text":"Predict method big_pls_cox_gd","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for big_pls_cox_gd — predict.big_pls_cox_gd","text":"","code":"# S3 method for class 'big_pls_cox_gd' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for big_pls_cox_gd — predict.big_pls_cox_gd","text":"object big_pls_cox_gd model. newdata numeric matrix big.matrix. NULL, uses training scores. type One \"link\", \"risk\", \"response\", \"components\". comps Integer vector components use. Default: . coef Optional coefficient vector. NULL, uses coef(object$cox_fit). ... Unused.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"methods extend stats::predict() Cox models fitted original PLS engines exposed coxgpls(), coxsgpls(), deviance-residual kernel variants. provide access latent component scores alongside linear predictors risk estimates, ensuring consistent behaviour newer big-memory solvers.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"","code":"# S3 method for class 'coxgpls' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxgplsDR' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxsgpls' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxsgplsDR' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxspls_sgpls' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxDKgplsDR' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxDKsgplsDR' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'coxDKspls_sgplsDR' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"object fitted model returned coxgpls(), coxsgpls(), coxspls_sgpls(), deviance-residual/kernel counterparts allres = TRUE. newdata Optional matrix data frame predictors. NULL, training components stored object reused. type Type prediction requested: \"link\" linear predictors, \"risk\"/\"response\" exponentiated scores, \"components\" return latent PLS scores. comps Optional integer vector specifying latent components retain. Defaults available components. coef Optional coefficient vector overriding Cox model coefficients stored object. ... Unused arguments future extensions.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"type \"components\", matrix latent scores; otherwise numeric vector containing requested prediction names inherited supplied data.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660 Bertrand, F., Bastien, P., & Maumy-Bertrand, M. (2018). Cross validating extensions kernel, sparse regular partial least squares regression models censored data. https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_cox_pls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict survival summaries from legacy Cox-PLS fits — predict_cox_pls","text":"","code":"if (requireNamespace(\"survival\", quietly = TRUE)) {   data(micro.censure, package = \"bigPLScox\")   data(Xmicro.censure_compl_imp, package = \"bigPLScox\")    X <- as.matrix(Xmicro.censure_compl_imp[1:60, 1:10])   time <- micro.censure$survyear[1:60]   status <- micro.censure$DC[1:60]    set.seed(321)   fit <- coxgpls(     Xplan = X,     time = time,     status = status,     ncomp = 2,     allres = TRUE   )    predict(fit, newdata = X[1:5, ], type = \"risk\")   head(predict(fit, type = \"components\")) } #>           dim.1      dim.2 #> [1,]  0.8180843  1.0402867 #> [2,] -1.6095533  0.0997729 #> [3,]  0.1280324 -0.5407040 #> [4,] -0.1346531 -1.9098214 #> [5,]  0.8531046 -0.3185590 #> [6,]  0.2168484 -0.3475775"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict responses and latent scores from PLS fits — predict_pls_latent","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"prediction helpers reconstruct response matrix latent component scores partial least squares (PLS) models fitted inside Cox-PLS toolbox. support group PLS, sparse PLS, sparse-group PLS, classical PLS models created sgPLS::gPLS(), sgPLS::sPLS(), sgPLS::sgPLS(), plsRcox::pls.cox().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"","code":"# S3 method for class 'gPLS' predict(object, newdata, scale.X = TRUE, scale.Y = TRUE, ...)  # S3 method for class 'pls.cox' predict(object, newdata, scale.X = TRUE, scale.Y = TRUE, ...)  # S3 method for class 'sPLS' predict(object, newdata, scale.X = TRUE, scale.Y = TRUE, ...)  # S3 method for class 'sgPLS' predict(object, newdata, scale.X = TRUE, scale.Y = TRUE, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"object fitted PLS model returned sgPLS::gPLS(), sgPLS::sPLS(), sgPLS::sgPLS(), plsRcox::pls.cox(). newdata Numeric matrix data frame number columns training design matrix used fitting object. scale.X, scale.Y Logical flags indicating whether predictors responses supplied newdata centred scaled according training statistics stored object. ... Unused arguments included compatibility generic stats::predict() signature.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"list containing reconstructed responses, latent component scores, regression coefficients. exact elements depend specific PLS algorithm always include components named predict, variates, B.hat.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"Bastien, P., Bertrand, F., Meyer, N., & Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS censored data. Bioinformatics, 31(3), 397–404. doi:10.1093/bioinformatics/btu660","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/predict_pls_latent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict responses and latent scores from PLS fits — predict_pls_latent","text":"","code":"n <- 100 sigma.gamma <- 1 sigma.e <- 1.5 p <- 400 q <- 500 theta.x1 <- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5,15),                rep(0, 5), rep(-1.5, 15), rep(0, 325)) theta.x2 <- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),               rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5)) theta.y1 <- 1 theta.y2 <- 1  Sigmax <- matrix(0, nrow = p, ncol = p) diag(Sigmax) <- sigma.e ^ 2 Sigmay <- matrix(0,nrow = 1, ncol = 1) diag(Sigmay) <- sigma.e ^ 2  set.seed(125)  gam1 <- rnorm(n) gam2 <- rnorm(n)  X <- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),  nrow = 2, byrow = TRUE) + mvtnorm::rmvnorm(n, mean = rep(0, p), sigma =  Sigmax, method = \"svd\") Y <- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.y1, theta.y2),  nrow = 2, byrow = TRUE) + rnorm(n,0,sd=sigma.e)  ind.block.x <- seq(20, 380, 20)  model.gPLS <- sgPLS::gPLS(X, Y, ncomp = 2, mode = \"regression\", keepX = c(4, 4),                     keepY = c(4, 4), ind.block.x = ind.block.x) head(predict(model.gPLS, newdata = X)$variates) #>            dim 1      dim 2 #> [1,]   1.7433859 -1.0107806 #> [2,]   0.3536207  5.7590437 #> [3,]   4.6851991 -1.7566289 #> [4,]   0.2587842 -0.6634727 #> [5,]   1.5699343  0.4017589 #> [6,] -10.5958505 -2.3180566"},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for big_pls_cox objects — print.big_pls_cox","title":"Print method for big_pls_cox objects — print.big_pls_cox","text":"Print method big_pls_cox objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for big_pls_cox objects — print.big_pls_cox","text":"","code":"# S3 method for class 'big_pls_cox' print(x, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for big_pls_cox objects — print.big_pls_cox","text":"x object class big_pls_cox. ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for big_pls_cox_gd objects — print.big_pls_cox_gd","title":"Print method for big_pls_cox_gd objects — print.big_pls_cox_gd","text":"Print method big_pls_cox_gd objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for big_pls_cox_gd objects — print.big_pls_cox_gd","text":"","code":"# S3 method for class 'big_pls_cox_gd' print(x, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/print.big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for big_pls_cox_gd objects — print.big_pls_cox_gd","text":"x object class big_pls_cox_gd. ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/print.summary.big_pls_cox_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for summary.big_pls_cox_fast objects — print.summary.big_pls_cox_fast","title":"Print method for summary.big_pls_cox_fast objects — print.summary.big_pls_cox_fast","text":"Print method summary.big_pls_cox_fast objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/print.summary.big_pls_cox_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for summary.big_pls_cox_fast objects — print.summary.big_pls_cox_fast","text":"","code":"# S3 method for class 'summary.big_pls_cox_fast' print(x, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/print.summary.big_pls_cox_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for summary.big_pls_cox_fast objects — print.summary.big_pls_cox_fast","text":"x object class summary.big_pls_cox_fast. ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated dataset — sim_data","title":"Simulated dataset — sim_data","text":"dataset provides explantory variables simulations censoring status.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated dataset — sim_data","text":"data frame 1000 observations following 11 variables. status binary vector X1 numeric vector X2 numeric vector X3 numeric vector X4 numeric vector X5 numeric vector X6 numeric vector X7 numeric vector X8 numeric vector X9 numeric vector X10 numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated dataset — sim_data","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS binary classification survival analysis. BMC Bioinformatics, 16, 211.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated dataset — sim_data","text":"","code":"# \\donttest{ data(sim_data) X_sim_data_train <- sim_data[1:800,2:11] C_sim_data_train <- sim_data$status[1:800] X_sim_data_test <- sim_data[801:1000,2:11] C_sim_data_test <- sim_data$status[801:1000] rm(X_sim_data_train,C_sim_data_train,X_sim_data_test,C_sim_data_test) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for big_pls_cox objects — summary.big_pls_cox","title":"Summary for big_pls_cox objects — summary.big_pls_cox","text":"Summary big_pls_cox objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for big_pls_cox objects — summary.big_pls_cox","text":"","code":"# S3 method for class 'big_pls_cox' summary(object, digits = 3, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for big_pls_cox objects — summary.big_pls_cox","text":"object big_pls_cox object. digits Number digits print. ... Unused, S3 compatibility.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for big_pls_cox objects — summary.big_pls_cox_fast","title":"Summary for big_pls_cox objects — summary.big_pls_cox_fast","text":"Summary big_pls_cox objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for big_pls_cox objects — summary.big_pls_cox_fast","text":"","code":"# S3 method for class 'big_pls_cox_fast' summary(object, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for big_pls_cox objects — summary.big_pls_cox_fast","text":"object big_pls_cox object. ... used.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for big_pls_cox_gd objects — summary.big_pls_cox_gd","title":"Summary for big_pls_cox_gd objects — summary.big_pls_cox_gd","text":"Summary big_pls_cox_gd objects","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for big_pls_cox_gd objects — summary.big_pls_cox_gd","text":"","code":"# S3 method for class 'big_pls_cox_gd' summary(object, digits = 3, ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/summary.big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for big_pls_cox_gd objects — summary.big_pls_cox_gd","text":"object big_pls_cox_gd object. digits Number digits print. ... Unused, S3 compatibility.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-080","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.8.0","title":"bigPLScox 0.8.0","text":"Added doi package.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-070","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.7.0","title":"bigPLScox 0.7.0","text":"Fixed problem C code led additionnal error CRAN tests. Added helpers big_pls_cox() big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-060","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.6.0","title":"bigPLScox 0.6.0","text":"CRAN release: 2025-11-11 See “Release highlights” section README condensed overview changes. Added C++ implementations Cox deviance residuals streaming support  matrices together benchmarking utilities. Introduced prediction wrappers component selection helpers (AIC/BIC) big_pls_cox() big_pls_cox_gd(). Enabled naive sparsity control big_pls_cox() exposed survival model objects downstream predictions. Added cross-validation helpers cv.big_pls_cox() cv.big_pls_cox_gd() mirroring plsRcox criteria, including recommended survivalROC iAUC metric default. Documented legacy big-memory prediction helpers runnable examples cross references diagnostic utilities. Extended unit test coverage new deviance prediction features. Fixed cv.coxgpls() accept big.matrix predictors without coercion errors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-050","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.5.0","title":"bigPLScox 0.5.0","text":"Added reproducible benchmarking utilities inst/benchmarks comparing big_pls_cox() plsRcox::plsRcox() -memory file-backed matrices. Published two package vignettes cover introductory workflows large-scale analyses bigmemory. Added introductory vignette covering core Cox-PLS workflow. Refreshed README website copy highlight core functionality demonstrate working examples without warnings, including guidance learning materials benchmarking resources. Refreshed README guidance learning materials benchmarking. Completed package-level documentation bibliographic references. Updated package metadata list optional dependencies used docs benchmarks.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-040","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.4.0","title":"bigPLScox 0.4.0","text":"Updated maintainer contact details DESCRIPTION. Added unit tests big_pls_cox() big_pls_cox_gd() stability checks. Added unit tests covering new C++-accelerated Cox PLS implementation cross-validation utilities.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-030","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.3.0","title":"bigPLScox 0.3.0","text":"Improved big_pls_cox() numerical stability added support additional convergence diagnostics gradient-descent solver. Refactored stochastic gradient solvers better integrate bigmemory file-backed matrices. Improved numerical stability deviance residual computations.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-020","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.2.0","title":"bigPLScox 0.2.0","text":"Expanded documentation examples deviance residuals Cox model utilities. Added dataset documentation micro.censure simulated Cox examples. Added pkgdown site configuration continuous integration workflows.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-010","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.1.0","title":"bigPLScox 0.1.0","text":"Introduced gPLS sgPLS model families support grouped predictors deviance residual pipelines cross-validation support.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-001","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.0.1","title":"bigPLScox 0.0.1","text":"Initial package skeleton core data objects helper routines.","code":""}]
