[{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Benchmarking bigPLScox","text":"High-dimensional survival datasets can computationally demanding. bigPLScox implements algorithms scale large numbers predictors observations via component-based models, sparse penalties, stochastic gradient descent routines. vignette demonstrates benchmark package baseline approaches using bench package. focus simulated data illustrate reproducible comparisons classical coxgpls() solver, big-memory counterparts, survival::coxph() implementation.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Benchmarking bigPLScox","text":"examples require recent version bench together survival. helper dataCox() simulates survival outcomes right censoring. work moderately sized problem , larger values n p can used stress test performance.","code":"library(bigPLScox) library(survival) library(bench) set.seed(2024) sim_design <- dataCox(   n = 2000,   lambda = 2,   rho = 1.5,   x = matrix(rnorm(2000 * 50), ncol = 50),   beta = c(1, 3, rep(0, 48)),   cens.rate = 5 )  cox_data <- list(   x = as.matrix(sim_design[, -(1:3)]),   time = sim_design$time,   status = sim_design$status )"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"running-the-benchmark","dir":"Articles","previous_headings":"","what":"Running the benchmark","title":"Benchmarking bigPLScox","text":"compare classical Cox proportional hazards model coxgpls(). bench::mark() helper executes estimators multiple times records timing statistics alongside memory usage information. resulting tibble reports elapsed time, memory allocations, garbage collection statistics estimator. itr/sec column often useful indicator comparing multiple implementations.","code":"bench_res <- bench::mark(   bigPLScox = coxgpls(     cox_data$x,     cox_data$time,     cox_data$status,     ncomp = 5,     ind.block.x = c(3, 10)   ),   survival = coxph(Surv(cox_data$time, cox_data$status) ~ cox_data$x, ties = \"breslow\"),   iterations = 100,   check = FALSE ) bench_res #> # A tibble: 2 × 6 #>   expression      min   median `itr/sec` mem_alloc `gc/sec` #>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #> 1 bigPLScox    19.3ms   19.9ms      50.2    67.3MB   1318.  #> 2 survival     27.4ms   28.2ms      35.4    13.4MB     25.7"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"visualising-the-results","dir":"Articles","previous_headings":"","what":"Visualising the results","title":"Benchmarking bigPLScox","text":"bench provides ggplot-based helpers visualise distributions elapsed memory usage.  Additional geometries, ridge plots, available via autoplot(bench_res, type = \"ridge\").","code":"plot(bench_res, type = \"jitter\")"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"exporting-benchmark-results","dir":"Articles","previous_headings":"","what":"Exporting benchmark results","title":"Benchmarking bigPLScox","text":"Use function write.csv() store benchmarking table part reproducible pipeline. larger studies consider varying number latent components, sparsity constraints, dataset dimensions.","code":"if (!dir.exists(\"inst/benchmarks/results\")) {   dir.create(\"inst/benchmarks/results\", recursive = TRUE) } write.csv(bench_res, file = \"inst/benchmarks/results/benchmarking-demo.csv\", row.names = FALSE)"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-benchmarking.html","id":"reusing-the-benchmarking-scripts","dir":"Articles","previous_headings":"","what":"Reusing the benchmarking scripts","title":"Benchmarking bigPLScox","text":"package also ships standalone scripts inst/benchmarks/ mirror vignette exposing additional configuration points. Run repository root : script accepts environment variables adjust problem size stores results inst/benchmarks/results/ time-stamped filenames.","code":"Rscript inst/benchmarks/cox-benchmark.R Rscript inst/benchmarks/benchmark_bigPLScox.R Rscript inst/benchmarks/cox_pls_benchmark.R"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Overview of bigPLScox","text":"goal bigPLScox provide Partial Least Squares (PLS) variants Cox proportional hazards model scale high-dimensional survival settings. package implements several algorithms tailored large-scale problems, including sparse, grouped, deviance-residual-based approaches. integrates bigmemory ecosystem data stored disk can analysed without exhausting RAM. vignette gives quick tour core workflows. highlights prepare data, fit model, assess model quality, explore advanced extensions. complementary vignette “Getting started bigPLScox” offers hands-tutorial, “Benchmarking bigPLScox” focuses performance comparisons.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"package-highlights","dir":"Articles","previous_headings":"","what":"Package highlights","title":"Overview of bigPLScox","text":"Generalised PLS Cox regression via coxgpls() support grouped predictors. Sparse structured-sparse extensions coxsgpls() coxspls_sgpls(). Deviance-residual estimators coxgplsDR() increased robustness. Cross-validation helpers (cv.coxgpls(), cv.coxsgpls(), …) select number latent components. Big-memory interfaces (big_pls_cox(), big_pls_cox_gd()) designed file-backed matrices stored bigmemory.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"available-algorithms","dir":"Articles","previous_headings":"","what":"Available algorithms","title":"Overview of bigPLScox","text":"following modeling functions provided: coxgpls() generalized PLS Cox regression. coxsgpls() coxspls_sgpls() sparse structured sparse extensions. coxgplsDR() coxsgplsDR() deviance-residual-based estimation. cv.coxgpls() related cv.* helpers component selection. stochastic gradient descent large data package includes big_pls_cox() big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"loading-an-example-dataset","dir":"Articles","previous_headings":"","what":"Loading an example dataset","title":"Overview of bigPLScox","text":"package ships small allelotyping dataset use throughout vignette. data include censoring indicators alongside large set predictors.","code":"library(bigPLScox)  data(micro.censure) data(Xmicro.censure_compl_imp)  train_idx <- seq_len(80) Y_train <- micro.censure$survyear[train_idx] C_train <- micro.censure$DC[train_idx] X_train <- Xmicro.censure_compl_imp[train_idx, -40]"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"fitting-a-pls-cox-model","dir":"Articles","previous_headings":"","what":"Fitting a PLS-Cox model","title":"Overview of bigPLScox","text":"coxgpls() provides matrix interface mirrors survival::coxph() adds latent components stabilise estimation high dimensions. summary includes convergence diagnostics, latent component information, predicted linear predictors can used risk stratification.","code":"fit <- coxgpls(   X_train,   Y_train,   C_train,   ncomp = 6,   ind.block.x = c(3, 10, 15) ) fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>          coef exp(coef) se(coef)      z       p #> dim.1 -0.6003    0.5486   0.2197 -2.733 0.00628 #> dim.2 -0.6876    0.5028   0.2816 -2.442 0.01460 #> dim.3 -0.4922    0.6113   0.2498 -1.971 0.04877 #> dim.4  0.2393    1.2703   0.2861  0.836 0.40292 #> dim.5 -0.3689    0.6915   0.2200 -1.677 0.09359 #> dim.6  0.1570    1.1700   0.2763  0.568 0.56979 #>  #> Likelihood ratio test=23.99  on 6 df, p=0.0005249 #> n= 80, number of events= 17"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model assessment","title":"Overview of bigPLScox","text":"Cross-validation helps decide many components retained. cv.coxgpls() helper accepts either matrix list containing x, time, status elements.  resulting object may plotted visualise cross-validated deviance apply one-standard-error rules choosing number components.","code":"set.seed(123) cv_res <- cv.coxgpls(   list(x = X_train, time = Y_train, status = C_train),   nt = 10,   ind.block.x = c(3, 10, 15) ) #> CV Fold 1 #> CV Fold 2 #> CV Fold 3 #> CV Fold 4 #> CV Fold 5 cv_res #> $nt #> [1] 10 #>  #> $cv.error10 #>  [1] 0.5000000 0.6013049 0.5183694 0.4226056 0.3860331 0.4071207 0.4252845 #>  [8] 0.4001223 0.4464093 0.4526887 0.4695600 #>  #> $cv.se10 #>  [1] 0.00000000 0.03487588 0.06866706 0.07717020 0.07373734 0.07084802 #>  [7] 0.07707939 0.07247893 0.07317843 0.06341118 0.06252387 #>  #> $folds #> $folds$`1` #>  [1] 31 42 69 75 72 12 66 27 71 55 58 49 11 30 37 22 #>  #> $folds$`2` #>  [1] 79 50 57 68 17 15 64 74 34 13 80 76 61  2 24 35 #>  #> $folds$`3` #>  [1] 51 43  9 62 73 32 41 78 29 18  6 16 44 59 33 48 #>  #> $folds$`4` #>  [1] 14 77 26 19 39 65 10 56  5  1 21 20 46 60  3 47 #>  #> $folds$`5` #>  [1] 67 25  7 36 53 45 23 38  8 40 54 28 52  4 70 63 #>  #>  #> $lambda.min10 #> [1] 1 #>  #> $lambda.1se10 #> [1] 0"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"alternative-estimators","dir":"Articles","previous_headings":"","what":"Alternative estimators","title":"Overview of bigPLScox","text":"Deviance-residual-based estimators provide increased robustness iteratively updating residuals. Sparse variants enable feature selection extremely high-dimensional designs. Additional sparse estimators can invoked via coxsgpls() coxspls_sgpls() providing keepX penalty arguments control number active predictors per component.","code":"dr_fit <- coxgplsDR(   X_train,   Y_train,   C_train,   ncomp = 6,   ind.block.x = c(3, 10, 15) ) dr_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>          coef exp(coef) se(coef)     z        p #> dim.1 0.92699   2.52690  0.23301 3.978 6.94e-05 #> dim.2 0.85445   2.35008  0.27352 3.124  0.00178 #> dim.3 0.56308   1.75607  0.29847 1.887  0.05922 #> dim.4 0.49242   1.63627  0.32344 1.522  0.12789 #> dim.5 0.18706   1.20569  0.38769 0.482  0.62946 #> dim.6 0.08581   1.08960  0.31517 0.272  0.78541 #>  #> Likelihood ratio test=51.46  on 6 df, p=2.39e-09 #> n= 80, number of events= 17"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"working-with-big-data","dir":"Articles","previous_headings":"","what":"Working with big data","title":"Overview of bigPLScox","text":"extremely large problems, stochastic gradient descent routines operate memory-mapped matrices created bigmemory. helper converts standard matrix big.matrix runs small example. big_pls_cox_gd() function exposes gradient-descent variant often preferred streaming workloads. functions can combined foreach::foreach() multi-core execution.","code":"X_big <- bigmemory::as.big.matrix(X_train) big_fit <- big_pls_cox(   X_big,   time = Y_train,   status = C_train,   ncomp = 6 ) big_fit #> $scores #>              [,1]        [,2]        [,3]        [,4]        [,5]         [,6] #>  [1,] -1.67104396 -1.31172970 -0.72053662  0.83758976  0.91523072  2.160972278 #>  [2,]  0.56500329 -2.40102720  1.39614422 -1.87960603 -0.09136061 -0.140687791 #>  [3,]  1.40616746 -0.69684421 -0.56989372 -0.01622647  0.68615313  0.063343145 #>  [4,]  0.58059459  0.14365512 -0.61241544 -2.57730299 -2.32512426 -1.229253581 #>  [5,]  1.42739124  0.02170243 -1.32960235  0.37746910 -1.98097619  1.172392190 #>  [6,] -1.16078731 -0.29961777 -0.22980325  0.21542915 -1.95714711 -1.283204950 #>  [7,] -1.23408322  1.33664160 -1.13549725 -0.12484523  0.20378409  1.580074806 #>  [8,]  2.94332576  0.70819715 -1.98537686 -0.15638169  0.44251820  2.001849745 #>  [9,]  0.02095444 -1.59587258 -0.68434695 -0.95788332  1.90956368 -0.964636074 #> [10,]  0.44524202 -0.96282654  2.47845180 -1.20488166 -1.04036886  1.367535052 #> [11,]  1.08512904  2.24438250 -0.38213400  0.99903346  0.58525310  3.015329777 #> [12,] -2.18125464  1.91284717 -0.28489813  1.73065024 -0.35121927 -0.198850021 #> [13,]  1.07471369 -1.43046906  0.44396702  0.85898313  1.12045349 -0.252855432 #> [14,] -1.61754215  0.88498067  0.30785096  0.77080467  0.73804337  0.443605286 #> [15,]  0.51720528 -0.94643073 -0.62399871  0.33306055  1.83769338 -0.871459432 #> [16,]  1.10085291 -1.78211236 -0.88393696  0.75099254 -0.78588660  1.584139906 #> [17,] -1.83313725 -0.43256798  0.30572026 -1.12545641 -0.19026054 -0.933739972 #> [18,] -1.94290640 -1.00042674 -0.54259313 -1.51321193 -0.16046741  1.346004692 #> [19,]  0.75005248  1.97644125 -0.63694082 -1.29752973  1.82426107 -2.266834083 #> [20,] -2.09144564  1.30983114 -0.77015689  0.30595855  1.02851410  0.391115096 #> [21,] -1.06832948 -1.79812101  1.31156771  0.23309168 -1.16799488  1.820129278 #> [22,] -0.72732728 -1.34943171  0.55404315  2.58015129  1.06548427  0.746357538 #> [23,]  0.68659962 -1.36226471  1.24958039 -0.21141390  1.32707245 -0.001936979 #> [24,]  0.64051825  0.86972749 -1.21949736  0.48197056 -1.15268954 -0.015782803 #> [25,] -3.16258865 -0.50120469 -1.44150348  1.16691956  0.34950903  0.095722045 #> [26,] -2.02253736  1.32415711  0.43825053 -0.91636530 -0.70489654 -0.110385401 #> [27,]  2.39611609  0.43308037  1.09930800  0.38042152 -0.38837697 -1.625543025 #> [28,]  1.79414318 -0.68043226 -2.08114620  0.53616832 -0.28912628 -2.437613030 #> [29,] -0.69653042  0.66341885  1.19836212 -0.87214101 -0.25326952 -3.355545199 #> [30,] -1.97105992  0.41749686  0.14848010 -1.64840958 -3.00195750 -0.439326986 #> [31,]  1.44730927 -0.03883362  1.96930809  2.91946177  1.09629507 -0.299438344 #> [32,] -1.87035902 -1.29281036  0.97050183  1.05646189 -0.41798590  1.262166994 #> [33,] -1.56262929 -1.61071056  1.91396985  0.68380944  1.16192551 -1.371079842 #> [34,] -0.30070481  1.89420490 -0.86002360 -0.93884533  2.11317196 -0.498123661 #> [35,]  1.94052729 -0.12396776 -0.50982180  2.64135497 -0.80210456 -0.757224864 #> [36,] -0.27646381  0.69498270 -0.70971117 -0.33712477  1.13985912 -0.200776009 #> [37,]  1.95839370  2.61494070  0.99400283  0.92655149 -1.80758389 -0.791362282 #> [38,] -1.19623313  1.71199889  1.69254301  1.51103508 -0.13841204 -0.954233914 #> [39,] -2.14893811 -0.42781160  0.79385084  0.40756776 -0.54150003  0.400999382 #> [40,]  0.47443255 -0.71831580  0.04438998  3.25520128  0.12572674 -0.760080990 #> [41,]  0.01038579  1.22634502  1.69247318 -0.01357900 -0.27652801 -1.539936107 #> [42,]  1.79481463 -0.92793623 -1.04005922  0.44122807  0.92921845  2.020257084 #> [43,] -2.01813391  1.06926582  2.30854724  1.73407299 -0.49604293  0.597531041 #> [44,] -0.40610435 -1.69036910  1.94673689  2.01313682 -0.98945192 -1.842766686 #> [45,] -1.15159486  0.79189839 -0.43274270 -1.99462095  1.05097661 -0.579690469 #> [46,]  0.12679724  0.57320104 -1.17330366  1.05916075 -2.70102967  1.830534303 #> [47,] -0.51382960 -1.52544274 -1.65552499 -1.58066193 -1.18635866 -0.005129010 #> [48,]  0.87538342 -1.20599642 -0.27385427 -3.14261822 -2.99232392 -1.194081029 #> [49,]  1.70751237 -0.42660178  0.97017036  1.51612272 -0.49242951  2.238275129 #> [50,] -0.08983474  0.13372715 -0.67666662 -2.00065278  1.06804125  2.219072130 #> [51,] -0.44112040  0.59609280  0.20012549 -2.31915979 -0.22759828 -0.640216836 #> [52,]  2.78002915 -4.25608264  0.29160756  0.16571098 -0.08539776 -0.540835490 #> [53,]  0.62370168 -1.02971836  0.21047586  0.52677910  1.36208648 -2.326641364 #> [54,]  1.99451623  2.01299517  3.85797376 -1.38049960 -1.40722400  0.810774141 #> [55,]  2.73032710  0.42244879  1.67364450 -0.93013251  0.11375487  0.605049105 #> [56,] -1.65794714 -0.52989444 -0.04189889 -0.05063020 -0.09582023  0.332710012 #> [57,] -2.73704777 -0.56825143 -0.24354962 -0.24131501  1.55048560  0.957924363 #> [58,] -0.10959685  1.30286539  2.42567336 -0.82654421 -0.01075101  0.851975320 #> [59,] -1.26087244  3.27637407  0.35929857  1.05281586 -1.43407403  1.173687550 #> [60,] -1.52206614  1.79489975 -0.33082720  0.99602740  1.11155205  0.196947147 #> [61,]  1.35452147  2.46037709 -0.25138125 -1.66482557  0.37463116 -0.745510708 #> [62,]  0.93541981 -0.61964456  2.09574208 -0.05569470  1.82573513  0.255991522 #> [63,]  4.36545770  0.51237927 -2.18648599  2.12424731 -0.01624430 -2.054853673 #> [64,]  0.49976873 -3.43013449 -0.78198124 -1.24522704 -1.16820750 -0.557866407 #> [65,]  2.28093675 -0.19441383  1.01226064 -3.36957600  1.56043016  1.711617208 #> [66,] -0.23703633  0.67594918 -0.28487533 -0.25598604  2.47218024  0.771870212 #> [67,] -2.44029420 -0.98292416 -2.52154120 -1.32320586 -0.36697728 -0.098037461 #> [68,]  0.08767379 -0.24619106 -2.59998415  0.14731033  0.72843686  1.170331755 #> [69,]  1.67254999  1.49937783  0.08055612 -1.75509908  1.36965516  1.595438530 #> [70,] -1.10331590 -0.15710217 -0.59222334 -0.12483345  0.24811213 -0.181938060 #> [71,]  0.19819077  1.00960968  0.71408507  1.55744834 -3.07028981 -0.333454103 #> [72,]  0.98924592  3.30582333 -1.91566026  0.02073128  1.26816027 -1.808580236 #> [73,]  1.22390387 -0.70875958  2.12356215 -0.92751738  1.52488173  0.675741852 #> [74,] -1.02295544 -0.25866087 -0.64929914 -1.83986540 -2.05540629 -0.472837941 #> [75,]  1.64172219 -1.02784392 -0.91509096  0.45459816  0.79625449  0.324813994 #> [76,]  1.81086382  0.57846179 -2.20079914  1.23378170 -2.75895200  1.521891073 #> [77,] -1.06735490 -0.29839478  0.26243399 -0.15851068  1.69887749 -1.157902139 #> [78,] -0.77628937 -0.39154284 -1.92516641  0.86589909  0.09701506 -1.663331304 #> [79,] -1.21317256  1.26811946 -0.32650975 -0.28146744  0.82285640 -1.278680182 #> [80,] -2.45392584 -2.43316354 -0.30239945  1.39063959 -0.26403844 -0.531906810 #>  #> $loadings #>               [,1]         [,2]          [,3]         [,4]         [,5] #>  [1,] -0.007907408  0.270526866 -0.1346712581  0.104027296 -0.126418953 #>  [2,] -0.054350954  0.114923658 -0.0181967641  0.055624084  0.147862732 #>  [3,] -0.064944236  0.166166291  0.1379580022 -0.272085595 -0.019622197 #>  [4,]  0.288963709  0.285763351  0.0447231266 -0.101896305 -0.089373970 #>  [5,] -0.010044191  0.305929506 -0.0009855362 -0.056007642 -0.024672587 #>  [6,] -0.025766375  0.269265072 -0.1225929663 -0.112212757 -0.303260480 #>  [7,] -0.123173378  0.323683296 -0.2606000263  0.211544752  0.034075860 #>  [8,] -0.198349136  0.221068688 -0.3568604653 -0.029350155 -0.136964627 #>  [9,] -0.084633840  0.127479767 -0.1875663683  0.165442284 -0.019979445 #> [10,]  0.166891755  0.151028319 -0.3098019805  0.142754582  0.097009827 #> [11,] -0.177695228 -0.004899100  0.0753697185 -0.154844568  0.218082027 #> [12,] -0.340662705 -0.027886330 -0.0459786749 -0.009847259  0.138068558 #> [13,]  0.056267272  0.259969757  0.1625712917  0.346074069 -0.372989323 #> [14,] -0.208673053  0.245709780 -0.0495597170 -0.251617875  0.313946761 #> [15,]  0.194331074  0.138882645 -0.2437843179 -0.059446437 -0.025929835 #> [16,] -0.248947154 -0.001222654 -0.1216218398  0.110444351 -0.407289398 #> [17,] -0.099005530  0.049072511 -0.0882831462  0.322808106 -0.248102781 #> [18,] -0.105172423  0.119320545  0.0988777535 -0.130283728 -0.106904843 #> [19,] -0.149709844 -0.089084891 -0.0949332008  0.143896146 -0.081850240 #> [20,] -0.028460398 -0.003786869  0.2237221447  0.231194460  0.208863334 #> [21,]  0.070620393  0.194364490 -0.3188777229 -0.162544961  0.141954627 #> [22,] -0.054039914  0.284461778  0.0016323577  0.011418776  0.092962813 #> [23,] -0.296679452  0.219477782 -0.2099858872 -0.052896946 -0.096501018 #> [24,] -0.108014508  0.142823533  0.0323119931  0.004078892  0.062701021 #> [25,] -0.013135682 -0.096537482  0.4518069771  0.257880475 -0.118500275 #> [26,] -0.272241045  0.218515950  0.0783360106  0.187862046  0.003219405 #> [27,]  0.049764074  0.244447856  0.0327620341  0.042175147 -0.129663416 #> [28,] -0.139704253  0.047021417 -0.2203429528  0.435558684 -0.194206651 #> [29,] -0.026552492  0.334921688 -0.1487928122  0.108209934  0.299974166 #> [30,] -0.095756877  0.188706122  0.2879865577  0.031370531 -0.337816403 #> [31,] -0.286327893  0.016984916 -0.0035272670  0.104699186  0.288976162 #> [32,] -0.241861131  0.208778175 -0.0022639029  0.075523620 -0.258075127 #> [33,] -0.168318826  0.040560476 -0.0144626390  0.289249740  0.097696346 #> [34,]  0.036900098 -0.235417402  0.0176137173  0.070599690  0.119878672 #> [35,]  0.055731568  0.171898143 -0.0469189059 -0.184313250  0.017995954 #> [36,]  0.061006304 -0.255681493 -0.0962174410  0.238018538 -0.111571263 #> [37,]  0.200358213  0.055925165 -0.3570718374  0.119349191  0.331869201 #> [38,]  0.383916827 -0.040313802 -0.2055934428  0.206349543  0.097574273 #> [39,]  0.334018148 -0.178990539 -0.1786034771  0.167838017 -0.168236076 #>                [,6] #>  [1,] -0.0049321154 #>  [2,] -0.3667098942 #>  [3,]  0.0830748871 #>  [4,]  0.0136962645 #>  [5,]  0.1582704751 #>  [6,] -0.1296597068 #>  [7,]  0.1099498946 #>  [8,]  0.0597092961 #>  [9,] -0.0555225440 #> [10,]  0.1067432490 #> [11,] -0.0376990447 #> [12,] -0.2649881493 #> [13,]  0.0002202799 #> [14,] -0.0270200862 #> [15,]  0.1911387534 #> [16,]  0.1287637590 #> [17,] -0.1407074857 #> [18,]  0.1540956062 #> [19,]  0.3096533745 #> [20,] -0.2737300615 #> [21,] -0.0529224406 #> [22,]  0.2489194502 #> [23,]  0.0884256988 #> [24,] -0.0140912439 #> [25,]  0.0044153702 #> [26,] -0.0247163277 #> [27,] -0.0398773617 #> [28,]  0.3059863737 #> [29,] -0.1474950314 #> [30,] -0.0498461608 #> [31,] -0.3479733126 #> [32,]  0.2886978056 #> [33,] -0.1241452725 #> [34,]  0.2945319290 #> [35,] -0.3082694573 #> [36,] -0.2825422619 #> [37,] -0.0534942102 #> [38,]  0.0045059335 #> [39,]  0.1130271900 #>  #> $weights #>               [,1]         [,2]         [,3]         [,4]          [,5] #>  [1,]  0.052215879  0.240419308 -0.161908752  0.024740216 -0.2111604497 #>  [2,] -0.034827909  0.084474856 -0.173922160  0.067864937 -0.1175210182 #>  [3,] -0.001391453  0.141335334  0.154065251 -0.224649019  0.0089002370 #>  [4,]  0.269622725  0.313179816 -0.037979386 -0.054736782 -0.0012735403 #>  [5,]  0.027378727  0.211060958  0.007106119  0.071613945 -0.1542108542 #>  [6,] -0.002555356  0.099603511 -0.178109475 -0.187903009 -0.2954068622 #>  [7,] -0.116609767  0.181948312 -0.091708642  0.187746575  0.1348122575 #>  [8,] -0.199633821 -0.070587422 -0.459236466 -0.003164958 -0.1282159006 #>  [9,] -0.149144225 -0.050383249 -0.146224130  0.187872439  0.0326676473 #> [10,]  0.101522309  0.137118268 -0.246453561  0.093856356  0.0142865523 #> [11,] -0.189760666  0.026011039  0.053665156 -0.137372414  0.2331523845 #> [12,] -0.276556703  0.065526328 -0.067606740  0.057921765  0.1478701776 #> [13,]  0.218056618  0.280310383  0.065577276  0.231986307 -0.2279127641 #> [14,] -0.151591107  0.117880080 -0.112208565 -0.242467908  0.2201492887 #> [15,]  0.195864430  0.189164526 -0.185165309 -0.026577860  0.1077735435 #> [16,] -0.257267985 -0.042343842 -0.073419847  0.045830324 -0.2249531996 #> [17,] -0.148346511  0.020431183 -0.143372621  0.046835578 -0.3366421512 #> [18,] -0.084111601  0.053355845  0.094413706 -0.227346273 -0.0567815343 #> [19,] -0.195725609 -0.010192432 -0.019555057  0.118765157  0.0686796085 #> [20,]  0.007935439 -0.035123813  0.176232317  0.217041233 -0.0173703772 #> [21,]  0.056749548  0.140405020 -0.181444012 -0.108024779  0.0780527249 #> [22,]  0.013721499  0.193867288 -0.050439336  0.072322950  0.1762406678 #> [23,] -0.216454579  0.067135799 -0.177081772  0.015522853 -0.0345302368 #> [24,] -0.097751534  0.079034635  0.023245750  0.146139763  0.0076540950 #> [25,]  0.002239107  0.009120856  0.440139152  0.164461637 -0.1230349122 #> [26,] -0.081356991  0.257305767  0.140494374  0.136831602  0.0555499048 #> [27,]  0.173124225  0.196695428 -0.028694998  0.030037514 -0.0267072869 #> [28,] -0.073427432  0.078668734 -0.047100811  0.352253902 -0.0570259242 #> [29,]  0.050438770  0.209972241 -0.155411864  0.068260790  0.1590282865 #> [30,]  0.009624597  0.136710186  0.155944665 -0.024523385 -0.4211525788 #> [31,] -0.294404574  0.115712071  0.054534578  0.193810422  0.1746227806 #> [32,] -0.155982776  0.100292492  0.041414692 -0.030958106 -0.1892936819 #> [33,] -0.069622279  0.136210412 -0.001628406  0.296639360  0.0556256063 #> [34,]  0.015047130 -0.126879646  0.095115710  0.077653748  0.0529430847 #> [35,]  0.210646938  0.090614166 -0.054018010 -0.267620344  0.0007203354 #> [36,]  0.050204885 -0.235970969 -0.029264420  0.205742962 -0.1602293133 #> [37,]  0.187580708  0.035035882 -0.127899924  0.140120255  0.2123884365 #> [38,]  0.382605577 -0.160444754 -0.059080333  0.284081768  0.1337327840 #> [39,]  0.180538911 -0.415369848 -0.300875022  0.086247873 -0.1001053218 #>               [,6] #>  [1,] -0.029665386 #>  [2,] -0.430577447 #>  [3,]  0.162026460 #>  [4,]  0.047873822 #>  [5,] -0.031603106 #>  [6,] -0.005719541 #>  [7,]  0.234496364 #>  [8,]  0.060561520 #>  [9,] -0.038825188 #> [10,]  0.036902990 #> [11,]  0.006304792 #> [12,] -0.164474372 #> [13,] -0.029147353 #> [14,] -0.052668936 #> [15,]  0.236984837 #> [16,]  0.219672387 #> [17,] -0.131679559 #> [18,]  0.122756935 #> [19,]  0.245419135 #> [20,] -0.217703853 #> [21,] -0.117210298 #> [22,]  0.095201600 #> [23,]  0.127892607 #> [24,]  0.072265151 #> [25,] -0.041220612 #> [26,]  0.102400260 #> [27,]  0.071365384 #> [28,]  0.239776939 #> [29,] -0.144274171 #> [30,]  0.019200216 #> [31,] -0.317604921 #> [32,]  0.173622871 #> [33,] -0.124328637 #> [34,]  0.213372600 #> [35,] -0.227915458 #> [36,] -0.187689566 #> [37,] -0.070876063 #> [38,]  0.120492759 #> [39,]  0.091659035 #>  #> $center #>  [1]  0.52500  0.45000  0.47500  0.60000  0.53750  0.47500  0.52500  0.47500 #>  [9]  0.37500  0.50000  0.46250  0.51250  0.46250  0.40000  0.43750  0.48750 #> [17]  0.45000  0.51250  0.51250  0.51250  0.45000  0.55000  0.42500  0.42500 #> [25]  0.47500  0.46250  0.52500  0.51250  0.48750  0.40000  0.57500  0.48750 #> [33]  0.41250  0.70000 64.23634  1.77500  2.51250  0.55000  0.25000 #>  #> $scale #>  [1]  0.5025253  0.5006325  0.5025253  0.4929888  0.5017375  0.5025253 #>  [7]  0.5025253  0.5025253  0.4871774  0.5031546  0.5017375  0.5029973 #> [13]  0.5017375  0.4929888  0.4992082  0.5029973  0.5006325  0.5029973 #> [19]  0.5029973  0.5029973  0.5006325  0.5006325  0.4974619  0.4974619 #> [25]  0.5025253  0.5017375  0.5025253  0.5029973  0.5029973  0.4929888 #> [31]  0.4974619  0.5029973  0.4953901  0.4611488 13.5030422  0.7458747 #> [37]  0.8999824  0.7778581  0.4357447 #>  #> $cox_fit #> $cox_fit$coefficients #> [1] 5.004052 2.746088 2.826956 3.123682 2.212297 1.836690 #>  #> $cox_fit$var #>           [,1]      [,2]      [,3]      [,4]      [,5]      [,6] #> [1,] 1.8176427 1.0007947 1.0270697 1.1557178 0.8273513 0.6773313 #> [2,] 1.0007947 0.6200044 0.5764073 0.6590198 0.4650547 0.3822643 #> [3,] 1.0270697 0.5764073 0.6412628 0.6891091 0.4976229 0.3878208 #> [4,] 1.1557178 0.6590198 0.6891091 0.8165358 0.5775589 0.4726054 #> [5,] 0.8273513 0.4650547 0.4976229 0.5775589 0.4824611 0.3348504 #> [6,] 0.6773313 0.3822643 0.3878208 0.4726054 0.3348504 0.3287053 #>  #> $cox_fit$loglik #> [1] -56.43995 -13.11777 #>  #> $cox_fit$score #> [1] 47.66948 #>  #> $cox_fit$iter #> [1] 8 #>  #> $cox_fit$linear.predictors #>  [1]  -5.39087955  -6.15109660   5.09550487 -13.88375547   2.39351618 #>  [6] -13.29476930  -2.75192032  15.22802654  -6.75150764   3.03694859 #> [11]  20.46668210  -2.20388522   7.40235358   0.06153643   1.73042067 #> [16]   1.63285788 -15.14819858 -16.61315366   3.19944499  -5.09653794 #> [21]  -5.08886457   6.00858147   5.49932139   1.07251252 -16.68306316 #> [26]  -9.87033333  13.63075463  -2.21580410  -7.72364593 -20.89429368 #> [31]  23.69774455  -5.47242729  -4.64364378   2.09307288  13.01430218 #> [36]  -0.38140506  17.23261789   6.16118530  -8.87236032   9.57734124 #> [41]   4.72160666  10.63749894   4.78039144  -0.45588309  -9.78156407 #> [46]  -0.41319153 -19.01181143 -18.33508937  17.87312742  -1.80604943 #> [51]  -8.92843325   2.38355006   1.27385539  20.47855089  18.01160999 #> [56]  -9.62908763 -11.50954928   8.84579672   5.97522735   2.30930801 #> [61]   7.08300227  13.23913535  19.89632332 -16.62795366   9.81202643 #> [66]   5.95200818 -27.16404514  -3.36617391  13.19271845  -7.80186252 #> [71]   3.24305062   8.16133664  11.89873024 -18.82754928   6.58394537 #> [76]   4.97416410  -4.28205147 -10.53776977  -4.91879100 -17.03328838 #>  #> $cox_fit$residuals #>             1             2             3             4             5  #> -2.744308e-02 -1.781275e-09 -1.504830e-08 -1.243296e-15 -1.760046e-01  #>             6             7             8             9            10  #> -5.402201e-15 -2.047726e-10  1.600869e-01 -9.771827e-10 -9.588986e-10  #>            11            12            13            14            15  #>  5.583397e-01 -1.017192e-11 -5.262802e-06 -1.051131e-01 -2.596300e-10  #>            16            17            18            19            20  #> -2.354962e-10 -2.204648e-13 -1.956207e-16  6.059654e-01 -6.046914e-04  #>            21            22            23            24            25  #> -1.855479e-10 -2.322817e-07 -7.847668e-07 -4.696986e-02 -5.617846e-09  #>            26            27            28            29            30  #> -2.377997e-15 -2.501978e-02 -3.282543e-09 -1.419315e-12 -7.767146e-20  #>            31            32            33            34            35  #> -8.044200e-01 -8.592934e-10 -8.042840e-09 -2.514877e-04  1.856192e-01  #>            36            37            38            39            40  #> -1.097466e-02  8.261257e-02 -3.961750e-04 -6.450978e-15  5.523967e-01  #>            41            42            43            44            45  #> -5.169046e-09 -8.523020e-03 -1.586027e-07 -1.018698e-02 -2.598743e-15  #>            46            47            48            49            50  #> -3.069642e-03 -5.472771e-10 -3.278640e-16 -1.856164e-01  1.075299e-02  #>            51            52            53            54            55  #> -1.014002e-08 -7.175306e-02 -4.758185e-09 -4.216039e-02  9.969438e-01  #>            56            57            58            59            60  #> -5.498683e-11 -9.917412e-07 -3.195386e-07 -8.049978e-05 -1.617904e-01  #>            61            62            63            64            65  #> -6.801896e-07  5.303204e-01 -4.037155e-01 -1.927468e-16 -3.961013e-01  #>            66            67            68            69            70  #> -1.769160e-08 -4.800948e-20 -7.061154e-09 -9.098569e-01 -6.572449e-06  #>            71            72            73            74            75  #> -4.115968e-01 -2.056243e-01 -4.426646e-03 -1.361713e-15 -2.321597e-06  #>            76            77            78            79            80  #>  3.289011e-01 -2.220045e-04 -7.980437e-13 -6.108218e-09 -1.205199e-15  #>  #> $cox_fit$means #> [1] -3.747003e-16 -3.080869e-16 -4.024558e-17  3.635980e-16  1.804112e-17 #> [6]  1.942890e-16 #>  #> $cox_fit$method #> [1] \"efron\" #>  #> $cox_fit$class #> [1] \"coxph\" #>  #>  #> attr(,\"class\") #> [1] \"big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox-overview.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Overview of bigPLScox","text":"vignette(\"getting-started\", package = \"bigPLScox\") detailed walkthrough data preparation model diagnostics. vignette(\"bigPLScox-benchmarking\", package = \"bigPLScox\") reproducible performance comparisons. package website https://fbertran.github.io/bigPLScox/ hosts reference documentation additional examples.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Big-memory workflows with bigPLScox","text":"central feature bigPLScox ability operate file-backed bigmemory::big.matrix objects. vignette demonstrates prepare datasets, fit models big_pls_cox() big_pls_cox_gd(), integrate cross-validation helpers. examples complement introductory vignette “Getting started bigPLScox”.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"preparing-a-big-matrix","dir":"Articles","previous_headings":"","what":"Preparing a big.matrix","title":"Big-memory workflows with bigPLScox","text":"simulate moderately large design matrix persist disk via bigmemory::filebacked.big.matrix(). Using file-backed storage allows models train datasets exceed available RAM. resulting big.matrix can reopened future sessions via descriptor file. big-memory modelling functions accept either -memory matrix big.matrix reference.","code":"library(bigPLScox) library(bigmemory)  set.seed(2024) n_obs <- 5000 n_pred <- 100  X_dense <- matrix(rnorm(n_obs * n_pred), nrow = n_obs) time <- rexp(n_obs, rate = 0.2) status <- rbinom(n_obs, 1, 0.7)  big_dir <- tempfile(\"bigPLScox-\") dir.create(big_dir) X_big <- filebacked.big.matrix(   nrow = n_obs,   ncol = n_pred,   backingpath = big_dir,   backingfile = \"X.bin\",   descriptorfile = \"X.desc\",   init = X_dense )"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"fitting-big-memory-models","dir":"Articles","previous_headings":"","what":"Fitting big-memory models","title":"Big-memory workflows with bigPLScox","text":"big_pls_cox() runs classical PLS-Cox algorithm streaming data disk. gradient-descent variant big_pls_cox_gd() uses stochastic optimisation well-suited large datasets. functions return objects expose latent scores loading vectors, allowing downstream visualisations diagnostics identical -memory counterparts.","code":"fit_big <- big_pls_cox(   X = X_big,   time = time,   status = status,   ncomp = 5 )  head(fit_big$scores) #>               [,1]          [,2]          [,3]          [,4]          [,5] #> [1,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [2,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [3,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [4,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [5,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [6,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 str(fit_big) #> List of 9 #>  $ scores  : num [1:5000, 1:5] -4.45e-06 -4.45e-06 -4.45e-06 -4.45e-06 -4.45e-06 ... #>  $ loadings: num [1:100, 1:5] -0.1 -0.1 -0.1 -0.1 -0.1 ... #>  $ weights : num [1:100, 1:5] -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 ... #>  $ center  : num [1:100] 0.982 0.982 0.982 0.982 0.982 ... #>  $ scale   : num [1:100] 1.65e-07 1.65e-07 1.65e-07 1.65e-07 1.65e-07 ... #>  $ cox_fit :List of 10 #>   ..$ coefficients     : num [1:5] NA NA 1.82e+41 NA NA #>   ..$ var              : num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ... #>   ..$ loglik           : num [1:2] -26230 -26230 #>   ..$ score            : num 8.72e-20 #>   ..$ iter             : int 1 #>   ..$ linear.predictors: num [1:5000] 0.000392 0.000392 0.000392 0.000392 0.000392 ... #>   ..$ residuals        : Named num [1:5000] 0.8605 0.7913 -0.0129 0.1737 0.9958 ... #>   .. ..- attr(*, \"names\")= chr [1:5000] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : num [1:5] -4.45e-06 -1.67e-19 -1.67e-32 -1.71e-46 -1.15e-59 #>   ..$ method           : chr \"efron\" #>   ..$ class            : chr \"coxph\" #>  $ keepX   : int [1:5] 0 0 0 0 0 #>  $ time    : num [1:5000] 1.024 1.5182 0.1047 5.9911 0.0424 ... #>  $ status  : num [1:5000] 1 1 0 1 1 1 1 1 0 1 ... #>  - attr(*, \"class\")= chr \"big_pls_cox\" fit_big_gd <- big_pls_cox_gd(   X = X_big,   time = time,   status = status,   ncomp = 5,   max_iter = 100,   tol = 1e-4   )  head(fit_big$scores) #>               [,1]          [,2]          [,3]          [,4]          [,5] #> [1,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [2,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [3,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [4,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [5,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 #> [6,] -4.450742e-06 -1.669808e-19 -1.671178e-32 -1.707642e-46 -1.148375e-59 str(fit_big) #> List of 9 #>  $ scores  : num [1:5000, 1:5] -4.45e-06 -4.45e-06 -4.45e-06 -4.45e-06 -4.45e-06 ... #>  $ loadings: num [1:100, 1:5] -0.1 -0.1 -0.1 -0.1 -0.1 ... #>  $ weights : num [1:100, 1:5] -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 ... #>  $ center  : num [1:100] 0.982 0.982 0.982 0.982 0.982 ... #>  $ scale   : num [1:100] 1.65e-07 1.65e-07 1.65e-07 1.65e-07 1.65e-07 ... #>  $ cox_fit :List of 10 #>   ..$ coefficients     : num [1:5] NA NA 1.82e+41 NA NA #>   ..$ var              : num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ... #>   ..$ loglik           : num [1:2] -26230 -26230 #>   ..$ score            : num 8.72e-20 #>   ..$ iter             : int 1 #>   ..$ linear.predictors: num [1:5000] 0.000392 0.000392 0.000392 0.000392 0.000392 ... #>   ..$ residuals        : Named num [1:5000] 0.8605 0.7913 -0.0129 0.1737 0.9958 ... #>   .. ..- attr(*, \"names\")= chr [1:5000] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : num [1:5] -4.45e-06 -1.67e-19 -1.67e-32 -1.71e-46 -1.15e-59 #>   ..$ method           : chr \"efron\" #>   ..$ class            : chr \"coxph\" #>  $ keepX   : int [1:5] 0 0 0 0 0 #>  $ time    : num [1:5000] 1.024 1.5182 0.1047 5.9911 0.0424 ... #>  $ status  : num [1:5000] 1 1 0 1 1 1 1 1 0 1 ... #>  - attr(*, \"class\")= chr \"big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"cross-validation-on-big-matrices","dir":"Articles","previous_headings":"","what":"Cross-validation on big matrices","title":"Big-memory workflows with bigPLScox","text":"Cross-validation big-memory models supported list interface. enables streaming fold directly disk. large experiments consider combining foreach::foreach() doParallel::registerDoParallel() parallelise folds.","code":"set.seed(2024) data_big <- list(x = X_big, time = time, status = status) cv_big <- cv.coxgpls(   data_big,   nt = 5,   ncores = 1,   ind.block.x = c(10, 40) ) cv_big$opt_nt"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"timing-snapshot","dir":"Articles","previous_headings":"","what":"Timing snapshot","title":"Big-memory workflows with bigPLScox","text":"native C++ solvers substantially reduce wall-clock time compared fitting R interface alone. bench package provides convenient instrumentation; chunk runs available.","code":"if (requireNamespace(\"bench\", quietly = TRUE)) {   bench::mark(     streaming = big_pls_cox(X_big, time, status, ncomp = 5, keepX = 0),     gd = big_pls_cox_gd(X_big, time, status, ncomp = 5, max_iter = 150),     iterations = 5,     check = FALSE   ) } #> # A tibble: 2 × 6 #>   expression      min   median `itr/sec` mem_alloc `gc/sec` #>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #> 1 streaming    31.8ms   32.2ms      31.0    8.81MB     7.74 #> 2 gd           14.3ms   14.3ms      69.8    6.79MB    46.5"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"deviance-residuals-with-big-matrices","dir":"Articles","previous_headings":"","what":"Deviance residuals with big matrices","title":"Big-memory workflows with bigPLScox","text":"model fitted can evaluate deviance residuals using new C++ backend. Supplying linear predictor avoids recomputing R works matrix backend.","code":"eta_big <- predict(fit_big, type = \"link\") dr_cpp <- computeDR(time, status, engine = \"cpp\", eta = eta_big) max(abs(dr_cpp - computeDR(time, status))) #> [1] 3.877472"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"cleaning-up","dir":"Articles","previous_headings":"","what":"Cleaning up","title":"Big-memory workflows with bigPLScox","text":"Temporary backing files can removed analysis. production pipelines typically keep descriptor file alongside binary data.","code":"rm(X_big) file.remove(file.path(big_dir, \"X.bin\")) #> [1] TRUE file.remove(file.path(big_dir, \"X.desc\")) #> [1] TRUE unlink(big_dir, recursive = TRUE)"},{"path":"https://fbertran.github.io/bigPLScox/articles/bigPLScox.html","id":"additional-resources","dir":"Articles","previous_headings":"","what":"Additional resources","title":"Big-memory workflows with bigPLScox","text":"help(big_pls_cox) help(big_pls_cox_gd) document tuning parameters big-memory solvers. benchmarking vignette demonstrates measure performance improvements obtained file-backed matrices. Consider persisting fitted objects saveRDS() avoid recomputing large models iterating analyses.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting started with bigPLScox","text":"bigPLScox package provides tools fit Partial Least Squares (PLS) models tailored Cox proportional hazards setting. includes cross-validation helpers, diagnostic utilities, interfaces work -memory matrices bigmemory objects. vignette walks core workflow allelotyping dataset bundled package.","code":""},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"loading-the-data","dir":"Articles","previous_headings":"","what":"Loading the data","title":"Getting started with bigPLScox","text":"original factor-based design matrix also available prefer work categorical predictors directly.","code":"library(bigPLScox)  data(micro.censure) data(Xmicro.censure_compl_imp)  Y_all <- micro.censure$survyear[1:80] status_all <- micro.censure$DC[1:80] X_all <- apply(   as.matrix(Xmicro.censure_compl_imp),   MARGIN = 2,   FUN = as.numeric )[1:80, ]  set.seed(2024) train_id <- 1:60 test_id <- 61:80  X_train <- X_all[train_id, ] X_test <- X_all[test_id, ] Y_train <- Y_all[train_id] Y_test <- Y_all[test_id] status_train <- status_all[train_id] status_test <- status_all[test_id] X_train_raw <- Xmicro.censure_compl_imp[train_id, ] X_test_raw <- Xmicro.censure_compl_imp[test_id, ]"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"exploring-deviance-residuals","dir":"Articles","previous_headings":"","what":"Exploring deviance residuals","title":"Getting started with bigPLScox","text":"computeDR() extracts deviance residuals null Cox model. Inspecting fitting PLS components helps detect anomalies survival outcomes.","code":"residuals_overview <- computeDR(Y_train, status_train, plot = TRUE) eta_null <- rep(0, length(Y_train)) head(residuals_overview) #>          1          2          3          4          5          6  #> -1.3771591 -0.5360370 -0.2693493 -0.3994329 -0.8040940 -0.3994329  if (requireNamespace(\"bench\", quietly = TRUE)) {   benchmark_dr <- bench::mark(     survival = computeDR(Y_train, status_train, engine = \"survival\"),     cpp = computeDR(Y_train, status_train, engine = \"cpp\", eta = eta_null),     iterations = 10,     check = FALSE   )   benchmark_dr } #> # A tibble: 2 × 6 #>   expression      min   median `itr/sec` mem_alloc `gc/sec` #>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> #> 1 survival    731.2µs    751µs     1257.    80.8KB        0 #> 2 cpp          82.8µs   91.2µs     9579.   159.3KB        0  all.equal(   as.numeric(computeDR(Y_train, status_train, engine = \"survival\")),   as.numeric(computeDR(Y_train, status_train, engine = \"cpp\", eta = eta_null)),   tolerance = 1e-7 ) #> [1] TRUE"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"fitting-cox-pls-models","dir":"Articles","previous_headings":"","what":"Fitting Cox PLS models","title":"Getting started with bigPLScox","text":"matrix interface coxgpls() mirrors survival::coxph() adding latent components stabilise estimation high dimensions. formula interface also available working data frames include predictors survival outcomes.","code":"set.seed(123) cox_pls_fit <- coxgpls(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,     ind.block.x = c(3, 10, 20) ) cox_pls_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>          coef exp(coef) se(coef)      z        p #> dim.1 -0.7368    0.4786   0.1162 -6.340  2.3e-10 #> dim.2 -0.5256    0.5912   0.1382 -3.804 0.000142 #> dim.3 -0.3314    0.7179   0.1199 -2.763 0.005720 #> dim.4 -0.2883    0.7495   0.1092 -2.641 0.008272 #> dim.5 -0.4002    0.6702   0.1435 -2.788 0.005298 #> dim.6 -0.2696    0.7636   0.1239 -2.176 0.029529 #>  #> Likelihood ratio test=60.94  on 6 df, p=2.906e-11 #> n= 60, number of events= 60 cox_pls_fit_formula <- coxgpls(   ~ ., Y_train, status_train,   ncomp = 6,   ind.block.x = c(3, 10, 20),   dataXplan = data.frame(X_train_raw) ) cox_pls_fit_formula #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>           coef exp(coef) se(coef)      z       p #> dim.1 -0.82612   0.43775  0.31903 -2.589 0.00961 #> dim.2 -0.79075   0.45350  0.39461 -2.004 0.04508 #> dim.3 -0.89888   0.40703  0.30294 -2.967 0.00301 #> dim.4  0.02354   1.02382  0.29663  0.079 0.93675 #> dim.5 -0.40714   0.66555  0.40456 -1.006 0.31423 #> dim.6 -0.53689   0.58456  0.38554 -1.393 0.16374 #>  #> Likelihood ratio test=19.59  on 6 df, p=0.00328 #> n= 60, number of events= 11"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"cross-validation-utilities","dir":"Articles","previous_headings":"","what":"Cross-validation utilities","title":"Getting started with bigPLScox","text":"Repeated cross-validation helps determine appropriate number latent components. Provide either matrix list x, time, status entries.  selected number components stored cv_results$opt_nt. Use refit model deviance residual solver comparison.","code":"set.seed(123456) cv_results <- suppressWarnings(cv.coxgpls(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) )) #> CV Fold 1  #> CV Fold 2  #> CV Fold 3  #> CV Fold 4  #> CV Fold 5 cv_results #> $nt #> [1] 6 #>  #> $cv.error10 #> [1] 0.5000000 0.5492633 0.4897065 0.5589258 0.6112917 0.6294183 0.6482323 #>  #> $cv.se10 #> [1] 0.00000000 0.03211886 0.04830433 0.06137605 0.05429528 0.04481718 0.04814978 #>  #> $folds #> $folds$`1` #>  [1] 60 45  3 57 21 15 35 22 51 12 20 13 #>  #> $folds$`2` #>  [1] 42 54 50 28  1 41  6 18 44  8 27 25 #>  #> $folds$`3` #>  [1] 59 36 55 52 24 46 37 19  4 47 33  5 #>  #> $folds$`4` #>  [1] 49 38 30  2 34 48 53 31 11 56 26 39 #>  #> $folds$`5` #>  [1]  7 10 23 16 14 58 29  9 43 17 40 32 #>  #>  #> $lambda.min10 #> [1] 6 #>  #> $lambda.1se10 #> [1] 0 set.seed(123456) cox_pls_dr <- coxgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = cv_results$nt,   ind.block.x = c(3, 10, 20) ) cox_pls_dr #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7329    2.0812   0.1120 6.545 5.95e-11 #> dim.2 0.6418    1.8999   0.1456 4.409 1.04e-05 #> dim.3 0.3467    1.4144   0.1080 3.210  0.00133 #> dim.4 0.4266    1.5320   0.1554 2.745  0.00605 #> dim.5 0.3694    1.4468   0.1453 2.542  0.01101 #> dim.6 0.2884    1.3343   0.1095 2.633  0.00847 #>  #> Likelihood ratio test=63.84  on 6 df, p=7.442e-12 #> n= 60, number of events= 60"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"dk-splines-extension","dir":"Articles","previous_headings":"","what":"DK-splines extension","title":"Getting started with bigPLScox","text":"flexible baseline hazards coxDKgplsDR() estimator augments PLS components DK-splines. interface mirrors previous functions. Cross-validation available DK-splines estimator well.","code":"cox_DKsplsDR_fit <- coxDKgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,   validation = \"CV\",   ind.block.x = c(3, 10, 20),   verbose = FALSE ) cox_DKsplsDR_fit #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>           coef exp(coef) se(coef)     z        p #> dim.1   4.8792  131.5255   0.7348 6.640 3.14e-11 #> dim.2   4.3106   74.4853   0.8523 5.058 4.25e-07 #> dim.3   4.3799   79.8304   1.0374 4.222 2.42e-05 #> dim.4   3.1313   22.9036   0.9043 3.463 0.000535 #> dim.5   1.9561    7.0716   0.7031 2.782 0.005400 #> dim.6   1.9467    7.0054   0.7344 2.651 0.008031 #>  #> Likelihood ratio test=77.54  on 6 df, p=1.151e-14 #> n= 60, number of events= 60 set.seed(123456) cv_coxDKgplsDR_res <- suppressWarnings(cv.coxDKgplsDR(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) )) #> Kernel :  rbfdot  #> Estimated_sigma  0.01316859  #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01209314  #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01249337  #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01189281  #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01321752  #> CV Fold 5 cv_coxDKgplsDR_res #> $nt #> [1] 6 #>  #> $cv.error10 #> [1] 0.5000000 0.5452198 0.4876477 0.6527581 0.7470071 0.7076771 0.7861610 #>  #> $cv.se10 #> [1] 0.000000000 0.034240301 0.027002603 0.030718584 0.014706929 0.019091539 #> [7] 0.004390742 #>  #> $folds #> $folds$`1` #>  [1] 60 45  3 57 21 15 35 22 51 12 20 13 #>  #> $folds$`2` #>  [1] 42 54 50 28  1 41  6 18 44  8 27 25 #>  #> $folds$`3` #>  [1] 59 36 55 52 24 46 37 19  4 47 33  5 #>  #> $folds$`4` #>  [1] 49 38 30  2 34 48 53 31 11 56 26 39 #>  #> $folds$`5` #>  [1]  7 10 23 16 14 58 29  9 43 17 40 32 #>  #>  #> $lambda.min10 #> [1] 6 #>  #> $lambda.1se10 #> [1] 0  # Unified prediction comparison  if (requireNamespace(\"bigmemory\", quietly = TRUE)) {   library(bigmemory)   X_big_train <- bigmemory::as.big.matrix(X_train)   X_big_test <- bigmemory::as.big.matrix(X_test)   big_fit <- big_pls_cox(X_big_train, Y_train, status_train, ncomp = 4)   gd_fit <- big_pls_cox_gd(X_big_train, Y_train, status_train, ncomp = 4, max_iter = 200)    risk_table <- data.frame(     subject = seq_along(test_id),     big_pls = predict(big_fit, newdata = X_big_test, type = \"link\", comps = 1:4),     big_pls_gd = predict(gd_fit, newdata = X_big_test, type = \"link\", comps = 1:4)   )    if (requireNamespace(\"plsRcox\", quietly = TRUE)) {     pls_fit <- try(plsRcox::plsRcox(Y_train, status_train, X_train_raw, nt = 4), silent = TRUE)     if (!inherits(pls_fit, \"try-error\") && !is.null(pls_fit$Coefficients)) {       risk_table$plsRcox <- as.numeric(as.matrix(X_test_raw) %*% pls_fit$Coefficients)     }   }    risk_table    apply(     risk_table[-1],     2,     function(lp) {       survival::concordance(survival::Surv(Y_test, status_test) ~ lp)$concordance     }   ) } #> ____************************************************____ #>    big_pls big_pls_gd  #>  0.3023256  0.3023256"},{"path":"https://fbertran.github.io/bigPLScox/articles/getting-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Getting started with bigPLScox","text":"vignette(\"bigPLScox-overview\", package = \"bigPLScox\") summarises main modelling functions big-memory counterparts. vignette(\"bigPLScox-benchmarking\", package = \"bigPLScox\") explains reproduce performance comparisons scripts inst/benchmarks/. README package website provide references data preparation tips large-scale studies.","code":""},{"path":"https://fbertran.github.io/bigPLScox/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer, author. Myriam Maumy-Bertrand. Author.","code":""},{"path":"https://fbertran.github.io/bigPLScox/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frederic Bertrand Myriam Maumy-Bertrand (2025). Partial Least Squares Cox Models Big Matrices, R package version 0.6.0. Maumy, M. Bertrand, F. (2023). PLS models extension big data. Conference presentation Joint Statistical Meetings (JSM 2023), Toronto, Ontario, Canada, Aug 5–10, 2023. Maumy, M. Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. Poster BioC2023: Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA, Aug 2–4, 2023. doi:10.7490/f1000research.1119546.1.","code":"@Manual{,   title = {Partial Least Squares for Cox Models with Big Matrices},   author = {Frederic Bertrand and Myriam Maumy-Bertrand},   publisher = {manual},   year = {2025},   note = {R package version 0.6.0},   url = {https://fbertran.github.io/bigPLScox/}, } @Misc{,   title = {PLS models and their extension for big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at the Joint Statistical Meetings (JSM 2023)},   address = {Toronto, Ontario, Canada},   note = {Aug 5–10, 2023}, } @Misc{,   title = {bigPLS: Fitting and cross-validating PLS-based Cox models to censored big data},   author = {Myriam Maumy and Frédéric Bertrand},   year = {2023},   howpublished = {Conference presentation at BioC2023: The Bioconductor Annual Conference},   address = {Dana-Farber Cancer Institute, Boston, MA, USA},   note = {Aug 2–4, 2023},   doi = {10.7490/f1000research.1119546.1},   url = {https://doi.org/10.7490/f1000research.1119546.1}, }"},{"path":[]},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"frédéric-bertrand-and-myriam-maumy-bertrand","dir":"","previous_headings":"","what":"Frédéric Bertrand and Myriam Maumy-Bertrand","title":"Partial Least Squares for Cox Models with Big Matrices","text":"bigPLScox provides Partial Least Squares (PLS) methods tailored Cox proportional hazards models large, high-dimensional feature matrices. package works directly bigmemory objects, enabling native C++ accelerators iterative algorithms run without loading full dataset memory. addition classical coxgpls() solver, package contains accelerated variants, cross-validation helpers, model diagnostics. Generalised PLS Cox regression via coxgpls() support grouped predictors. Sparse structured sparse extensions (coxsgpls(), coxspls_sgpls()). Deviance-residual estimators (coxgplsDR(), coxsgplsDR()) robust fits. Cross-validation helpers (cv.coxgpls(), cv.coxsgpls(), …) select number latent components. Dataset generators, diagnostics computeDR() quick residual exploration. High-performance deviance residuals via computeDR(engine = \"cpp\") -memory big-memory workflows. Sparse, group-sparse, stochastic gradient variants able consume file-backed big.matrix objects leveraging foreach parallelism. Interfaces big-memory data big_pls_cox() big_pls_cox_gd(). GPU support available current release; ongoing development focuses improving multi-core CPU back-end instead. Additional articles available vignettes/ directory: Getting started bigPLScox — walkthrough core modelling, cross-validation, diagnostic helpers. Overview bigPLScox — tour main modelling functions practical guidance choosing estimators. Big-memory workflows bigPLScox — guidance using bigmemory matrices parallel back-ends. Benchmarking bigPLScox — reproducible performance comparisons using bench package. Standalone benchmarking scripts complement vignette live inst/benchmarks/. documentation website examples maintained Frédéric Bertrand Myriam Maumy.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"key-features","dir":"","previous_headings":"","what":"Key features","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Scalable Cox-PLS solvers (coxgpls(), coxgplsDR()) operate big matrices stored disk. Cross-validation tooling select optimal number PLS components time-dependent performance metrics. Model diagnostics deviance residual visualisation computeDR(). Benchmark scripts inst/benchmarks/ quantify runtime trade-offs available solvers. Comprehensive vignette (vignettes/bigPLScox.Rmd) showing complete modelling workflow.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partial Least Squares for Cox Models with Big Matrices","text":"can install released version bigPLScox CRAN : can install development version bigPLScox GitHub :","code":"install.packages(\"bigPLScox\") # install.packages(\"devtools\") devtools::install_github(\"fbertran/bigPLScox\")"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"learning-materials","dir":"","previous_headings":"","what":"Learning materials","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Browse Getting started vignette vignette(\"getting-started\",   package = \"bigPLScox\") worked example. Explore vignette(\"bigPLScox\", package = \"bigPLScox\") big-memory workflows streaming solvers. Consult function reference https://fbertran.github.io/bigPLScox/. Run benchmarking scripts inst/benchmarks/ compare solver performance simulated data.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Partial Least Squares for Cox Models with Big Matrices","text":"following example demonstrates typical workflow subset allelotyping dataset bundled package. Chunks evaluated default README rendered locally, can toggled knitr::opts_chunk$set(eval = FALSE) faster builds. Fit Cox-PLS model six components inspect fit summary: Visualise deviance residuals assess baseline model fit verify agreement R C++ engines: plot chunk unnamed-chunk-5 Cross-validate number components re-fit using deviance residual solver comparison: Explore alternative estimators coxgplsDR() deviance-residual fitting coxsgpls() sparse component selection. Refer package reference full list available models helper functions.","code":"library(bigPLScox) data(micro.censure) data(Xmicro.censure_compl_imp) Y_train <- micro.censure$survyear[1:80] status_train <- micro.censure$DC[1:80] X_train <- Xmicro.censure_compl_imp[1:80, ] set.seed(123) cox_pls_fit <- coxgpls(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = 6,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cox_pls_fit #> Error: object 'cox_pls_fit' not found residuals_overview <- computeDR(Y_train, status_train, plot = TRUE) head(residuals_overview) #>          1          2          3          4          5          6  #> -1.4843296 -0.5469540 -0.2314550 -0.3400301 -0.9763372 -0.3866766  cpp_residuals <- computeDR(   Y_train,   status_train,   engine = \"cpp\",   eta = predict(cox_pls_fit, type = \"lp\") ) #> Error: object 'cox_pls_fit' not found stopifnot(all.equal(residuals_overview, cpp_residuals, tolerance = 1e-7)) #> Error: object 'cpp_residuals' not found set.seed(123) cv_results <- cv.coxgpls(   list(x = X_train, time = Y_train, status = status_train),   nt = 6,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cv_results$opt_nt #> Error: object 'cv_results' not found cox_pls_dr <- coxgplsDR(   Xplan = X_train,   time = Y_train,   status = status_train,   ncomp = cv_results$opt_nt,   ind.block.x = c(3, 10, 20) ) #> Error in colMeans(x, na.rm = TRUE): 'x' must be numeric cox_pls_dr #> Error: object 'cox_pls_dr' not found"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"benchmarking","dir":"","previous_headings":"","what":"Benchmarking","title":"Partial Least Squares for Cox Models with Big Matrices","text":"provide reproducible benchmarks compare coxgpls() big-memory solvers survival::coxph(). Start Benchmarking bigPLScox vignette interactive tour. command-line experiments, execute scripts inst/benchmarks/ installing optional dependencies listed Suggests DESCRIPTION file. script accepts environment variables (example, bigPLScox.benchmark.n, bigPLScox.benchmark.p, bigPLScox.benchmark.ncomp) control simulation size. Results stored inst/benchmarks/results/ time-stamped filenames traceability.","code":"Rscript inst/benchmarks/cox-benchmark.R Rscript inst/benchmarks/cox_pls_benchmark.R Rscript inst/benchmarks/benchmark_bigPLScox.R"},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"vignettes-and-documentation","dir":"","previous_headings":"","what":"Vignettes and documentation","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Four vignettes ship package: Getting started bigPLScox – end--end introduction covering data preparation, fitting, validation workflows. Overview bigPLScox – high-level description modelling functions typical use cases. Big-memory workflows bigPLScox – instructions working bigmemory matrices streaming solvers. Benchmarking bigPLScox – guidance evaluating performance baseline Cox implementations using bench package. full reference documentation pkgdown website available https://fbertran.github.io/bigPLScox/.","code":""},{"path":"https://fbertran.github.io/bigPLScox/index.html","id":"bug-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bug reports and feature requests","title":"Partial Least Squares for Cox Models with Big Matrices","text":"Bug reports feature requests can filed issue tracker. Please make sure new code comes unit tests reproducible examples applicable.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputed Microsat features — Xmicro.censure_compl_imp","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"dataset provides imputed microsat specifications. Imputations computed using Multivariate Imputation Chained Equations (MICE) using predictive mean matching numeric columns, logistic regression imputation binary data factors 2 levels polytomous regression imputation categorical data .e. factors three levels.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"data frame 117 observations following 40 variables. D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/Xmicro.censure_compl_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputed Microsat features — Xmicro.censure_compl_imp","text":"","code":"# \\donttest{ data(Xmicro.censure_compl_imp) X_train_micro <- Xmicro.censure_compl_imp[1:80,] X_test_micro <- Xmicro.censure_compl_imp[81:117,] rm(X_train_micro,X_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLS-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bigPLScox-package — bigPLScox-package","title":"bigPLScox-package — bigPLScox-package","text":"Provides Partial least squares Regression regular, generalized linear Cox models big data. allows missing data explanatory variables. Repeated k-fold cross-validation models using various criteria. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLS-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bigPLScox-package — bigPLScox-package","text":"TODO","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLS-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bigPLScox-package — bigPLScox-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy-Bertrand myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLS-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bigPLScox-package — bigPLScox-package","text":"","code":"set.seed(314) library(bigPLScox) data(sim_data) head(sim_data) #>                    status         X1         X2         X3        X4         X5 #> 0.0013236229370777      1  0.5448667 -0.9205711  1.1017160 1.3558567  1.4346174 #> 0.193665925040523       1 -0.5641483  0.2733279  0.9731780 1.1232252  0.2652977 #> 0.0167866701431944      1  1.4921118  0.2598002 -1.5436997 0.1165158  1.2208183 #> 0.0584127055299712      1 -0.6430141 -0.9807448 -1.2294945 0.8006227  1.5492078 #> 0.732960708716205       1  0.1876928 -1.2571263  0.9016827 1.3562191 -1.6809553 #> 0.508483386474255       0 -0.6141516 -0.8162560  0.2633415 0.4188066  0.2791399 #>                            X6         X7         X8          X9        X10 #> 0.0013236229370777 -0.8727406  1.5161252  0.7801527 -0.53617252 -0.6990319 #> 0.193665925040523   1.5046047  0.9096495 -1.2200395 -1.57280359  0.8347194 #> 0.0167866701431944 -0.6451659  1.2515692  0.5867273 -0.20080821  0.7492891 #> 0.0584127055299712  1.2557210  0.6188920  0.7123894 -0.67379538 -1.2377412 #> 0.732960708716205   0.7304366 -1.1223302  0.9633307  0.14016470 -0.9996676 #> 0.508483386474255  -0.0538974 -0.1410697 -0.8637916  0.01669784  1.5589135"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bigPLScox-package — bigPLScox-package","title":"bigPLScox-package — bigPLScox-package","text":"Provides Partial least squares Regression regular, generalized linear Cox models big data. allows missing data explanatory variables. Repeated k-fold cross-validation models using various criteria. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bigPLScox-package — bigPLScox-package","text":"Maumy, M., Bertrand, F. (2023). PLS models extension big data. Joint Statistical Meetings (JSM 2023), Toronto, , Canada. Maumy, M., Bertrand, F. (2023). bigPLS: Fitting cross-validating PLS-based Cox models censored big data. BioC2023 — Bioconductor Annual Conference, Dana-Farber Cancer Institute, Boston, MA, USA. Poster. https://doi.org/10.7490/f1000research.1119546.1 Bastien, P., Bertrand, F., Meyer, N., Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS binary classification survival analysis. BMC Bioinformatics, 16, 211.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"bigPLScox-package — bigPLScox-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy-Bertrand myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigPLScox-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bigPLScox-package — bigPLScox-package","text":"","code":"set.seed(314) library(bigPLScox) data(sim_data) head(sim_data) #>                    status         X1         X2         X3        X4         X5 #> 0.0013236229370777      1  0.5448667 -0.9205711  1.1017160 1.3558567  1.4346174 #> 0.193665925040523       1 -0.5641483  0.2733279  0.9731780 1.1232252  0.2652977 #> 0.0167866701431944      1  1.4921118  0.2598002 -1.5436997 0.1165158  1.2208183 #> 0.0584127055299712      1 -0.6430141 -0.9807448 -1.2294945 0.8006227  1.5492078 #> 0.732960708716205       1  0.1876928 -1.2571263  0.9016827 1.3562191 -1.6809553 #> 0.508483386474255       0 -0.6141516 -0.8162560  0.2633415 0.4188066  0.2791399 #>                            X6         X7         X8          X9        X10 #> 0.0013236229370777 -0.8727406  1.5161252  0.7801527 -0.53617252 -0.6990319 #> 0.193665925040523   1.5046047  0.9096495 -1.2200395 -1.57280359  0.8347194 #> 0.0167866701431944 -0.6451659  1.2515692  0.5867273 -0.20080821  0.7492891 #> 0.0584127055299712  1.2557210  0.6188920  0.7123894 -0.67379538 -1.2377412 #> 0.732960708716205   0.7304366 -1.1223302  0.9633307  0.14016470 -0.9996676 #> 0.508483386474255  -0.0538974 -0.1410697 -0.8637916  0.01669784  1.5589135"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"Performs stochastic gradient descent optimisation large-scale survival models removing observations missing values.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"","code":"bigSurvSGD.na.omit(   formula = survival::Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   features.mean = NULL,   features.sd = NULL,   opt.method = \"AMSGrad\",   beta.init = NULL,   beta.type = \"averaged\",   lr.const = 0.12,   lr.tau = 0.5,   strata.size = 20,   batch.size = 1,   num.epoch = 100,   b1 = 0.9,   b2 = 0.99,   eps = 1e-08,   inference.method = \"plugin\",   num.boot = 1000,   num.epoch.boot = 100,   boot.method = \"SGD\",   lr.const.boot = 0.12,   lr.tau.boot = 0.5,   num.sample.strata = 1000,   sig.level = 0.05,   beta0 = 0,   alpha = NULL,   lambda = NULL,   nlambda = 100,   num.strata.lambda = 10,   lambda.scale = 1,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"float\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"formula Model formula describing survival outcome set predictors include optimisation. data Input data set connection big-memory backed design matrix contains variables referenced formula. norm.method Normalization strategy applied feature matrix optimisation, example centring standardising columns. features.mean Optional pre-computed column means used normalising features repeated fits can reuse shared statistics. features.sd Optional pre-computed column standard deviations used concert features.mean scaling predictors. opt.method Gradient based optimisation routine employ, vanilla SGD adaptive methods like Adam. beta.init Vector starting values regression coefficients supplied warm-starting optimisation. beta.type Indicator controlling beta.init interpreted, example whether coefficients correspond original normalised scale. lr.const Base learning-rate constant used stochastic gradient descent routine. lr.tau Learning-rate decay horizon damping factor moderates step size schedule. strata.size Number observations drawn per stratum building mini-batches optimisation loop. batch.size Total number observations assembled stochastic gradient batch. num.epoch Number passes training data used optimisation. b1 First exponential moving-average rate used adaptive methods Adam smooth gradients. b2 Second exponential moving-average rate used adaptive methods smooth squared gradients. eps Numerical stabilisation constant added denominators updating adaptive moments. inference.method Inference approach requested fitting, example naive asymptotics bootstrap resampling. num.boot Number bootstrap replicates draw inference.method relies resampling. num.epoch.boot Number optimisation epochs run within bootstrap replicate. boot.method Type bootstrap scheme apply, ordinary stratified resampling. lr.const.boot Learning-rate constant used bootstrap refits. lr.tau.boot Learning-rate decay factor applied bootstrap refits. num.sample.strata Number strata sampled without replacement bootstrap iteration stratified resampling selected. sig.level Significance level used constructing confidence intervals hypothesis tests. beta0 Optional vector coefficients null hypothesis performing hypothesis tests. alpha Elastic-net mixing parameter controlling relative weight \\(\\ell_1\\) \\(\\ell_2\\) regularisation penalties. lambda Sequence regularisation strengths supplied explicitly penalised estimation. nlambda Number automatically generated lambda values grid produced internally. num.strata.lambda Number strata used tuning lambda via cross-validation search procedures. lambda.scale Scale lambda grid generated, example logarithmic linear spacing. parallel.flag Logical flag enabling parallel computation gradients bootstrap replicates. num.cores Number processing cores use parallel execution enabled. bigmemory.flag Logical flag indicating whether intermediate matrices stored using bigmemory backed objects. num.rows.chunk Row chunk size use streaming data -disk matrix representation. col.names Optional character vector column names associated feature matrix. type Type survival model fit, example Cox proportional hazards accelerated failure time variants.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"fitted model object storing learned coefficients, optimisation metadata, requested inference summaries. coef: Log hazards ratio. inference used, returns vector estimated coefficients: inference used, returns matrix including estimates confidence intervals coefficients. case penalization, resturns matrix columns corresponding lambdas. coef.exp: Exponentiated version coef (hazards ratio). lambda: Returns lambda(s) used penalizarion. alpha: Returns alpha used penalizarion. features.mean: Returns means features, given calculated features.sd: Returns standard deviations features, given calculated.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigSurvSGD.na.omit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Survival Models with Stochastic Gradient Descent — bigSurvSGD.na.omit","text":"","code":"data(micro.censure, package = \"bigPLScox\") surv_data <- stats::na.omit(micro.censure[, c(\"survyear\", \"DC\", \"sexe\", \"Agediag\")]) # Increase num.epoch and num.boot for real use fit <- bigSurvSGD.na.omit(   survival::Surv(survyear, DC) ~ .,   data = surv_data,   norm.method = \"standardize\",   opt.method = \"adam\",   batch.size = 64,   num.epoch = 1,   num.boot = 100 ) #> Warning: Strata size times batch size is greater than number of observations. #>  This package resizes them to strata size = 20 and batch size = 4"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"Compute Partial Least Squares (PLS) components tailored Cox proportional hazards models predictors stored big.matrix bigmemory package.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"","code":"big_pls_cox(   X,   time,   status,   ncomp = 2L,   control = survival::coxph.control(),   keepX = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"X numeric matrix bigmemory::big.matrix object containing predictors. time Numeric vector survival times. status Integer (0/1) vector event indicators. ncomp Number latent components compute. control Optional list passed survival::coxph.control. keepX Optional integer vector specifying number variables retain (naive sparsity) component. value zero keeps predictors. single integer supplied recycled across components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"list computed scores, loadings, weights, scaling information fitted Cox model returned survival::coxph.fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"function standardises predictor column, iteratively builds latent scores using martingale residuals Cox fits, deflates predictors without materialising full design matrix memory. -memory file-backed bigmemory matrices supported.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares Components for Cox Models with Big Matrices — big_pls_cox","text":"","code":"if (requireNamespace(\"survival\", quietly = TRUE)) {   set.seed(1)   X <- matrix(rnorm(100), nrow = 20)   time <- rexp(20)   status <- rbinom(20, 1, 0.5)   fit <- big_pls_cox(X, time, status, ncomp = 2)   str(fit) } #> List of 9 #>  $ scores  : num [1:20, 1:2] 0.315 0.28 -1.226 1.668 -0.372 ... #>  $ loadings: num [1:5, 1:2] 0.6905 0.0875 0.2379 0.2205 -0.6772 ... #>  $ weights : num [1:5, 1:2] 0.681 0.273 0.248 0.117 -0.622 ... #>  $ center  : num [1:5] 0.19052 -0.00647 0.1388 0.10174 0.11985 #>  $ scale   : num [1:5] 0.913 0.871 0.81 1.05 0.911 #>  $ cox_fit :List of 10 #>   ..$ coefficients     : num [1:2] 0.756 0.247 #>   ..$ var              : num [1:2, 1:2] 0.1286 0.0544 0.0544 0.2571 #>   ..$ loglik           : num [1:2] -18.5 -15.8 #>   ..$ score            : num 4.82 #>   ..$ iter             : int 4 #>   ..$ linear.predictors: num [1:20] 0.0329 0.0502 -0.7536 1.4699 -0.5345 ... #>   ..$ residuals        : Named num [1:20] -0.26 -0.125 -0.504 0.837 0.921 ... #>   .. ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ means            : num [1:2] 7.77e-17 -3.33e-17 #>   ..$ method           : chr \"efron\" #>   ..$ class            : chr \"coxph\" #>  $ keepX   : int [1:2] 0 0 #>  $ time    : num [1:20] 0.7632 1.5727 1.8356 0.0372 0.1256 ... #>  $ status  : num [1:20] 0 1 0 1 1 1 0 0 0 1 ... #>  - attr(*, \"class\")= chr \"big_pls_cox\""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"Fits Cox proportional hazards regression model using gradient-descent optimizer implemented C++. function operates directly bigmemory::big.matrix object avoid materialising large design matrices memory.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"","code":"big_pls_cox_gd(   X,   time,   status,   ncomp = NULL,   max_iter = 500L,   tol = 1e-06,   learning_rate = 0.01,   keepX = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"X bigmemory::big.matrix containing design matrix (rows observations). time numeric vector follow-times length equal number rows X. status numeric integer vector length time containing event indicators (1 event, 0 censoring). ncomp integer giving number components (columns) use X. Defaults min(5, ncol(X)). max_iter Maximum number gradient-descent iterations (default 500). tol Convergence tolerance Euclidean distance successive coefficient vectors. learning_rate Step size used gradient-descent updates. keepX Optional integer vector describing number predictors retain per component (naive sparsity). value zero keeps predictors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"list components: coefficients: Estimated Cox regression coefficients latent scores. loglik: Final partial log-likelihood value. iterations: Number gradient-descent iterations performed. converged: Logical flag indicating whether convergence achieved. scores: Matrix latent score vectors (one column per component). loadings: Matrix loading vectors associated component. weights: Matrix PLS weight vectors. center: Column means used centre predictors. scale: Column scales (standard deviations) used standardise predictors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/big_pls_cox_gd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient-Descent Solver for Cox Models on Big Matrices — big_pls_cox_gd","text":"","code":"if (FALSE) { # \\dontrun{ library(bigmemory) set.seed(1) n <- 50 p <- 10 X <- bigmemory::as.big.matrix(matrix(rnorm(n * p), n, p)) time <- rexp(n, rate = 0.1) status <- rbinom(n, 1, 0.7) fit <- big_pls_cox_gd(X, time, status, ncomp = 3, max_iter = 200) } # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"methods extend base matrix multiplication operator (%*%) group generic Arithmetic big.matrix objects can interoperate base R matrices numeric scalars using high-performance routines provided bigalgebra.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"# S4 method for class 'big.matrix,big.matrix' x %*% y  # S4 method for class 'matrix,big.matrix' x %*% y  # S4 method for class 'big.matrix,matrix' x %*% y  # S4 method for class 'big.matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,matrix' Arith(e1, e2)  # S4 method for class 'matrix,big.matrix' Arith(e1, e2)  # S4 method for class 'numeric,big.matrix' Arith(e1, e2)  # S4 method for class 'big.matrix,numeric' Arith(e1, e2)"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"x, y Matrix operands supplied either big.matrix instances base R matrices, depending method signature. e1, e2 Numeric operands, may big.matrix objects, base R matrices, numeric scalars depending method signature.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"Matrix multiplications dispatch bigalgebra::dgemm(), mixed arithmetic matrices relies bigalgebra::daxpy(), scalar/matrix combinations use bigalgebra::dadd() appropriate.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigmatrix-operations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix and arithmetic operations for big.matrix objects — bigmatrix-operations","text":"","code":"if (requireNamespace(\"bigmemory\", quietly = TRUE) &&     requireNamespace(\"bigalgebra\", quietly = TRUE)) {   x <- bigmemory::big.matrix(2, 2, init = 1)   y <- bigmemory::big.matrix(2, 2, init = 2)   x %*% y   x + y   x * 3 } #> An object of class \"big.matrix\" #> Slot \"address\": #> <pointer: 0x118b72d40> #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares Regression generalized linear models — bigplsRcox","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"function implements extension Partial least squares Regression Cox Models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"","code":"bigplsRcox(formula, data, ...)  bigplsRcoxmodel(formula, data, ...)  # Default S3 method bigplsRcoxmodel(   formula = Surv(time = time, status = status) ~ .,   data,   deepcopy_data = TRUE,   scale.X = TRUE,   scale.Y = TRUE,   nt = 2,   type = \"double\",   allres = TRUE,   verbose = TRUE,   backingfile = NULL,   backingpath = NULL,   descriptorfile = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"... arguments pass plsRmodel.default plsRmodel.formula nt number components extracted type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. verbose details displayed ? Xplan formula matrix eXplanatory variables (training) dataset time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? limQ2set limit value Q2 dataPredictY predictor(s) (testing) dataset pvals.expli individual p-values reported tune model selection ? alpha.pvals.expli level significance predictors pvals.expli=TRUE tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxDKplsDR called. model_frame TRUE, model frame returned. method method used fitting model. default method \"glm.fit\" uses iteratively reweighted least squares (IWLS). User-supplied fitting functions can supplied either function character string naming function, function takes arguments glm.fit. control list parameters controlling fitting process. glm.fit passed glm.control. sparse coefficients non-significant predictors (<alpha.pvals.expli) set 0 sparseStop component extraction stop significant predictors (<alpha.pvals.expli) found model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"Depends model used fit model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"bigplsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigplsRcox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares Regression generalized linear models — bigplsRcox","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  bigplsRcox(X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default bigplsRcox(~X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(~X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default  bigplsRcox(Xplan=X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5,sparse=TRUE, alpha.pvals.expli=.15) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(Xplan = X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5, sparse = TRUE, alpha.pvals.expli = 0.15)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default bigplsRcox(Xplan=~X_train_micro,time=Y_train_micro,event=C_train_micro,nt=5,sparse=TRUE, alpha.pvals.expli=.15) #> ____************************************************____ #> Using big matrix without backing and descriptor files #> Error in (function (cond) .Internal(C_tryCatchHelper(addr, 1L, cond)))(structure(list(message = \"argument \\\"data\\\" is missing, with no default\",     call = bigplsRcoxmodel.default(Xplan = ~X_train_micro, time = Y_train_micro,         event = C_train_micro, nt = 5, sparse = TRUE, alpha.pvals.expli = 0.15)), class = c(\"getvarError\", \"missingArgError\", \"error\", \"condition\"))): error in evaluating the argument 'filename' in selecting a method for function 'read.big.matrix': argument \"data\" is missing, with no default"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct Scaled Design Matrices for Big Survival Models — bigscale","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"Prepares large-scale feature matrix stochastic gradient descent byapplying optional normalisation, stratified sampling, batching rules.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"","code":"bigscale(   formula = survival::Surv(time = time, status = status) ~ .,   data,   norm.method = \"standardize\",   strata.size = 20,   batch.size = 1,   features.mean = NULL,   features.sd = NULL,   parallel.flag = FALSE,   num.cores = NULL,   bigmemory.flag = FALSE,   num.rows.chunk = 1e+06,   col.names = NULL,   type = \"short\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"formula formula used extract outcome predictors included scaled design matrix. data Input data source containing variables referenced formula. norm.method Normalisation strategy (example centring standardising columns) applied feature matrix. strata.size Number observations retain stratum constructing stratified batches. batch.size Total size mini-batch produced scaling routine. features.mean Optional vector column means can reused normalise multiple data sets consistent manner. features.sd Optional vector column standard deviations pairs features.mean scaling. parallel.flag Logical flag signalling whether scaling work parallelised across cores. num.cores Number processor cores allocated parallel.flag TRUE. bigmemory.flag Logical flag specifying whether intermediate results stored bigmemory-backed matrices. num.rows.chunk Chunk size used streaming data -disk objects memory. col.names Optional character vector assigning column names generated design matrix. type Type model preprocessing target prepared, survival regression.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"scaled design matrix scaler class along metadata describing transformation applied. time.indices: indices time variable cens.indices: indices censored variables features.indices: indices features time.sd: standard deviation time variable time.mean: mean time variable features.sd: standard deviation features features.mean: mean features nr: number rows nc: number columns col.names: columns names","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/bigscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct Scaled Design Matrices for Big Survival Models — bigscale","text":"","code":"data(micro.censure, package = \"bigPLScox\") surv_data <- stats::na.omit(   micro.censure[, c(\"survyear\", \"DC\", \"sexe\", \"Agediag\")] ) scaled <- bigscale(   survival::Surv(survyear, DC) ~ .,   data = surv_data,   norm.method = \"standardize\",   batch.size = 16 ) #> Warning: Strata size times batch size is greater than number of observations. #>  This package resizes them to strata size = 20 and batch size = 4"},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":null,"dir":"Reference","previous_headings":"","what":"Information criteria for component selection — component_information","title":"Information criteria for component selection — component_information","text":"Computes log-likelihood, AIC BIC values nested models using latent components estimated big_pls_cox() big_pls_cox_gd().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information criteria for component selection — component_information","text":"","code":"component_information(object, max_comp = ncol(object$scores))  # S3 method for class 'big_pls_cox' component_information(object, max_comp = ncol(object$scores))  # S3 method for class 'big_pls_cox_gd' component_information(object, max_comp = ncol(object$scores))  select_ncomp(object, criterion = c(\"AIC\", \"BIC\", \"loglik\"), ...)"},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information criteria for component selection — component_information","text":"object fitted object class big_pls_cox big_pls_cox_gd. max_comp Maximum number components consider. Defaults components stored model. criterion Criterion optimise: \"AIC\", \"BIC\" \"loglik\". ... Passed component_information().","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/component_information.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information criteria for component selection — component_information","text":"data frame columns ncomp, loglik, AIC, BIC. list table information criteria recommended number components.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute deviance residuals — computeDR","title":"Compute deviance residuals — computeDR","text":"function computes deviance residuals null Cox model. default delegates survival::coxph(), high-performance C++ engine also available large -memory bigmemory::big.matrix design matrices.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute deviance residuals — computeDR","text":"","code":"computeDR(   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleY = TRUE,   plot = FALSE,   engine = c(\"survival\", \"cpp\"),   method = c(\"efron\", \"breslow\"),   X = NULL,   coef = NULL,   eta = NULL,   center = NULL,   scale = NULL )"},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute deviance residuals — computeDR","text":"time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleY time values standardized ? plot survival function plotted ? engine Either \"survival\" (default) call survival::coxph() \"cpp\" use C++ implementation. method Tie handling use engine = \"cpp\": either \"efron\" (default) \"breslow\". X Optional design matrix used compute linear predictor engine = \"cpp\". Supports base matrices, data frames, bigmemory::big.matrix objects. coef Optional coefficient vector associated X engine = \"cpp\". eta Optional precomputed linear predictor passed directly C++ engine. center, scale Optional centring scaling vectors applied X computing linear predictor C++ engine.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute deviance residuals — computeDR","text":"Residuals null model fit. engine = \"cpp\", returned vector attributes \"martingale\", \"cumhaz\", \"linear_predictor\".","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute deviance residuals — computeDR","text":"Bastien, P., Bertrand, F., Meyer, N., Maumy-Bertrand, M. (2015). Deviance residuals-based sparse PLS sparse kernel PLS binary classification survival analysis. BMC Bioinformatics, 16, 211. Therneau, T.M., Grambsch, P.M. (2000). Modeling Survival Data: Extending Cox Model. Springer.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute deviance residuals — computeDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/computeDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute deviance residuals — computeDR","text":"","code":"data(micro.censure, package = \"bigPLScox\")  Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  Y_DR <- computeDR(Y_train_micro,C_train_micro) Y_DR <- computeDR(Y_train_micro,C_train_micro,plot=TRUE)   Y_cpp <- computeDR(   Y_train_micro,   C_train_micro,   engine = \"cpp\",   eta = rep(0, length(Y_train_micro)) )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"coxDKgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE : cox_DKgplsDR Final Cox-model. allres=TRUE : tt_DKgplsDR PLSR components. cox_DKgplsDR Final Cox-model. DKgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group PLS model on the (Deviance) Residuals — coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKgplsDR_fit=coxDKgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.882e+00 1.784e+01 1.106e+00 2.606 0.00915 #> dim.2 7.980e+00 2.920e+03 2.570e+00 3.105 0.00190 #> dim.3 5.410e+00 2.236e+02 1.880e+00 2.878 0.00400 #> dim.4 1.559e+01 5.897e+06 5.096e+00 3.059 0.00222 #> dim.5 3.741e+00 4.212e+01 2.015e+00 1.857 0.06336 #> dim.6 1.054e+01 3.768e+04 4.080e+00 2.583 0.00980 #>  #> Likelihood ratio test=65.97  on 6 df, p=2.731e-12 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.907e+00 1.830e+01 1.114e+00 2.609 0.00907 #> dim.2 8.249e+00 3.825e+03 2.650e+00 3.113 0.00185 #> dim.3 5.707e+00 3.008e+02 1.988e+00 2.870 0.00410 #> dim.4 1.616e+01 1.040e+07 5.278e+00 3.061 0.00220 #> dim.5 3.844e+00 4.670e+01 2.045e+00 1.880 0.06014 #> dim.6 1.069e+01 4.381e+04 4.066e+00 2.629 0.00857 #>  #> Likelihood ratio test=66.91  on 6 df, p=1.759e-12 #> n= 80, number of events= 17  (coxDKgplsDR_fit=coxDKgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKgplsDR) #>  #>            coef exp(coef)  se(coef)     z       p #> dim.1 2.936e+00 1.884e+01 1.123e+00 2.614 0.00895 #> dim.2 8.479e+00 4.814e+03 2.721e+00 3.116 0.00183 #> dim.3 5.962e+00 3.884e+02 2.084e+00 2.860 0.00423 #> dim.4 1.661e+01 1.637e+07 5.428e+00 3.061 0.00221 #> dim.5 3.928e+00 5.082e+01 2.070e+00 1.898 0.05770 #> dim.6 1.079e+01 4.871e+04 4.057e+00 2.660 0.00780 #>  #> Likelihood ratio test=67.65  on 6 df, p=1.24e-12 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"coxDKsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ?","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE : cox_sgplsDR Final Cox-model. allres=TRUE : tt_sgplsDR PLSR components. cox_sgplsDR Final Cox-model. sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Direct Kernel group sparse PLS model on the (Deviance) Residuals — coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxDKsgplsDR_fit=coxDKsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxDKsgplsDR_fit=coxDKsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgplsDR_sgfit) #> Warning: object 'cox_sgplsDR_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"coxDKspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )  # Default S3 method coxDKspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   kernel = \"rbfdot\",   hyperkernel,   verbose = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. kernel kernel function used training predicting. parameter can set function, class kernel, computes inner product feature space two vector arguments (see kernels). kernlab package provides popular kernel functions can used setting kernel parameter following strings: list(\"rbfdot\") Radial Basis kernel \"Gaussian\" list(\"polydot\") Polynomial kernel list(\"vanilladot\") Linear kernel list(\"tanhdot\") Hyperbolic tangent kernel list(\"laplacedot\") Laplacian kernel list(\"besseldot\") Bessel kernel list(\"anovadot\") ANOVA RBF kernel list(\"splinedot\") Spline kernel hyperkernel list hyper-parameters (kernel parameters). list contains parameters used kernel function. valid parameters existing kernels : sigma, inverse kernel width Radial Basis kernel function \"rbfdot\" Laplacian kernel \"laplacedot\". degree, scale, offset Polynomial kernel \"polydot\". scale, offset Hyperbolic tangent kernel function \"tanhdot\". sigma, order, degree Bessel kernel \"besseldot\". sigma, degree ANOVA kernel \"anovadot\". case Radial Basis kernel function (Gaussian) Laplacian kernel, hyperkernel missing, heuristics sigest used calculate good sigma value data. verbose details displayed ? alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value controlling maximal penalty considered sgPLS estimating sparse group loadings. Defaults 10^5.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE : cox_DKspls_sgplsDR Final Cox-model. allres=TRUE : tt_DKspls_sgplsDR PLSR components. cox_DKspls_sgplsDR Final Cox-model. DKspls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(X_train_micro,Y_train_micro, C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.334e+00 2.804e+01 1.238e+00 2.692 0.007095 #> dim.2 9.578e+00 1.444e+04 2.865e+00 3.343 0.000829 #> dim.3 7.886e+00 2.659e+03 2.891e+00 2.728 0.006377 #> dim.4 1.369e+01 8.842e+05 4.470e+00 3.063 0.002188 #> dim.5 4.028e+00 5.615e+01 2.151e+00 1.873 0.061074 #> dim.6 6.562e+00 7.074e+02 2.831e+00 2.318 0.020448 #>  #> Likelihood ratio test=66.14  on 6 df, p=2.526e-12 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~X_train_micro,Y_train_micro, C_train_micro,ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.302e+00 2.718e+01 1.232e+00 2.680 0.007352 #> dim.2 9.661e+00 1.570e+04 2.895e+00 3.337 0.000846 #> dim.3 8.212e+00 3.684e+03 2.952e+00 2.782 0.005409 #> dim.4 1.422e+01 1.495e+06 4.648e+00 3.059 0.002220 #> dim.5 4.073e+00 5.873e+01 2.193e+00 1.857 0.063244 #> dim.6 7.077e+00 1.185e+03 2.954e+00 2.395 0.016603 #>  #> Likelihood ratio test=66.48  on 6 df, p=2.15e-12 #> n= 80, number of events= 17  (cox_DKspls_sgplsDR_fit=coxDKspls_sgplsDR(~.,Y_train_micro,C_train_micro, ncomp=6,dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),  alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_DKspls_sgplsDR) #>  #>            coef exp(coef)  se(coef)     z        p #> dim.1 3.300e+00 2.711e+01 1.233e+00 2.676 0.007450 #> dim.2 9.647e+00 1.548e+04 2.885e+00 3.344 0.000825 #> dim.3 8.074e+00 3.209e+03 2.901e+00 2.783 0.005386 #> dim.4 1.414e+01 1.389e+06 4.609e+00 3.069 0.002148 #> dim.5 4.100e+00 6.036e+01 2.188e+00 1.874 0.060979 #> dim.6 7.143e+00 1.266e+03 2.991e+00 2.389 0.016913 #>  #> Likelihood ratio test=66.38  on 6 df, p=2.256e-12 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_DKspls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components — coxgpls","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"coxgpls(Xplan, ...)  # S3 method for class 'formula' coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. missing, every predictor placed group. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE : cox_gpls Final Cox-model. allres=TRUE : tt_gpls PLSR components. cox_gpls Final Cox-model. gpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components — coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgpls_fit=coxgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17  (coxgpls_fit=coxgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17  (ccoxgpls_fit=coxgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gpls) #>  #>            coef exp(coef)  se(coef)      z      p #> dim.1 -0.696933  0.498111  0.307358 -2.267 0.0234 #> dim.2 -0.101947  0.903078  0.250931 -0.406 0.6845 #> dim.3 -0.601144  0.548184  0.269089 -2.234 0.0255 #> dim.4  0.001834  1.001836  0.458089  0.004 0.9968 #> dim.5 -0.276795  0.758210  0.287096 -0.964 0.3350 #> dim.6 -0.785772  0.455768  0.321865 -2.441 0.0146 #>  #> Likelihood ratio test=19.33  on 6 df, p=0.003642 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"coxgplsDR(Xplan, ...)  # S3 method for class 'formula' coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE : cox_gplsDR Final Cox-model. allres=TRUE : tt_gplsDR PLSR components. cox_gplsDR Final Cox-model. gplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group PLSR components using the (Deviance) Residuals — coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxgplsDR_fit=coxgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17  (coxgplsDR_fit=coxgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15),keepX=rep(4,6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_gplsDR) #>  #>         coef exp(coef) se(coef)     z        p #> dim.1 0.7784    2.1781   0.1987 3.917 8.96e-05 #> dim.2 0.9626    2.6186   0.2982 3.228  0.00125 #> dim.3 0.9110    2.4868   0.4075 2.236  0.02536 #> dim.4 0.9022    2.4650   0.4004 2.253  0.02424 #> dim.5 0.1844    1.2026   0.2664 0.692  0.48865 #> dim.6 0.7448    2.1059   0.4228 1.761  0.07819 #>  #> Likelihood ratio test=54.95  on 6 df, p=4.745e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit) #> Warning: object 'cox_spls_sgpls_fit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"coxsgpls(Xplan, ...)  # S3 method for class 'formula' coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE : cox_sgpls Final Cox-model. allres=TRUE : tt_sgpls PLSR components. cox_sgpls Final Cox-model. sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components — coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgpls_fit=coxsgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (coxsgpls_fit=coxsgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgpls_sgfit) #> Warning: object 'cox_sgpls_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgplsDR perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"coxsgplsDR(Xplan, ...)  # S3 method for class 'formula' coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxsgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   modepls = \"regression\",   ind.block.x,   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x mixing parameter (value 0 1) related sparsity within group X dataset. upper.lambda default upper.lambda=10^5. large value specifying upper bound intervall lambda values searching value tuning parameter (lambda) corresponding non-zero group variables. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE : cox_sgplsDR Final Cox-model. allres=TRUE : tt_sgplsDR PLSR components. cox_sgplsDR Final Cox-model. sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on group sparse PLSR components using the (Deviance) Residuals — coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)),FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (coxsgplsDR_fit=coxsgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17  (coxsgplsDR_fit=coxsgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_sgplsDR) #>  #>           coef exp(coef) se(coef)      z        p #> dim.1  0.85431   2.34976  0.24239  3.525 0.000424 #> dim.2  0.96004   2.61180  0.29938  3.207 0.001342 #> dim.3  1.64702   5.19149  0.69268  2.378 0.017419 #> dim.4  0.23137   1.26033  0.23656  0.978 0.328037 #> dim.5 -0.06767   0.93457  0.30587 -0.221 0.824917 #> dim.6  0.37661   1.45734  0.36468  1.033 0.301734 #>  #> Likelihood ratio test=53.66  on 6 df, p=8.658e-10 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_sgplsDR_sgfit) #> Warning: object 'cox_sgplsDR_sgfit' not found"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"coxspls_sgpls(Xplan, ...)  # S3 method for class 'formula' coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgpls(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors. alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value controlling maximal penalty considered sgPLS estimating sparse group loadings. Defaults 10^5.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE : cox_spls_sgpls Final Cox-model. allres=TRUE : tt_spls_sgpls PLSR components. cox_spls_sgpls Final Cox-model. spls_sgpls_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components — coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgpls_fit=coxspls_sgpls(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgpls_fit=coxspls_sgpls(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgpls) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgpls_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"function computes Cox Model based PLSR components computed model explanatory variables: Xplan. uses package sgPLS perform group PLSR fit.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"coxspls_sgplsDR(Xplan, ...)  # S3 method for class 'formula' coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   dataXplan = NULL,   subset,   weights,   model_frame = FALSE,   model_matrix = FALSE,   contrasts.arg = NULL,   ... )  # Default S3 method coxspls_sgplsDR(   Xplan,   time,   time2,   event,   type,   origin,   typeres = \"deviance\",   collapse,   weighted,   scaleX = TRUE,   scaleY = TRUE,   ncomp = min(7, ncol(Xplan)),   ind.block.x = NULL,   modepls = \"regression\",   keepX,   alpha.x,   upper.lambda = 10^5,   plot = FALSE,   allres = FALSE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Xplan formula matrix eXplanatory variables (training) dataset ... Arguments passed survival::coxph. time right censored data, follow time. interval data, first argument starting time interval. time2 status indicator, normally 0=alive, 1=dead. choices TRUE/FALSE (TRUE = death) 1/2 (2=death). interval censored data, status indicator 0=right censored, 1=event time, 2=left censored, 3=interval censored. Although unusual, event indicator can omitted, case subjects assumed event. event ending time interval interval censored counting process data . Intervals assumed open left closed right, (start, end]. counting process data, event indicates whether event occurred end interval. type character string specifying type censoring. Possible values \"right\", \"left\", \"counting\", \"interval\", \"interval2\". default \"right\" \"counting\" depending whether time2 argument absent present, respectively. origin counting process data, hazard function origin. option intended used conjunction model containing time dependent strata order align subjects properly cross one strata another, rarely proven useful. typeres character string indicating type residual desired. Possible values \"martingale\", \"deviance\", \"score\", \"schoenfeld\", \"dfbeta\", \"dfbetas\", \"scaledsch\". enough string determine unique match required. collapse vector indicating rows collapse (sum) . time-dependent models one row data can pertain single individual. 4 individuals represented 3, 1, 2 4 rows data respectively, collapse=c(1,1,1,2,3,3,4,4,4,4) used obtain per subject rather per observation residuals. weighted TRUE model fit case weights, weighted residuals returned. scaleX Xplan columns standardized ? scaleY time values standardized ? ncomp number components include model. supplied, min(7,maximal number) components used. ind.block.x vector integers describing grouping X-variables. ind.block.x <- c(3,10,15) means X structured 4 groups: X1 X3; X4 X10, X11 X15 X16 Xp p number variables X matrix. modepls character string. type algorithm use, (partially) matching one \"regression\", \"canonical\". See gPLS details keepX numeric vector length ncomp, number variables keep X-loadings. default variables kept model. alpha.x numeric vector length ncomp giving sparsity level applied within component. Required ind.block.x specified. upper.lambda numeric value giving upper bound regularized regression penalty used sgPLS. Defaults 10\\(^5\\). plot survival function plotted ?) allres FALSE return Cox model TRUE additionnal results. See details. Defaults FALSE. dataXplan optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found dataXplan, variables taken environment(Xplan), typically environment coxpls called. subset optional vector specifying subset observations used fitting process. weights optional vector 'prior weights' used fitting process. NULL numeric vector. model_frame TRUE, model frame returned. model_matrix TRUE, model matrix returned. contrasts.arg list, whose entries values (numeric matrices, functions character strings naming functions) used replacement values contrasts replacement function whose names names columns data containing factors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE : cox_spls_sgplsDR Final Cox-model. allres=TRUE : tt_spls_sgplsDR PLSR components. cox_spls_sgplsDR Final Cox-model. spls_sgplsDR_mod PLSR model.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"allres=FALSE returns final Cox-model. allres=TRUE returns list PLS components, final Cox-model group PLSR model. allres=TRUE useful evluating model prediction accuracy test sample.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"group Sparse Group Partial Least Square approach applied Genomics context, Liquet Benoit, Lafaye de Micheaux, Boris Hejblum, Rodolphe Thiebaut (2016). Bioinformatics. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting a Cox-Model on sparse PLSR components using the (Deviance) Residuals — coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp)  X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~X_train_micro,Y_train_micro,C_train_micro, ncomp=6,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17  (cox_spls_sgplsDR_fit=coxspls_sgplsDR(~.,Y_train_micro,C_train_micro,ncomp=6, dataXplan=X_train_micro_df,ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6))) #> Call: #> coxph(formula = YCsurv ~ ., data = tt_spls_sgplsDR) #>  #>          coef exp(coef) se(coef)      z      p #> dim.1 -0.7429    0.4757   0.2647 -2.807 0.0050 #> dim.2 -0.4003    0.6701   0.2622 -1.527 0.1268 #> dim.3 -0.6329    0.5310   0.2930 -2.160 0.0308 #> dim.4 -0.5733    0.5637   0.2591 -2.213 0.0269 #> dim.5  0.1578    1.1709   0.2375  0.664 0.5064 #> dim.6 -0.2209    0.8018   0.3337 -0.662 0.5079 #>  #> Likelihood ratio test=21.77  on 6 df, p=0.001331 #> n= 80, number of events= 17   rm(X_train_micro,Y_train_micro,C_train_micro,cox_spls_sgplsDR_fit)"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"function cross-validates coxDKgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"cv.coxDKgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"data list three items: x explanatory variables passed coxDKgplsDR's Xplan argument, time passed coxDKgplsDR's time argument, status coxDKgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group PLS model fitted on the (Deviance) Residuals — cv.coxDKgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKgplsDR.res=cv.coxDKgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=2)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6381540 0.6963262 #>  #> $cv.se10 #> [1] 0.00000000 0.03036225 0.02912723 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"function cross-validates coxDKsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"cv.coxDKsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"data list three items: x explanatory variables passed coxDKsgplsDR's Xplan argument, time passed coxDKsgplsDR's time argument, status coxDKsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel group sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) if (FALSE) { # \\dontrun{ (cv.coxDKsgplsDR.res=cv.coxDKsgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15),  alpha.x = rep(0.95, 6),nt=3)) } # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"function cross-validates coxDKspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"cv.coxDKspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"data list three items: x explanatory variables passed coxDKspls_sgplsDR's Xplan argument, time passed coxDKspls_sgplsDR's time argument, status coxDKspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxDKspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxDKspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Direct Kernel sparse PLS model fitted on the (Deviance) Residuals — cv.coxDKspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxDKspls_sgplsDR.res=cv.coxDKspls_sgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 3),nt=3)) #> Kernel :  rbfdot  #> Estimated_sigma  0.01257168  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Kernel :  rbfdot  #> Estimated_sigma  0.01198263  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Kernel :  rbfdot  #> Estimated_sigma  0.01156809  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Kernel :  rbfdot  #> Estimated_sigma  0.01287851  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Kernel :  rbfdot  #> Estimated_sigma  0.01127231  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6530362 0.7257771 0.6553724 #>  #> $cv.se10 #> [1] 0.00000000 0.03313505 0.03135189 0.04381849 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"function cross-validates coxgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"cv.coxgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components — cv.coxgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgpls.res=cv.coxgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.5225223 0.6037656 0.5639968 #>  #> $cv.se10 #> [1] 0.00000000 0.05032449 0.04012942 0.03493106 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"function cross-validates coxgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"cv.coxgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"data list three items: x explanatory variables passed coxgpls's Xplan argument, time passed coxgpls's time argument, status coxgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on group PLSR components using (Deviance) Residuals — cv.coxgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxgplsDR.res=cv.coxgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.6786893 0.6913293 0.6485690 #>  #> $cv.se10 #> [1] 0.00000000 0.04017423 0.02726346 0.03897730 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"function cross-validates coxsgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"cv.coxsgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"data list three items: x explanatory variables passed coxsgpls's Xplan argument, time passed coxsgpls's time argument, status coxsgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components — cv.coxsgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgpls.res=cv.coxsgpls(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"function cross-validates coxsgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"cv.coxsgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"data list three items: x explanatory variables passed coxsgplsDR's Xplan argument, time passed coxsgplsDR's time argument, status coxsgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxsgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxsgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse group PLSR components using (Deviance) Residuals — cv.coxsgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxsgplsDR.res=cv.coxsgplsDR(list(x=X_train_micro,time=Y_train_micro, status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=2)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 2 #>  #> $cv.error10 #> [1] 0.5000000 0.6856847 0.6944862 #>  #> $cv.se10 #> [1] 0.00000000 0.03282521 0.03554813 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 2 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"function cross-validates coxspls_sgpls models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"cv.coxspls_sgpls(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"data list three items: x explanatory variables passed coxspls_sgpls's Xplan argument, time passed coxspls_sgpls's time argument, status coxspls_sgpls's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgpls.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components — cv.coxspls_sgpls","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgpls.res=cv.coxspls_sgpls(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"function cross-validates coxspls_sgplsDR models.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"cv.coxspls_sgplsDR(   data,   method = c(\"efron\", \"breslow\"),   nfold = 5,   nt = 10,   plot.it = TRUE,   se = TRUE,   givefold,   scaleX = TRUE,   folddetails = FALSE,   allCVcrit = FALSE,   details = FALSE,   namedataset = \"data\",   save = FALSE,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"data list three items: x explanatory variables passed coxspls_sgplsDR's Xplan argument, time passed coxspls_sgplsDR's time argument, status coxspls_sgplsDR's status argument. method character string specifying method tie handling. tied death times methods equivalent. Efron approximation used default , accurate dealing tied death times, efficient computationally. nfold number folds use perform cross-validation process. nt number components include model. supplied, 10 components fitted. plot.Shall results displayed plot ? se standard errors plotted ? givefold Explicit list omited values fold can provided using argument. scaleX Shall predictors standardized ? folddetails values completion status folds returned ? allCVcrit 13 CV criteria evaled returned ? details results functions perform error computations returned ? namedataset Name use craft temporary results names save temporary results saved ? verbose CV details displayed ? ... arguments pass coxspls_sgplsDR.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"nt number components requested cv.error1 Vector mean values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.error2 Vector mean values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.error3 Vector mean values, across folds, iAUC_CD models 0 nt components. cv.error4 Vector mean values, across folds, iAUC_hc models 0 nt components. cv.error5 Vector mean values, across folds, iAUC_sh models 0 nt components. cv.error6 Vector mean values, across folds, iAUC_Uno models 0 nt components. cv.error7 Vector mean values, across folds, iAUC_hz.train models 0 nt components. cv.error8 Vector mean values, across folds, iAUC_hz.test models 0 nt components. cv.error9 Vector mean values, across folds, iAUC_survivalROC.train models 0 nt components. cv.error10 Vector mean values, across folds, iAUC_survivalROC.test models 0 nt components. cv.error11 Vector mean values, across folds, iBrierScore unw models 0 nt components. cv.error12 Vector mean values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.error13 Vector mean values, across folds, iBrierScore w models 0 nt components. cv.error14 Vector mean values, across folds, iSchmidScore (robust BS) w models 0 nt components. cv.se1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. cv.se2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. cv.se3 Vector standard error values, across folds, iAUC_CD models 0 nt components. cv.se4 Vector standard error values, across folds, iAUC_hc models 0 nt components. cv.se5 Vector standard error values, across folds, iAUC_sh models 0 nt components. cv.se6 Vector standard error values, across folds, iAUC_Uno models 0 nt components. cv.se7 Vector standard error values, across folds, iAUC_hz.train models 0 nt components. cv.se8 Vector standard error values, across folds, iAUC_hz.test models 0 nt components. cv.se9 Vector standard error values, across folds, iAUC_survivalROC.train models 0 nt components. cv.se10 Vector standard error values, across folds, iAUC_survivalROC.test models 0 nt components. cv.se11 Vector standard error values, across folds, iBrierScore unw models 0 nt components. cv.se12 Vector standard error values, across folds, iSchmidScore (robust BS) unw models 0 nt components. cv.se13 Vector standard error values, across folds, iBrierScore w models 0 nt components. cv.se14 Vector standard error values, across folds, iSchmidScore (robust BS) w models 0 nt components. folds Explicit list values omited values fold. lambda.min1 Vector standard error values, across folds, , per fold unit, Cross-validated log-partial-likelihood models 0 nt components. lambda.min2 Vector standard error values, across folds, , per fold unit, van Houwelingen Cross-validated log-partial-likelihood models 0 nt components. lambda.min1 Optimal Nbr components, min Cross-validated log-partial-likelihood criterion. lambda.se1 Optimal Nbr components, min+1se Cross-validated log-partial-likelihood criterion. lambda.min2 Optimal Nbr components, min van Houwelingen Cross-validated log-partial-likelihood. lambda.se2 Optimal Nbr components, min+1se van Houwelingen Cross-validated log-partial-likelihood. lambda.min3 Optimal Nbr components, max iAUC_CD criterion. lambda.se3 Optimal Nbr components, max+1se iAUC_CD criterion. lambda.min4 Optimal Nbr components, max iAUC_hc criterion. lambda.se4 Optimal Nbr components, max+1se iAUC_hc criterion. lambda.min5 Optimal Nbr components, max iAUC_sh criterion. lambda.se5 Optimal Nbr components, max+1se iAUC_sh criterion. lambda.min6 Optimal Nbr components, max iAUC_Uno criterion. lambda.se6 Optimal Nbr components, max+1se iAUC_Uno criterion. lambda.min7 Optimal Nbr components, max iAUC_hz.train criterion. lambda.se7 Optimal Nbr components, max+1se iAUC_hz.train criterion. lambda.min8 Optimal Nbr components, max iAUC_hz.test criterion. lambda.se8 Optimal Nbr components, max+1se iAUC_hz.test criterion. lambda.min9 Optimal Nbr components, max iAUC_survivalROC.train criterion. lambda.se9 Optimal Nbr components, max+1se iAUC_survivalROC.train criterion. lambda.min10 Optimal Nbr components, max iAUC_survivalROC.test criterion. lambda.se10 Optimal Nbr components, max+1se iAUC_survivalROC.test criterion. lambda.min11 Optimal Nbr components, min iBrierScore unw criterion. lambda.se11 Optimal Nbr components, min+1se iBrierScore unw criterion. lambda.min12 Optimal Nbr components, min iSchmidScore unw criterion. lambda.se12 Optimal Nbr components, min+1se iSchmidScore unw criterion. lambda.min13 Optimal Nbr components, min iBrierScore w criterion. lambda.se13 Optimal Nbr components, min+1se iBrierScore w criterion. lambda.min14 Optimal Nbr components, min iSchmidScore w criterion. lambda.se14 Optimal Nbr components, min+1se iSchmidScore w criterion. errormat1-14 details=TRUE, matrices error values every folds across components criteria completed.cv1-14 details=TRUE, matrices logical values every folds across components criteria: TRUE computation completed FALSE failed. All_indics results functions perform error computation, fold, component error criterion.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"computes recommended iAUCSurvROC criterion. Set allCVcrit=TRUE retrieve 13 ones.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660. Cross validating extensions kernel, sparse regular partial least squares regression models censored data, Bertrand, F., Bastien, Ph. Maumy-Bertrand, M. (2018), https://arxiv.org/abs/1810.01005.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/cv.coxspls_sgplsDR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validating a Cox-Model fitted on sparse PLSR components components using (Deviance) Residuals — cv.coxspls_sgplsDR","text":"","code":"data(micro.censure) data(Xmicro.censure_compl_imp) set.seed(123456) X_train_micro <- apply((as.matrix(Xmicro.censure_compl_imp)), FUN=\"as.numeric\",MARGIN=2)[1:80,] X_train_micro_df <- data.frame(X_train_micro) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80]  #Should be run with a higher value of nt (at least 10) (cv.coxspls_sgplsDR.res=cv.coxspls_sgplsDR(list(x=X_train_micro, time=Y_train_micro,status=C_train_micro),ind.block.x=c(3,10,15), alpha.x = rep(0.95, 6),nt=3)) #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 1  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 2  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 3  #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 4  #> Warning: no non-missing arguments to min; returning Inf #> CV Fold 5   #> $nt #> [1] 3 #>  #> $cv.error10 #> [1] 0.5000000 0.4217599 0.5382923 0.5519544 #>  #> $cv.se10 #> [1] 0.00000000 0.03195833 0.02746499 0.03490158 #>  #> $folds #> $folds$`1` #>  [1] 60  3  2 14 77  6 50  4 72 32 22  1 41 21 63 25 #>  #> $folds$`2` #>  [1] 42 67 65 15 73 48 57 26  7 13 31 53  5 27 37 64 #>  #> $folds$`3` #>  [1] 71 23 56 35 75 29 30 18 62 44 12 33 68 49 43 55 #>  #> $folds$`4` #>  [1] 54 76 24 16 34 66  9 11 69 40 70 36 39  8 19 20 #>  #> $folds$`5` #>  [1] 74 38 46 80 47 78 10 45 51 28 61 79 58 17 52 59 #>  #>  #> $lambda.min10 #> [1] 3 #>  #> $lambda.1se10 #> [1] 0 #>"},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated survival dataset for Cox models — dCox_sim","title":"Simulated survival dataset for Cox models — dCox_sim","text":"dCox_sim dataset contains simulated survival times, censoring indicators two binary covariates demonstrating Cox-related procedures included bigPLScox.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated survival dataset for Cox models — dCox_sim","text":"data frame 10000 observations following 5 variables. id observation identifier time simulated survival time status event indicator (1 = event, 0 = censored) x.1 first binary covariate x.2 second binary covariate","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dCox_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated survival dataset for Cox models — dCox_sim","text":"","code":"# \\donttest{ data(dCox_sim) with(dCox_sim, table(status)) #> status #>    0    1  #> 5612 4388  # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"Function dataCox generaters random survivaldata Weibull distribution (parameters lambda rho given input x data, model coefficients beta censoring rate censoring comes exponential distribution parameter cens.rate.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"dataCox(n, lambda, rho, x, beta, cens.rate)"},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"n Number observations generate. lambda lambda parameter Weibull distribution. rho rho parameter Weibull distribution. x data.frame input data generate survival times . beta True model coefficients. cens.rate Parameter exponential distribution, responsible censoring.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"data.frame containing columns: id integer. time survival times. status observation status (event occured (1) (0)). x data.frame input data generate survival times .","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"observation true survival time generated censroing time. censoring time less survival time, survival time returned status observations set 0 means observation censored time. survival time less censoring time, observation true survival time returned status observation set 1 means event noticed.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"http://onlinelibrary.wiley.com/doi/10.1002/sim.2059/abstract Generating survival times simulate Cox proportional hazards models, 2005 Ralf Bender, Thomas Augustin, Maria Blettner.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/dataCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cox Proportional Hazards Model Data Generation From Weibull Distribution — dataCox","text":"","code":"if (FALSE) { # \\dontrun{ x <- matrix(sample(0:1, size = 20000, replace = TRUE), ncol = 2) dCox <- dataCox(10^4, lambda = 3, rho = 2, x, beta = c(1,3), cens.rate = 5)  } # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLS.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal bigPLScox functions — internal-bigPLS","title":"Internal bigPLScox functions — internal-bigPLS","text":"called user.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Internal bigPLScox functions — internal-bigPLS","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/internal-bigPLS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Internal bigPLScox functions — internal-bigPLS","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsat features and survival times — micro.censure","title":"Microsat features and survival times — micro.censure","text":"dataset provides Microsat specifications survival times.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsat features and survival times — micro.censure","text":"data frame 117 observations following 43 variables. numpat factor levels B1006 B1017 B1028 B1031 B1046 B1059 B1068 B1071 B1102 B1115 B1124 B1139 B1157 B1161 B1164 B1188 B1190 B1192 B1203 B1211 B1221 B1225 B1226 B1227 B1237 B1251 B1258 B1266 B1271 B1282 B1284 B1285 B1286 B1287 B1290 B1292 B1298 B1302 B1304 B1310 B1319 B1327 B1353 B1357 B1363 B1368 B1372 B1373 B1379 B1388 B1392 B1397 B1403 B1418 B1421t1 B1421t2 B1448 B1451 B1455 B1460 B1462 B1466 B1469 B1493 B1500 B1502 B1519 B1523 B1529 B1530 B1544 B1548 B500 B532 B550 B558 B563 B582 B605 B609 B634 B652 B667 B679 B701 B722 B728 B731 B736 B739 B744 B766 B771 B777 B788 B800 B836 B838 B841 B848 B871 B873 B883 B889 B912 B924 B925 B927 B938 B952 B954 B955 B968 B972 B976 B982 B984 D18S61 numeric vector D17S794 numeric vector D13S173 numeric vector D20S107 numeric vector TP53 numeric vector D9S171 numeric vector D8S264 numeric vector D5S346 numeric vector D22S928 numeric vector D18S53 numeric vector D1S225 numeric vector D3S1282 numeric vector D15S127 numeric vector D1S305 numeric vector D1S207 numeric vector D2S138 numeric vector D16S422 numeric vector D9S179 numeric vector D10S191 numeric vector D4S394 numeric vector D1S197 numeric vector D6S264 numeric vector D14S65 numeric vector D17S790 numeric vector D5S430 numeric vector D3S1283 numeric vector D4S414 numeric vector D8S283 numeric vector D11S916 numeric vector D2S159 numeric vector D16S408 numeric vector D6S275 numeric vector D10S192 numeric vector sexe numeric vector Agediag numeric vector Siege numeric vector T numeric vector N numeric vector M numeric vector STADE factor levels 0 1 2 3 4 survyear numeric vector DC numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsat features and survival times — micro.censure","text":"Allelotyping identification genomic alterations rectal chromosomally unstable tumors without preoperative treatment, #' Benoît Romain, Agnès Neuville, Nicolas Meyer, Cécile Brigand, Serge Rohr, Anne Schneider, Marie-Pierre Gaub Dominique Guenot, BMC Cancer 2010, 10:561, doi:10.1186/1471-2407-10-561.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Microsat features and survival times — micro.censure","text":"plsRcox, Cox-Models high dimensional setting R, Frederic Bertrand, Philippe Bastien, Nicolas Meyer Myriam Maumy-Bertrand (2014). Proceedings User2014!, Los Angeles, page 152. Deviance residuals-based sparse PLS sparse kernel PLS regression censored data, Philippe Bastien, Frederic Bertrand, Nicolas Meyer Myriam Maumy-Bertrand (2015), Bioinformatics, 31(3):397-404, doi:10.1093/bioinformatics/btu660.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/micro.censure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Microsat features and survival times — micro.censure","text":"","code":"# \\donttest{ data(micro.censure) Y_train_micro <- micro.censure$survyear[1:80] C_train_micro <- micro.censure$DC[1:80] Y_test_micro <- micro.censure$survyear[81:117] C_test_micro <- micro.censure$DC[81:117] rm(Y_train_micro,C_train_micro,Y_test_micro,C_test_micro) # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":null,"dir":"Reference","previous_headings":"","what":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"Loads previously scaled design matrix continues stochastic gradient optimisation subset variables.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"","code":"partialbigSurvSGDv0(   name.col,   datapath,   ncores = 1,   resBigscale,   bigmemory.flag = FALSE,   parallel.flag = FALSE,   inf.mth = \"none\" )"},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"name.col Character vector containing column names included partial fit. datapath File system path connection big-memory backing file scaled design matrix stored. ncores Number processor cores allocated partial fitting procedure. Defaults 1. resBigscale Result object returned bigscale containing scaling statistics reused. default helper reuses globally cached resultsBigscale object created bigscale. bigmemory.flag Logical flag determining whether big-memory backed matrices used loading updating design matrix. Defaults FALSE. parallel.flag Logical flag toggling use parallelised stochastic gradient updates. Defaults FALSE. inf.mth Inference method requested partial fit, \"none\", \"asymptotic\", bootstrap summaries. Defaults \"none\".","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"Either numeric vector log hazard-ratio coefficients , inference requested, matrix whose columns correspond inferred coefficient summaries penalisation setting.","code":""},{"path":[]},{"path":"https://fbertran.github.io/bigPLScox/reference/partialbigSurvSGDv0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incremental Survival Model Fitting with Pre-Scaled Data — partialbigSurvSGDv0","text":"","code":"if (FALSE) { # \\dontrun{ continued <- partialbigSurvSGDv0(   name.col = c(\"age\", \"sex\"),   datapath = tempfile(),   ncores = 2,   resBigscale = scaled,   bigmemory.flag = TRUE,   parallel.flag = TRUE,   inf.mth = \"bootstrap\" ) } # }"},{"path":"https://fbertran.github.io/bigPLScox/reference/pls_big.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares for bigmemory matrices — pls_big","title":"Partial least squares for bigmemory matrices — pls_big","text":"`pls_big()` fits partial least squares (PLS) model using NIPALS algorithm implemented C++ operates directly [bigmemory::big.matrix] inputs. -memory file-backed matrices supported. `matrixpls_stream_bigmatrix()` pure R fallback performs computation streaming chunks file-backed `big.matrix` without loading fully memory.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/pls_big.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares for bigmemory matrices — pls_big","text":"","code":"pls_big(   X,   Y,   ncomp = 2L,   tol = 1e-06,   max_iter = 500L,   stream = FALSE,   num.rows.chunk = 1e+06,   backingfile = NULL,   backingpath = NULL,   descriptorfile = NULL,   type = \"double\",   ... )  matrixpls_stream_bigmatrix(   X,   Y,   ncomp = 2L,   tol = 1e-06,   max_iter = 500L,   num.rows.chunk = 1e+06,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/pls_big.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares for bigmemory matrices — pls_big","text":"X Either `bigmemory::big.matrix`, `bigmemory::big.matrix.descriptor`, character path delimited file can read [bigmemory::read.big.matrix()]. Y Numeric response matrix matching number rows. Vectors coerced one-column matrix. ncomp Number latent components extract. tol Convergence tolerance iterative updates. max_iter Maximum number iterations NIPALS inner loop. stream Logical; `TRUE`, force chunk-wise R implementation via [matrixpls_stream_bigmatrix()]. num.rows.chunk Number rows load per chunk `stream = TRUE`. backingfile, backingpath, descriptorfile Optional arguments passed [bigmemory::read.big.matrix()] `X` file path. type Storage mode use reading file path, defaulting `\"double\"`. ... Reserved future extensions.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/pls_big.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares for bigmemory matrices — pls_big","text":"list containing   * `scores`: X-score matrix (`T`)   * `Yscores`: Y-score matrix (`U`)   * `weights`: weight matrix (`W`)   * `loadings`: X-loading matrix (`P`)   * `Yloadings`: Y-loading matrix (`Q`)   * `coefficients`: regression coefficients linking `T` `U`","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"Predict method big-memory PLS-Cox models","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"","code":"# S3 method for class 'big_pls_cox' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )  # S3 method for class 'big_pls_cox_gd' predict(   object,   newdata = NULL,   type = c(\"link\", \"risk\", \"response\", \"components\"),   comps = NULL,   coef = NULL,   ... )"},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"object model fitted big_pls_cox(). newdata Optional matrix, data frame bigmemory::big.matrix containing predictors project latent space. NULL training scores used. type Type prediction: \"link\" linear predictor, \"risk\" \"response\" exponential linear predictor, \"components\" obtain latent scores. comps Integer vector indicating components use. Defaults available components. coef Optional coefficient vector overriding fitted Cox model coefficients. ... Unused.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/predict.big_pls_cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for big-memory PLS-Cox models — predict.big_pls_cox","text":"Depending type, either numeric vector predictions matrix component scores.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated dataset — sim_data","title":"Simulated dataset — sim_data","text":"dataset provides explantory variables simulations censoring status.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated dataset — sim_data","text":"data frame 1000 observations following 11 variables. status binary vector X1 numeric vector X2 numeric vector X3 numeric vector X4 numeric vector X5 numeric vector X6 numeric vector X7 numeric vector X8 numeric vector X9 numeric vector X10 numeric vector","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated dataset — sim_data","text":"TODO.","code":""},{"path":"https://fbertran.github.io/bigPLScox/reference/sim_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated dataset — sim_data","text":"","code":"# \\donttest{ data(sim_data) X_sim_data_train <- sim_data[1:800,2:11] C_sim_data_train <- sim_data$status[1:800] X_sim_data_test <- sim_data[801:1000,2:11] C_sim_data_test <- sim_data$status[801:1000] rm(X_sim_data_train,C_sim_data_train,X_sim_data_test,C_sim_data_test) # }"},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-060","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.6.0","title":"bigPLScox 0.6.0","text":"Added C++ implementations Cox deviance residuals streaming support  matrices together benchmarking utilities. Introduced prediction wrappers component selection helpers (AIC/BIC) big_pls_cox() big_pls_cox_gd(). Enabled naive sparsity control big_pls_cox() exposed survival model objects downstream predictions. Extended unit test coverage new deviance prediction features. Fixed cv.coxgpls() accept big.matrix predictors without coercion errors.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-050","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.5.0","title":"bigPLScox 0.5.0","text":"Added reproducible benchmarking utilities inst/benchmarks comparing big_pls_cox() plsRcox::plsRcox() -memory file-backed matrices. Published two package vignettes cover introductory workflows large-scale analyses bigmemory. Added introductory vignette covering core Cox-PLS workflow. Refreshed README website copy highlight core functionality demonstrate working examples without warnings. Refreshed README guidance learning materials benchmarking. Completed package-level documentation bibliographic references. Updated package metadata list optional dependencies used docs benchmarks.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-040","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.4.0","title":"bigPLScox 0.4.0","text":"Updated maintainer contact details DESCRIPTION. Added unit tests big_pls_cox() big_pls_cox_gd() stability checks. Added unit tests covering new C++-accelerated Cox PLS implementation cross-validation utilities.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-030","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.3.0","title":"bigPLScox 0.3.0","text":"Improved big_pls_cox() numerical stability added support additional convergence diagnostics gradient-descent solver. Refactored stochastic gradient solvers better integrate bigmemory file-backed matrices. Improved numerical stability deviance residual computations.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-020","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.2.0","title":"bigPLScox 0.2.0","text":"Expanded documentation examples deviance residuals Cox model utilities. Added dataset documentation micro.censure simulated Cox examples. Added pkgdown site configuration continuous integration workflows.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-010","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.1.0","title":"bigPLScox 0.1.0","text":"Introduced gPLS sgPLS model families support grouped predictors deviance residual pipelines cross-validation support.","code":""},{"path":"https://fbertran.github.io/bigPLScox/news/index.html","id":"bigplscox-001","dir":"Changelog","previous_headings":"","what":"bigPLScox 0.0.1","title":"bigPLScox 0.0.1","text":"Initial package skeleton core data objects helper routines.","code":""}]
