<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Overview of bigPLScox • bigPLScox</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Overview of bigPLScox">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">bigPLScox</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.7.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/bigPLScox.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/bigPLScox-benchmarking.html">Benchmarking bigPLScox</a></li>
    <li><a class="dropdown-item" href="../articles/bigPLScox-overview.html">Overview of bigPLScox</a></li>
    <li><a class="dropdown-item" href="../articles/getting-started.html">Getting started with bigPLScox</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/fbertran/bigPLScox/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Overview of bigPLScox</h1>
                        <h4 data-toc-skip class="author">Frédéric
Bertrand</h4>
            <address class="author_afil">
      Cedric, Cnam,
Paris<br><a class="author_email" href="mailto:#"></a><a href="mailto:frederic.bertrand@lecnam.net" class="email">frederic.bertrand@lecnam.net</a>
      </address>
                  
            <h4 data-toc-skip class="date">2025-11-15</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/fbertran/bigPLScox/blob/HEAD/vignettes/bigPLScox-overview.Rmd" class="external-link"><code>vignettes/bigPLScox-overview.Rmd</code></a></small>
      <div class="d-none name"><code>bigPLScox-overview.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The goal of <strong>bigPLScox</strong> is to provide Partial Least
Squares (PLS) variants of the Cox proportional hazards model that scale
to high-dimensional survival settings. The package implements several
algorithms tailored for large-scale problems, including sparse, grouped,
and deviance-residual-based approaches. It integrates with the
<strong>bigmemory</strong> ecosystem so that data stored on disk can be
analysed without exhausting RAM.</p>
<p>This vignette gives a quick tour of the core workflows. It highlights
how to prepare data, fit a model, assess model quality, and explore
advanced extensions. The complementary vignette “Getting started with
bigPLScox” offers a more hands-on tutorial, while “Benchmarking
bigPLScox” focuses on performance comparisons.</p>
</div>
<div class="section level2">
<h2 id="package-highlights">Package highlights<a class="anchor" aria-label="anchor" href="#package-highlights"></a>
</h2>
<ul>
<li>
<strong>Generalised PLS Cox regression</strong> via
<code><a href="../reference/coxgpls.html">coxgpls()</a></code> with support for grouped predictors.</li>
<li>
<strong>Sparse and structured-sparse extensions</strong> through
<code><a href="../reference/coxsgpls.html">coxsgpls()</a></code> and <code><a href="../reference/coxspls_sgpls.html">coxspls_sgpls()</a></code>.</li>
<li>
<strong>Deviance-residual estimators</strong> such as
<code><a href="../reference/coxgplsDR.html">coxgplsDR()</a></code> for increased robustness.</li>
<li>
<strong>Cross-validation helpers</strong>
(<code><a href="../reference/cv.coxgpls.html">cv.coxgpls()</a></code>, <code><a href="../reference/cv.coxsgpls.html">cv.coxsgpls()</a></code>, …) to select the
number of latent components.</li>
<li>
<strong>Big-memory interfaces</strong> (<code><a href="../reference/big_pls_cox.html">big_pls_cox()</a></code>,
<code><a href="../reference/big_pls_cox_gd.html">big_pls_cox_gd()</a></code>) designed for file-backed matrices stored
with <strong>bigmemory</strong>.</li>
</ul>
</div>
<div class="section level2">
<h2 id="available-algorithms">Available algorithms<a class="anchor" aria-label="anchor" href="#available-algorithms"></a>
</h2>
<p>The following modeling functions are provided:</p>
<ul>
<li>
<code><a href="../reference/coxgpls.html">coxgpls()</a></code> for generalized PLS Cox regression.</li>
<li>
<code><a href="../reference/coxsgpls.html">coxsgpls()</a></code> and <code><a href="../reference/coxspls_sgpls.html">coxspls_sgpls()</a></code> for sparse
and structured sparse extensions.</li>
<li>
<code><a href="../reference/coxgplsDR.html">coxgplsDR()</a></code> and <code><a href="../reference/coxsgplsDR.html">coxsgplsDR()</a></code> for
deviance-residual-based estimation.</li>
<li>
<code><a href="../reference/cv.coxgpls.html">cv.coxgpls()</a></code> and related <code>cv.*</code> helpers for
component selection.</li>
</ul>
<p>For stochastic gradient descent on large data the package includes
<code><a href="../reference/big_pls_cox.html">big_pls_cox()</a></code> and <code><a href="../reference/big_pls_cox_gd.html">big_pls_cox_gd()</a></code>.</p>
</div>
<div class="section level2">
<h2 id="loading-an-example-dataset">Loading an example dataset<a class="anchor" aria-label="anchor" href="#loading-an-example-dataset"></a>
</h2>
<p>The package ships with a small allelotyping dataset that we use
throughout this vignette. The data include censoring indicators
alongside a large set of predictors.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://fbertran.github.io/bigPLScox/">bigPLScox</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">micro.censure</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">Xmicro.censure_compl_imp</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_idx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="fl">80</span><span class="op">)</span></span>
<span><span class="va">Y_train</span> <span class="op">&lt;-</span> <span class="va">micro.censure</span><span class="op">$</span><span class="va">survyear</span><span class="op">[</span><span class="va">train_idx</span><span class="op">]</span></span>
<span><span class="va">C_train</span> <span class="op">&lt;-</span> <span class="va">micro.censure</span><span class="op">$</span><span class="va">DC</span><span class="op">[</span><span class="va">train_idx</span><span class="op">]</span></span>
<span><span class="va">X_train</span> <span class="op">&lt;-</span> <span class="va">Xmicro.censure_compl_imp</span><span class="op">[</span><span class="va">train_idx</span>, <span class="op">-</span><span class="fl">40</span><span class="op">]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="fitting-a-pls-cox-model">Fitting a PLS-Cox model<a class="anchor" aria-label="anchor" href="#fitting-a-pls-cox-model"></a>
</h2>
<p><code><a href="../reference/coxgpls.html">coxgpls()</a></code> provides a matrix interface that mirrors
<code><a href="https://rdrr.io/pkg/survival/man/coxph.html" class="external-link">survival::coxph()</a></code> but adds latent components to stabilise
estimation in high dimensions.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/coxgpls.html">coxgpls</a></span><span class="op">(</span></span>
<span>  <span class="va">X_train</span>,</span>
<span>  <span class="va">Y_train</span>,</span>
<span>  <span class="va">C_train</span>,</span>
<span>  ncomp <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  ind.block.x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">fit</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; coxph(formula = YCsurv ~ ., data = tt_gpls)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          coef exp(coef) se(coef)      z       p</span></span>
<span><span class="co">#&gt; dim.1 -0.6003    0.5486   0.2197 -2.733 0.00628</span></span>
<span><span class="co">#&gt; dim.2 -0.6876    0.5028   0.2816 -2.442 0.01460</span></span>
<span><span class="co">#&gt; dim.3 -0.4922    0.6113   0.2498 -1.971 0.04877</span></span>
<span><span class="co">#&gt; dim.4  0.2393    1.2703   0.2861  0.836 0.40292</span></span>
<span><span class="co">#&gt; dim.5 -0.3689    0.6915   0.2200 -1.677 0.09359</span></span>
<span><span class="co">#&gt; dim.6  0.1570    1.1700   0.2763  0.568 0.56979</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Likelihood ratio test=23.99  on 6 df, p=0.0005249</span></span>
<span><span class="co">#&gt; n= 80, number of events= 17</span></span></code></pre></div>
<p>The summary includes convergence diagnostics, latent component
information, and predicted linear predictors that can be used for risk
stratification.</p>
</div>
<div class="section level2">
<h2 id="model-assessment">Model assessment<a class="anchor" aria-label="anchor" href="#model-assessment"></a>
</h2>
<p>Cross-validation helps decide how many components should be retained.
The <code><a href="../reference/cv.coxgpls.html">cv.coxgpls()</a></code> helper accepts either a matrix or a list
containing <code>x</code>, <code>time</code>, and <code>status</code>
elements.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">cv_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.coxgpls.html">cv.coxgpls</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">X_train</span>, time <span class="op">=</span> <span class="va">Y_train</span>, status <span class="op">=</span> <span class="va">C_train</span><span class="op">)</span>,</span>
<span>  nt <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  ind.block.x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; CV Fold 1</span></span>
<span><span class="co">#&gt; CV Fold 2</span></span>
<span><span class="co">#&gt; CV Fold 3</span></span>
<span><span class="co">#&gt; CV Fold 4</span></span>
<span><span class="co">#&gt; CV Fold 5</span></span></code></pre></div>
<p><img src="figures/overview-cv-coxgpls-1.png" width="1050"></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv_res</span></span>
<span><span class="co">#&gt; $nt</span></span>
<span><span class="co">#&gt; [1] 10</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cv.error10</span></span>
<span><span class="co">#&gt;  [1] 0.5000000 0.6013049 0.5183694 0.4226056 0.3860331 0.4071207 0.4252845</span></span>
<span><span class="co">#&gt;  [8] 0.4001223 0.4464093 0.4526887 0.4695600</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cv.se10</span></span>
<span><span class="co">#&gt;  [1] 0.00000000 0.03487588 0.06866706 0.07717020 0.07373734 0.07084802</span></span>
<span><span class="co">#&gt;  [7] 0.07707939 0.07247893 0.07317843 0.06341118 0.06252387</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $folds</span></span>
<span><span class="co">#&gt; $folds$`1`</span></span>
<span><span class="co">#&gt;  [1] 31 42 69 75 72 12 66 27 71 55 58 49 11 30 37 22</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $folds$`2`</span></span>
<span><span class="co">#&gt;  [1] 79 50 57 68 17 15 64 74 34 13 80 76 61  2 24 35</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $folds$`3`</span></span>
<span><span class="co">#&gt;  [1] 51 43  9 62 73 32 41 78 29 18  6 16 44 59 33 48</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $folds$`4`</span></span>
<span><span class="co">#&gt;  [1] 14 77 26 19 39 65 10 56  5  1 21 20 46 60  3 47</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $folds$`5`</span></span>
<span><span class="co">#&gt;  [1] 67 25  7 36 53 45 23 38  8 40 54 28 52  4 70 63</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $lambda.min10</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $lambda.1se10</span></span>
<span><span class="co">#&gt; [1] 0</span></span></code></pre></div>
<p>The resulting object may be plotted to visualise the cross-validated
deviance or to apply one-standard-error rules when choosing the number
of components.</p>
</div>
<div class="section level2">
<h2 id="alternative-estimators">Alternative estimators<a class="anchor" aria-label="anchor" href="#alternative-estimators"></a>
</h2>
<p>Deviance-residual-based estimators provide increased robustness by
iteratively updating residuals. Sparse variants enable feature selection
in extremely high-dimensional designs.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dr_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/coxgplsDR.html">coxgplsDR</a></span><span class="op">(</span></span>
<span>  <span class="va">X_train</span>,</span>
<span>  <span class="va">Y_train</span>,</span>
<span>  <span class="va">C_train</span>,</span>
<span>  ncomp <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  ind.block.x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">dr_fit</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; coxph(formula = YCsurv ~ ., data = tt_gplsDR)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          coef exp(coef) se(coef)     z        p</span></span>
<span><span class="co">#&gt; dim.1 0.92699   2.52690  0.23301 3.978 6.94e-05</span></span>
<span><span class="co">#&gt; dim.2 0.85445   2.35008  0.27352 3.124  0.00178</span></span>
<span><span class="co">#&gt; dim.3 0.56308   1.75607  0.29847 1.887  0.05922</span></span>
<span><span class="co">#&gt; dim.4 0.49242   1.63627  0.32344 1.522  0.12789</span></span>
<span><span class="co">#&gt; dim.5 0.18706   1.20569  0.38769 0.482  0.62946</span></span>
<span><span class="co">#&gt; dim.6 0.08581   1.08960  0.31517 0.272  0.78541</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Likelihood ratio test=51.46  on 6 df, p=2.39e-09</span></span>
<span><span class="co">#&gt; n= 80, number of events= 17</span></span></code></pre></div>
<p>Additional sparse estimators can be invoked via
<code><a href="../reference/coxsgpls.html">coxsgpls()</a></code> and <code><a href="../reference/coxspls_sgpls.html">coxspls_sgpls()</a></code> by providing
<code>keepX</code> or <code>penalty</code> arguments that control the
number of active predictors per component.</p>
</div>
<div class="section level2">
<h2 id="working-with-big-data">Working with big data<a class="anchor" aria-label="anchor" href="#working-with-big-data"></a>
</h2>
<p>For extremely large problems, stochastic gradient descent routines
operate on memory-mapped matrices created with
<strong>bigmemory</strong>. The helper below converts a standard matrix
to a <code>big.matrix</code> and runs a small example.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X_big</span> <span class="op">&lt;-</span> <span class="fu">bigmemory</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/bigmemory/man/big.matrix.html" class="external-link">as.big.matrix</a></span><span class="op">(</span><span class="va">X_train</span><span class="op">)</span></span>
<span><span class="va">big_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/big_pls_cox.html">big_pls_cox</a></span><span class="op">(</span></span>
<span>  <span class="va">X_big</span>,</span>
<span>  time <span class="op">=</span> <span class="va">Y_train</span>,</span>
<span>  status <span class="op">=</span> <span class="va">C_train</span>,</span>
<span>  ncomp <span class="op">=</span> <span class="fl">6</span></span>
<span><span class="op">)</span></span>
<span><span class="va">big_fit</span></span>
<span><span class="co">#&gt; $scores</span></span>
<span><span class="co">#&gt;               [,1]        [,2]        [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] -1.057691442 -0.91808629 -0.55160423  0.610842224 -0.698100417</span></span>
<span><span class="co">#&gt;  [2,]  0.357620245 -1.68049116  1.06881321 -1.370769779  0.069686124</span></span>
<span><span class="co">#&gt;  [3,]  0.890037203 -0.48772481 -0.43628009 -0.011833733 -0.523369440</span></span>
<span><span class="co">#&gt;  [4,]  0.367488795  0.10054495 -0.46883245 -1.879590192  1.773509331</span></span>
<span><span class="co">#&gt;  [5,]  0.903470844  0.01518964 -1.01787232  0.275282810  1.511007308</span></span>
<span><span class="co">#&gt;  [6,] -0.734723223 -0.20970400 -0.17592505  0.157109400  1.492831471</span></span>
<span><span class="co">#&gt;  [7,] -0.781116052  0.93552226 -0.86927585 -0.091047843 -0.155438134</span></span>
<span><span class="co">#&gt;  [8,]  1.862985380  0.49567079 -1.51989814 -0.114046931 -0.337534718</span></span>
<span><span class="co">#&gt;  [9,]  0.013263162 -1.11695934 -0.52389935 -0.698570599 -1.456536784</span></span>
<span><span class="co">#&gt; [10,]  0.281817048 -0.67388720  1.89736990 -0.878702955  0.793550654</span></span>
<span><span class="co">#&gt; [11,]  0.686835134  1.57085473 -0.29254131  0.728580810 -0.446407041</span></span>
<span><span class="co">#&gt; [12,] -1.380630565  1.33881147 -0.21810275  1.262138454  0.267895641</span></span>
<span><span class="co">#&gt; [13,]  0.680242709 -1.00119258  0.33987736  0.626444104 -0.854635921</span></span>
<span><span class="co">#&gt; [14,] -1.023827340  0.61940247  0.23567420  0.562136815 -0.562949187</span></span>
<span><span class="co">#&gt; [15,]  0.327366374 -0.66241169 -0.47769998  0.242896297 -1.401717065</span></span>
<span><span class="co">#&gt; [16,]  0.696787597 -1.24730951 -0.67669477  0.547688115  0.599442037</span></span>
<span><span class="co">#&gt; [17,] -1.160288793 -0.30275653  0.23404305 -0.820779257  0.145122925</span></span>
<span><span class="co">#&gt; [18,] -1.229767452 -0.70020376 -0.41538023 -1.103563807  0.122397952</span></span>
<span><span class="co">#&gt; [19,]  0.474747590  1.38332129 -0.48760777 -0.946269867 -1.391471451</span></span>
<span><span class="co">#&gt; [20,] -1.323785735  0.91675748 -0.58959085  0.223131196 -0.784508329</span></span>
<span><span class="co">#&gt; [21,] -0.676201807 -1.25851405  1.00406597  0.169990426  0.890898543</span></span>
<span><span class="co">#&gt; [22,] -0.460363613 -0.94447412  0.42414575  1.881667415 -0.812707658</span></span>
<span><span class="co">#&gt; [23,]  0.434584944 -0.95345600  0.95661179 -0.154181134 -1.012236385</span></span>
<span><span class="co">#&gt; [24,]  0.405417623  0.60872670 -0.93358184  0.351494234  0.879224262</span></span>
<span><span class="co">#&gt; [25,] -2.001768372 -0.35079572 -1.10353782  0.851017736 -0.266591138</span></span>
<span><span class="co">#&gt; [26,] -1.280170067  0.92678430  0.33550112 -0.668292099  0.537666143</span></span>
<span><span class="co">#&gt; [27,]  1.516627653  0.30311515  0.84157130  0.277435969  0.296238010</span></span>
<span><span class="co">#&gt; [28,]  1.135607402 -0.47623800 -1.59321402  0.391019881  0.220533655</span></span>
<span><span class="co">#&gt; [29,] -0.440870666  0.46433023  0.91740183 -0.636039962  0.193183592</span></span>
<span><span class="co">#&gt; [30,] -1.247587296  0.29220818  0.11366841 -1.202161519  2.289769942</span></span>
<span><span class="co">#&gt; [31,]  0.916078015 -0.02717985  1.50759676  2.129121693 -0.836208870</span></span>
<span><span class="co">#&gt; [32,] -1.183848404 -0.90484455  0.74296420  0.770462537  0.318822484</span></span>
<span><span class="co">#&gt; [33,] -0.989070106 -1.12734452  1.46523276  0.498692439 -0.886269079</span></span>
<span><span class="co">#&gt; [34,] -0.190331860  1.32576365 -0.65838798 -0.684686463 -1.611840821</span></span>
<span><span class="co">#&gt; [35,]  1.228261591 -0.08676566 -0.39029225  1.926302382  0.611812427</span></span>
<span><span class="co">#&gt; [36,] -0.174988461  0.48642193 -0.54331684 -0.245860269 -0.869437742</span></span>
<span><span class="co">#&gt; [37,]  1.239570180  1.83021030  0.76095531  0.675720747  1.378750787</span></span>
<span><span class="co">#&gt; [38,] -0.757158745  1.19823673  1.29572024  1.101976260  0.105575024</span></span>
<span><span class="co">#&gt; [39,] -1.360175735 -0.29942751  0.60772966  0.297233334  0.413033989</span></span>
<span><span class="co">#&gt; [40,]  0.300293266 -0.50275288  0.03398259  2.373971715 -0.095899194</span></span>
<span><span class="co">#&gt; [41,]  0.006573713  0.85832512  1.29566678 -0.009902972  0.210924212</span></span>
<span><span class="co">#&gt; [42,]  1.136032395 -0.64946729 -0.79621361  0.321781315 -0.708769688</span></span>
<span><span class="co">#&gt; [43,] -1.277382893  0.74838459  1.76730007  1.264634618  0.378361186</span></span>
<span><span class="co">#&gt; [44,] -0.257044762 -1.18309793  1.49031745  1.468151876  0.754713306</span></span>
<span><span class="co">#&gt; [45,] -0.728904838  0.55425371 -0.33128462 -1.454648518 -0.801641810</span></span>
<span><span class="co">#&gt; [46,]  0.080256632  0.40118632 -0.89821842  0.772430776  2.060234543</span></span>
<span><span class="co">#&gt; [47,] -0.325229728 -1.06766514 -1.26738123 -1.152754129  0.904905680</span></span>
<span><span class="co">#&gt; [48,]  0.554076117 -0.84408303 -0.20964816 -2.291866502  2.282421843</span></span>
<span><span class="co">#&gt; [49,]  1.080774216 -0.29858076  0.74271045  1.105686606  0.375605013</span></span>
<span><span class="co">#&gt; [50,] -0.056861121  0.09359631 -0.51801971 -1.459047448 -0.814658016</span></span>
<span><span class="co">#&gt; [51,] -0.279208261  0.41720838  0.15320535 -1.691330048  0.173602626</span></span>
<span><span class="co">#&gt; [52,]  1.759626388 -2.97885390  0.22323912  0.120850649  0.065137908</span></span>
<span><span class="co">#&gt; [53,]  0.394773535 -0.72070512  0.16112904  0.384172457 -1.038943651</span></span>
<span><span class="co">#&gt; [54,]  1.262434022  1.40890556  2.95345799 -1.006778607  1.073372699</span></span>
<span><span class="co">#&gt; [55,]  1.728167348  0.29567406  1.28125255 -0.678332331 -0.086767542</span></span>
<span><span class="co">#&gt; [56,] -1.049401780 -0.37087582 -0.03207555 -0.036923882  0.073087734</span></span>
<span><span class="co">#&gt; [57,] -1.732421214 -0.39772207 -0.18644854 -0.175987586 -1.182646765</span></span>
<span><span class="co">#&gt; [58,] -0.069369600  0.91188211  1.85696555 -0.602786862  0.008200431</span></span>
<span><span class="co">#&gt; [59,] -0.798072356  2.29315088  0.27505974  0.767803540  1.093852798</span></span>
<span><span class="co">#&gt; [60,] -0.963395562  1.25625947 -0.25326358  0.726388531 -0.847846273</span></span>
<span><span class="co">#&gt; [61,]  0.857347742  1.72203044 -0.19244402 -1.214133464 -0.285753268</span></span>
<span><span class="co">#&gt; [62,]  0.592076303 -0.43369238  1.60438784 -0.040617347 -1.392595804</span></span>
<span><span class="co">#&gt; [63,]  2.763127339  0.35861686 -1.67385652  1.549183168  0.012390487</span></span>
<span><span class="co">#&gt; [64,]  0.316329864 -2.40076859 -0.59864294 -0.908126260  0.891060724</span></span>
<span><span class="co">#&gt; [65,]  1.443724603 -0.13607123  0.77493250 -2.457383559 -1.190232065</span></span>
<span><span class="co">#&gt; [66,] -0.150032733  0.47310027 -0.21808529 -0.186686954 -1.885677598</span></span>
<span><span class="co">#&gt; [67,] -1.544590304 -0.68795362 -1.93035684 -0.964995102  0.279915206</span></span>
<span><span class="co">#&gt; [68,]  0.055493347 -0.17231038 -1.99040856  0.107431313 -0.555621730</span></span>
<span><span class="co">#&gt; [69,]  1.058644687  1.04942217  0.06166945 -1.279968648 -1.044716723</span></span>
<span><span class="co">#&gt; [70,] -0.698346550 -0.10995660 -0.45337446 -0.091039250 -0.189249749</span></span>
<span><span class="co">#&gt; [71,]  0.125445344  0.70663095  0.54666527  1.135824787  2.341891020</span></span>
<span><span class="co">#&gt; [72,]  0.626145672  2.31376257 -1.46652685  0.015119025 -0.967300589</span></span>
<span><span class="co">#&gt; [73,]  0.774673005 -0.49606443  1.62568540 -0.676425152 -1.163117184</span></span>
<span><span class="co">#&gt; [74,] -0.647482200 -0.18103806 -0.49706863 -1.341787508  1.567779533</span></span>
<span><span class="co">#&gt; [75,]  1.039132154 -0.71939319 -0.70054461  0.331531931 -0.607350233</span></span>
<span><span class="co">#&gt; [76,]  1.146190775  0.40486835 -1.68481390  0.899779337  2.104415321</span></span>
<span><span class="co">#&gt; [77,] -0.675584944 -0.20884802  0.20090540 -0.115599574 -1.295834004</span></span>
<span><span class="co">#&gt; [78,] -0.491354295 -0.27404283 -1.47380425  0.631487818 -0.073999104</span></span>
<span><span class="co">#&gt; [79,] -0.767880597  0.88756326 -0.24995837 -0.205270178 -0.627641082</span></span>
<span><span class="co">#&gt; [80,] -1.553218484 -1.70298354 -0.23150082  1.014173551  0.201397680</span></span>
<span><span class="co">#&gt;               [,6]</span></span>
<span><span class="co">#&gt;  [1,] -1.681314844</span></span>
<span><span class="co">#&gt;  [2,]  0.109460206</span></span>
<span><span class="co">#&gt;  [3,] -0.049283265</span></span>
<span><span class="co">#&gt;  [4,]  0.956403890</span></span>
<span><span class="co">#&gt;  [5,] -0.912163665</span></span>
<span><span class="co">#&gt;  [6,]  0.998380013</span></span>
<span><span class="co">#&gt;  [7,] -1.229355532</span></span>
<span><span class="co">#&gt;  [8,] -1.557511739</span></span>
<span><span class="co">#&gt;  [9,]  0.750521868</span></span>
<span><span class="co">#&gt; [10,] -1.063991892</span></span>
<span><span class="co">#&gt; [11,] -2.346035979</span></span>
<span><span class="co">#&gt; [12,]  0.154712531</span></span>
<span><span class="co">#&gt; [13,]  0.196730701</span></span>
<span><span class="co">#&gt; [14,] -0.345141009</span></span>
<span><span class="co">#&gt; [15,]  0.678027059</span></span>
<span><span class="co">#&gt; [16,] -1.232518327</span></span>
<span><span class="co">#&gt; [17,]  0.726483579</span></span>
<span><span class="co">#&gt; [18,] -1.047240491</span></span>
<span><span class="co">#&gt; [19,]  1.763679169</span></span>
<span><span class="co">#&gt; [20,] -0.304301737</span></span>
<span><span class="co">#&gt; [21,] -1.416126622</span></span>
<span><span class="co">#&gt; [22,] -0.580693246</span></span>
<span><span class="co">#&gt; [23,]  0.001507040</span></span>
<span><span class="co">#&gt; [24,]  0.012279593</span></span>
<span><span class="co">#&gt; [25,] -0.074475224</span></span>
<span><span class="co">#&gt; [26,]  0.085883847</span></span>
<span><span class="co">#&gt; [27,]  1.264731457</span></span>
<span><span class="co">#&gt; [28,]  1.896551387</span></span>
<span><span class="co">#&gt; [29,]  2.610735922</span></span>
<span><span class="co">#&gt; [30,]  0.341812336</span></span>
<span><span class="co">#&gt; [31,]  0.232973897</span></span>
<span><span class="co">#&gt; [32,] -0.982011719</span></span>
<span><span class="co">#&gt; [33,]  1.066749867</span></span>
<span><span class="co">#&gt; [34,]  0.387558283</span></span>
<span><span class="co">#&gt; [35,]  0.589148420</span></span>
<span><span class="co">#&gt; [36,]  0.156211021</span></span>
<span><span class="co">#&gt; [37,]  0.615708570</span></span>
<span><span class="co">#&gt; [38,]  0.742428610</span></span>
<span><span class="co">#&gt; [39,] -0.311992069</span></span>
<span><span class="co">#&gt; [40,]  0.591370590</span></span>
<span><span class="co">#&gt; [41,]  1.198126168</span></span>
<span><span class="co">#&gt; [42,] -1.571833317</span></span>
<span><span class="co">#&gt; [43,] -0.464900832</span></span>
<span><span class="co">#&gt; [44,]  1.433739347</span></span>
<span><span class="co">#&gt; [45,]  0.451020219</span></span>
<span><span class="co">#&gt; [46,] -1.424222110</span></span>
<span><span class="co">#&gt; [47,]  0.003990556</span></span>
<span><span class="co">#&gt; [48,]  0.929038368</span></span>
<span><span class="co">#&gt; [49,] -1.741459267</span></span>
<span><span class="co">#&gt; [50,] -1.726518637</span></span>
<span><span class="co">#&gt; [51,]  0.498111929</span></span>
<span><span class="co">#&gt; [52,]  0.420789635</span></span>
<span><span class="co">#&gt; [53,]  1.810211404</span></span>
<span><span class="co">#&gt; [54,] -0.630811701</span></span>
<span><span class="co">#&gt; [55,] -0.470750158</span></span>
<span><span class="co">#&gt; [56,] -0.258860461</span></span>
<span><span class="co">#&gt; [57,] -0.745299913</span></span>
<span><span class="co">#&gt; [58,] -0.662867713</span></span>
<span><span class="co">#&gt; [59,] -0.913171501</span></span>
<span><span class="co">#&gt; [60,] -0.153232027</span></span>
<span><span class="co">#&gt; [61,]  0.580034382</span></span>
<span><span class="co">#&gt; [62,] -0.199170693</span></span>
<span><span class="co">#&gt; [63,]  1.598750718</span></span>
<span><span class="co">#&gt; [64,]  0.434040307</span></span>
<span><span class="co">#&gt; [65,] -1.331700294</span></span>
<span><span class="co">#&gt; [66,] -0.600543032</span></span>
<span><span class="co">#&gt; [67,]  0.076276702</span></span>
<span><span class="co">#&gt; [68,] -0.910560572</span></span>
<span><span class="co">#&gt; [69,] -1.241309067</span></span>
<span><span class="co">#&gt; [70,]  0.141554412</span></span>
<span><span class="co">#&gt; [71,]  0.259439391</span></span>
<span><span class="co">#&gt; [72,]  1.407141048</span></span>
<span><span class="co">#&gt; [73,] -0.525751680</span></span>
<span><span class="co">#&gt; [74,]  0.367885075</span></span>
<span><span class="co">#&gt; [75,] -0.252717073</span></span>
<span><span class="co">#&gt; [76,] -1.184086477</span></span>
<span><span class="co">#&gt; [77,]  0.900889879</span></span>
<span><span class="co">#&gt; [78,]  1.294132109</span></span>
<span><span class="co">#&gt; [79,]  0.994859579</span></span>
<span><span class="co">#&gt; [80,]  0.413842798</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $loadings</span></span>
<span><span class="co">#&gt;              [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] -0.01249289  0.386519358 -0.175915209  0.142642722  0.165739063</span></span>
<span><span class="co">#&gt;  [2,] -0.08586893  0.164198917 -0.023769642  0.076272008 -0.193852504</span></span>
<span><span class="co">#&gt;  [3,] -0.10260523  0.237412606  0.180208540 -0.373085059  0.025725292</span></span>
<span><span class="co">#&gt;  [4,]  0.45653301  0.408288717  0.058419876 -0.139720696  0.117171972</span></span>
<span><span class="co">#&gt;  [5,] -0.01586879  0.437101417 -0.001287363 -0.076797945  0.032346506</span></span>
<span><span class="co">#&gt;  [6,] -0.04070823  0.384716552 -0.160137861 -0.153866665  0.397583642</span></span>
<span><span class="co">#&gt;  [7,] -0.19460130  0.462467413 -0.340410483  0.290071168 -0.044674480</span></span>
<span><span class="co">#&gt;  [8,] -0.31337128  0.315855237 -0.466151309 -0.040245071  0.179564760</span></span>
<span><span class="co">#&gt;  [9,] -0.13371278  0.182138648 -0.245009791  0.226855245  0.026193656</span></span>
<span><span class="co">#&gt; [10,]  0.26367185  0.215783999 -0.404680857  0.195745760 -0.127182812</span></span>
<span><span class="co">#&gt; [11,] -0.28074023 -0.006999664  0.098452186 -0.212323607 -0.285912120</span></span>
<span><span class="co">#&gt; [12,] -0.53821212 -0.039843017 -0.060059944 -0.013502608 -0.181012046</span></span>
<span><span class="co">#&gt; [13,]  0.08889652  0.371435729  0.212359810  0.474538405  0.489000260</span></span>
<span><span class="co">#&gt; [14,] -0.32968201  0.351061571 -0.064737703 -0.345019624 -0.411593679</span></span>
<span><span class="co">#&gt; [15,]  0.30702316  0.198430683 -0.318444855 -0.081513237  0.033994796</span></span>
<span><span class="co">#&gt; [16,] -0.39331096 -0.001746886 -0.158869321  0.151441819  0.533968694</span></span>
<span><span class="co">#&gt; [17,] -0.15641858  0.070113093 -0.115320435  0.442636007  0.325270233</span></span>
<span><span class="co">#&gt; [18,] -0.16616164  0.170481037  0.129159710 -0.178645666  0.140155475</span></span>
<span><span class="co">#&gt; [19,] -0.23652619 -0.127281388 -0.124007112  0.197311078  0.107308135</span></span>
<span><span class="co">#&gt; [20,] -0.04496451 -0.005410546  0.292238510  0.317014940 -0.273826135</span></span>
<span><span class="co">#&gt; [21,]  0.11157297  0.277701209 -0.416536105 -0.222882422 -0.186106801</span></span>
<span><span class="co">#&gt; [22,] -0.08537752  0.406429076  0.002132278  0.015657479 -0.121877054</span></span>
<span><span class="co">#&gt; [23,] -0.46872309  0.313582206 -0.274295434 -0.072532544  0.126515747</span></span>
<span><span class="co">#&gt; [24,] -0.17065184  0.204061287  0.042207752  0.005592996 -0.082202931</span></span>
<span><span class="co">#&gt; [25,] -0.02075303 -0.137929389  0.590175809  0.353606931  0.155357437</span></span>
<span><span class="co">#&gt; [26,] -0.43011292  0.312207974  0.102326925  0.257597329 -0.004220737</span></span>
<span><span class="co">#&gt; [27,]  0.07862213  0.349258578  0.042795621  0.057830761  0.169992652</span></span>
<span><span class="co">#&gt; [28,] -0.22071839  0.067182562 -0.287824419  0.597240134  0.254610781</span></span>
<span><span class="co">#&gt; [29,] -0.04195021  0.478524436 -0.194361581  0.148377975 -0.393275185</span></span>
<span><span class="co">#&gt; [30,] -0.15128604  0.269616732  0.376184319  0.043015421  0.442887500</span></span>
<span><span class="co">#&gt; [31,] -0.45236869  0.024267457 -0.004607516  0.143564021 -0.378856470</span></span>
<span><span class="co">#&gt; [32,] -0.38211577  0.298294981 -0.002957238  0.103558347  0.338344280</span></span>
<span><span class="co">#&gt; [33,] -0.26592647  0.057951395 -0.018891916  0.396620616 -0.128082858</span></span>
<span><span class="co">#&gt; [34,]  0.05829837 -0.336356180  0.023008033  0.096806630 -0.157164557</span></span>
<span><span class="co">#&gt; [35,]  0.08805016  0.245602076 -0.061288127 -0.252731204 -0.023593238</span></span>
<span><span class="co">#&gt; [36,]  0.09638370 -0.365308807 -0.125684660  0.326372149  0.146273293</span></span>
<span><span class="co">#&gt; [37,]  0.31654542  0.079903927 -0.466427416  0.163652176 -0.435090539</span></span>
<span><span class="co">#&gt; [38,]  0.60654920 -0.057598955 -0.268557775  0.282947472 -0.127922817</span></span>
<span><span class="co">#&gt; [39,]  0.52771440 -0.255735445 -0.233301956  0.230140286  0.220562573</span></span>
<span><span class="co">#&gt;                [,6]</span></span>
<span><span class="co">#&gt;  [1,]  0.0063391844</span></span>
<span><span class="co">#&gt;  [2,]  0.4713274961</span></span>
<span><span class="co">#&gt;  [3,] -0.1067750806</span></span>
<span><span class="co">#&gt;  [4,] -0.0176036321</span></span>
<span><span class="co">#&gt;  [5,] -0.2034229998</span></span>
<span><span class="co">#&gt;  [6,]  0.1666499484</span></span>
<span><span class="co">#&gt;  [7,] -0.1413171811</span></span>
<span><span class="co">#&gt;  [8,] -0.0767435879</span></span>
<span><span class="co">#&gt;  [9,]  0.0713624095</span></span>
<span><span class="co">#&gt; [10,] -0.1371957208</span></span>
<span><span class="co">#&gt; [11,]  0.0484540957</span></span>
<span><span class="co">#&gt; [12,]  0.3405858497</span></span>
<span><span class="co">#&gt; [13,] -0.0002831229</span></span>
<span><span class="co">#&gt; [14,]  0.0347285682</span></span>
<span><span class="co">#&gt; [15,] -0.2456681739</span></span>
<span><span class="co">#&gt; [16,] -0.1654983983</span></span>
<span><span class="co">#&gt; [17,]  0.1808495161</span></span>
<span><span class="co">#&gt; [18,] -0.1980570947</span></span>
<span><span class="co">#&gt; [19,] -0.3979934874</span></span>
<span><span class="co">#&gt; [20,]  0.3518217167</span></span>
<span><span class="co">#&gt; [21,]  0.0680205301</span></span>
<span><span class="co">#&gt; [22,] -0.3199329580</span></span>
<span><span class="co">#&gt; [23,] -0.1136524098</span></span>
<span><span class="co">#&gt; [24,]  0.0181112939</span></span>
<span><span class="co">#&gt; [25,] -0.0056750183</span></span>
<span><span class="co">#&gt; [26,]  0.0317675772</span></span>
<span><span class="co">#&gt; [27,]  0.0512538586</span></span>
<span><span class="co">#&gt; [28,] -0.3932803385</span></span>
<span><span class="co">#&gt; [29,]  0.1895734610</span></span>
<span><span class="co">#&gt; [30,]  0.0640666274</span></span>
<span><span class="co">#&gt; [31,]  0.4472456095</span></span>
<span><span class="co">#&gt; [32,] -0.3710595650</span></span>
<span><span class="co">#&gt; [33,]  0.1595623171</span></span>
<span><span class="co">#&gt; [34,] -0.3785580886</span></span>
<span><span class="co">#&gt; [35,]  0.3962147564</span></span>
<span><span class="co">#&gt; [36,]  0.3631479241</span></span>
<span><span class="co">#&gt; [37,]  0.0687554183</span></span>
<span><span class="co">#&gt; [38,] -0.0057914182</span></span>
<span><span class="co">#&gt; [39,] -0.1452723891</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $weights</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]          [,5]</span></span>
<span><span class="co">#&gt;  [1,]  0.052215879  0.240419308 -0.161908752  0.024740216  0.2111604497</span></span>
<span><span class="co">#&gt;  [2,] -0.034827909  0.084474856 -0.173922160  0.067864937  0.1175210182</span></span>
<span><span class="co">#&gt;  [3,] -0.001391453  0.141335334  0.154065251 -0.224649019 -0.0089002370</span></span>
<span><span class="co">#&gt;  [4,]  0.269622725  0.313179816 -0.037979386 -0.054736782  0.0012735403</span></span>
<span><span class="co">#&gt;  [5,]  0.027378727  0.211060958  0.007106119  0.071613945  0.1542108542</span></span>
<span><span class="co">#&gt;  [6,] -0.002555356  0.099603511 -0.178109475 -0.187903009  0.2954068622</span></span>
<span><span class="co">#&gt;  [7,] -0.116609767  0.181948312 -0.091708642  0.187746575 -0.1348122575</span></span>
<span><span class="co">#&gt;  [8,] -0.199633821 -0.070587422 -0.459236466 -0.003164958  0.1282159006</span></span>
<span><span class="co">#&gt;  [9,] -0.149144225 -0.050383249 -0.146224130  0.187872439 -0.0326676473</span></span>
<span><span class="co">#&gt; [10,]  0.101522309  0.137118268 -0.246453561  0.093856356 -0.0142865523</span></span>
<span><span class="co">#&gt; [11,] -0.189760666  0.026011039  0.053665156 -0.137372414 -0.2331523845</span></span>
<span><span class="co">#&gt; [12,] -0.276556703  0.065526328 -0.067606740  0.057921765 -0.1478701776</span></span>
<span><span class="co">#&gt; [13,]  0.218056618  0.280310383  0.065577276  0.231986307  0.2279127641</span></span>
<span><span class="co">#&gt; [14,] -0.151591107  0.117880080 -0.112208565 -0.242467908 -0.2201492887</span></span>
<span><span class="co">#&gt; [15,]  0.195864430  0.189164526 -0.185165309 -0.026577860 -0.1077735435</span></span>
<span><span class="co">#&gt; [16,] -0.257267985 -0.042343842 -0.073419847  0.045830324  0.2249531996</span></span>
<span><span class="co">#&gt; [17,] -0.148346511  0.020431183 -0.143372621  0.046835578  0.3366421512</span></span>
<span><span class="co">#&gt; [18,] -0.084111601  0.053355845  0.094413706 -0.227346273  0.0567815343</span></span>
<span><span class="co">#&gt; [19,] -0.195725609 -0.010192432 -0.019555057  0.118765157 -0.0686796085</span></span>
<span><span class="co">#&gt; [20,]  0.007935439 -0.035123813  0.176232317  0.217041233  0.0173703772</span></span>
<span><span class="co">#&gt; [21,]  0.056749548  0.140405020 -0.181444012 -0.108024779 -0.0780527249</span></span>
<span><span class="co">#&gt; [22,]  0.013721499  0.193867288 -0.050439336  0.072322950 -0.1762406678</span></span>
<span><span class="co">#&gt; [23,] -0.216454579  0.067135799 -0.177081772  0.015522853  0.0345302368</span></span>
<span><span class="co">#&gt; [24,] -0.097751534  0.079034635  0.023245750  0.146139763 -0.0076540950</span></span>
<span><span class="co">#&gt; [25,]  0.002239107  0.009120856  0.440139152  0.164461637  0.1230349122</span></span>
<span><span class="co">#&gt; [26,] -0.081356991  0.257305767  0.140494374  0.136831602 -0.0555499048</span></span>
<span><span class="co">#&gt; [27,]  0.173124225  0.196695428 -0.028694998  0.030037514  0.0267072869</span></span>
<span><span class="co">#&gt; [28,] -0.073427432  0.078668734 -0.047100811  0.352253902  0.0570259242</span></span>
<span><span class="co">#&gt; [29,]  0.050438770  0.209972241 -0.155411864  0.068260790 -0.1590282865</span></span>
<span><span class="co">#&gt; [30,]  0.009624597  0.136710186  0.155944665 -0.024523385  0.4211525788</span></span>
<span><span class="co">#&gt; [31,] -0.294404574  0.115712071  0.054534578  0.193810422 -0.1746227806</span></span>
<span><span class="co">#&gt; [32,] -0.155982776  0.100292492  0.041414692 -0.030958106  0.1892936819</span></span>
<span><span class="co">#&gt; [33,] -0.069622279  0.136210412 -0.001628406  0.296639360 -0.0556256063</span></span>
<span><span class="co">#&gt; [34,]  0.015047130 -0.126879646  0.095115710  0.077653748 -0.0529430847</span></span>
<span><span class="co">#&gt; [35,]  0.210646938  0.090614166 -0.054018010 -0.267620344 -0.0007203354</span></span>
<span><span class="co">#&gt; [36,]  0.050204885 -0.235970969 -0.029264420  0.205742962  0.1602293133</span></span>
<span><span class="co">#&gt; [37,]  0.187580708  0.035035882 -0.127899924  0.140120255 -0.2123884365</span></span>
<span><span class="co">#&gt; [38,]  0.382605577 -0.160444754 -0.059080333  0.284081768 -0.1337327840</span></span>
<span><span class="co">#&gt; [39,]  0.180538911 -0.415369848 -0.300875022  0.086247873  0.1001053218</span></span>
<span><span class="co">#&gt;               [,6]</span></span>
<span><span class="co">#&gt;  [1,]  0.029665386</span></span>
<span><span class="co">#&gt;  [2,]  0.430577447</span></span>
<span><span class="co">#&gt;  [3,] -0.162026460</span></span>
<span><span class="co">#&gt;  [4,] -0.047873822</span></span>
<span><span class="co">#&gt;  [5,]  0.031603106</span></span>
<span><span class="co">#&gt;  [6,]  0.005719541</span></span>
<span><span class="co">#&gt;  [7,] -0.234496364</span></span>
<span><span class="co">#&gt;  [8,] -0.060561520</span></span>
<span><span class="co">#&gt;  [9,]  0.038825188</span></span>
<span><span class="co">#&gt; [10,] -0.036902990</span></span>
<span><span class="co">#&gt; [11,] -0.006304792</span></span>
<span><span class="co">#&gt; [12,]  0.164474372</span></span>
<span><span class="co">#&gt; [13,]  0.029147353</span></span>
<span><span class="co">#&gt; [14,]  0.052668936</span></span>
<span><span class="co">#&gt; [15,] -0.236984837</span></span>
<span><span class="co">#&gt; [16,] -0.219672387</span></span>
<span><span class="co">#&gt; [17,]  0.131679559</span></span>
<span><span class="co">#&gt; [18,] -0.122756935</span></span>
<span><span class="co">#&gt; [19,] -0.245419135</span></span>
<span><span class="co">#&gt; [20,]  0.217703853</span></span>
<span><span class="co">#&gt; [21,]  0.117210298</span></span>
<span><span class="co">#&gt; [22,] -0.095201600</span></span>
<span><span class="co">#&gt; [23,] -0.127892607</span></span>
<span><span class="co">#&gt; [24,] -0.072265151</span></span>
<span><span class="co">#&gt; [25,]  0.041220612</span></span>
<span><span class="co">#&gt; [26,] -0.102400260</span></span>
<span><span class="co">#&gt; [27,] -0.071365384</span></span>
<span><span class="co">#&gt; [28,] -0.239776939</span></span>
<span><span class="co">#&gt; [29,]  0.144274171</span></span>
<span><span class="co">#&gt; [30,] -0.019200216</span></span>
<span><span class="co">#&gt; [31,]  0.317604921</span></span>
<span><span class="co">#&gt; [32,] -0.173622871</span></span>
<span><span class="co">#&gt; [33,]  0.124328637</span></span>
<span><span class="co">#&gt; [34,] -0.213372600</span></span>
<span><span class="co">#&gt; [35,]  0.227915458</span></span>
<span><span class="co">#&gt; [36,]  0.187689566</span></span>
<span><span class="co">#&gt; [37,]  0.070876063</span></span>
<span><span class="co">#&gt; [38,] -0.120492759</span></span>
<span><span class="co">#&gt; [39,] -0.091659035</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $center</span></span>
<span><span class="co">#&gt;  [1]  0.52500  0.45000  0.47500  0.60000  0.53750  0.47500  0.52500  0.47500</span></span>
<span><span class="co">#&gt;  [9]  0.37500  0.50000  0.46250  0.51250  0.46250  0.40000  0.43750  0.48750</span></span>
<span><span class="co">#&gt; [17]  0.45000  0.51250  0.51250  0.51250  0.45000  0.55000  0.42500  0.42500</span></span>
<span><span class="co">#&gt; [25]  0.47500  0.46250  0.52500  0.51250  0.48750  0.40000  0.57500  0.48750</span></span>
<span><span class="co">#&gt; [33]  0.41250  0.70000 64.23634  1.77500  2.51250  0.55000  0.25000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $scale</span></span>
<span><span class="co">#&gt;  [1]  0.5025253  0.5006325  0.5025253  0.4929888  0.5017375  0.5025253</span></span>
<span><span class="co">#&gt;  [7]  0.5025253  0.5025253  0.4871774  0.5031546  0.5017375  0.5029973</span></span>
<span><span class="co">#&gt; [13]  0.5017375  0.4929888  0.4992082  0.5029973  0.5006325  0.5029973</span></span>
<span><span class="co">#&gt; [19]  0.5029973  0.5029973  0.5006325  0.5006325  0.4974619  0.4974619</span></span>
<span><span class="co">#&gt; [25]  0.5025253  0.5017375  0.5025253  0.5029973  0.5029973  0.4929888</span></span>
<span><span class="co">#&gt; [31]  0.4974619  0.5029973  0.4953901  0.4611488 13.5030422  0.7458747</span></span>
<span><span class="co">#&gt; [37]  0.8999824  0.7778581  0.4357447</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit</span></span>
<span><span class="co">#&gt; $cox_fit$coefficients</span></span>
<span><span class="co">#&gt; [1]  7.905889  3.923515  3.692730  4.283208 -2.900388 -2.360674</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$var</span></span>
<span><span class="co">#&gt;           [,1]       [,2]      [,3]       [,4]       [,5]       [,6]</span></span>
<span><span class="co">#&gt; [1,]  4.536974  2.2590963  2.119616  2.5037040 -1.7136872 -1.3754037</span></span>
<span><span class="co">#&gt; [2,]  2.259096  1.2656583  1.075768  1.2911052 -0.8711192 -0.7019801</span></span>
<span><span class="co">#&gt; [3,]  2.119616  1.0757684  1.094191  1.2342944 -0.8522000 -0.6511180</span></span>
<span><span class="co">#&gt; [4,]  2.503704  1.2911052  1.234294  1.5352526 -1.0382724 -0.8329159</span></span>
<span><span class="co">#&gt; [5,] -1.713687 -0.8711192 -0.852200 -1.0382724  0.8292542  0.5642397</span></span>
<span><span class="co">#&gt; [6,] -1.375404 -0.7019801 -0.651118 -0.8329159  0.5642397  0.5430090</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$loglik</span></span>
<span><span class="co">#&gt; [1] -56.43995 -13.11777</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$score</span></span>
<span><span class="co">#&gt; [1] 47.66948</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$iter</span></span>
<span><span class="co">#&gt; [1] 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$linear.predictors</span></span>
<span><span class="co">#&gt;  [1]  -5.39087955  -6.15109660   5.09550487 -13.88375547   2.39351618</span></span>
<span><span class="co">#&gt;  [6] -13.29476930  -2.75192032  15.22802654  -6.75150764   3.03694859</span></span>
<span><span class="co">#&gt; [11]  20.46668210  -2.20388522   7.40235358   0.06153643   1.73042067</span></span>
<span><span class="co">#&gt; [16]   1.63285788 -15.14819858 -16.61315366   3.19944499  -5.09653794</span></span>
<span><span class="co">#&gt; [21]  -5.08886457   6.00858147   5.49932139   1.07251252 -16.68306316</span></span>
<span><span class="co">#&gt; [26]  -9.87033333  13.63075463  -2.21580410  -7.72364593 -20.89429368</span></span>
<span><span class="co">#&gt; [31]  23.69774455  -5.47242729  -4.64364378   2.09307288  13.01430218</span></span>
<span><span class="co">#&gt; [36]  -0.38140506  17.23261789   6.16118530  -8.87236032   9.57734124</span></span>
<span><span class="co">#&gt; [41]   4.72160666  10.63749894   4.78039144  -0.45588309  -9.78156407</span></span>
<span><span class="co">#&gt; [46]  -0.41319153 -19.01181143 -18.33508937  17.87312742  -1.80604943</span></span>
<span><span class="co">#&gt; [51]  -8.92843325   2.38355006   1.27385539  20.47855089  18.01160999</span></span>
<span><span class="co">#&gt; [56]  -9.62908763 -11.50954928   8.84579672   5.97522735   2.30930801</span></span>
<span><span class="co">#&gt; [61]   7.08300227  13.23913535  19.89632332 -16.62795366   9.81202643</span></span>
<span><span class="co">#&gt; [66]   5.95200818 -27.16404514  -3.36617391  13.19271845  -7.80186252</span></span>
<span><span class="co">#&gt; [71]   3.24305062   8.16133664  11.89873024 -18.82754928   6.58394537</span></span>
<span><span class="co">#&gt; [76]   4.97416410  -4.28205147 -10.53776977  -4.91879100 -17.03328838</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$residuals</span></span>
<span><span class="co">#&gt;             1             2             3             4             5 </span></span>
<span><span class="co">#&gt; -2.744308e-02 -1.781275e-09 -1.504830e-08 -1.243296e-15 -1.760046e-01 </span></span>
<span><span class="co">#&gt;             6             7             8             9            10 </span></span>
<span><span class="co">#&gt; -5.402201e-15 -2.047726e-10  1.600869e-01 -9.771827e-10 -9.588986e-10 </span></span>
<span><span class="co">#&gt;            11            12            13            14            15 </span></span>
<span><span class="co">#&gt;  5.583397e-01 -1.017192e-11 -5.262802e-06 -1.051131e-01 -2.596300e-10 </span></span>
<span><span class="co">#&gt;            16            17            18            19            20 </span></span>
<span><span class="co">#&gt; -2.354962e-10 -2.204648e-13 -1.956207e-16  6.059654e-01 -6.046914e-04 </span></span>
<span><span class="co">#&gt;            21            22            23            24            25 </span></span>
<span><span class="co">#&gt; -1.855479e-10 -2.322817e-07 -7.847668e-07 -4.696986e-02 -5.617846e-09 </span></span>
<span><span class="co">#&gt;            26            27            28            29            30 </span></span>
<span><span class="co">#&gt; -2.377997e-15 -2.501978e-02 -3.282543e-09 -1.419315e-12 -7.767146e-20 </span></span>
<span><span class="co">#&gt;            31            32            33            34            35 </span></span>
<span><span class="co">#&gt; -8.044200e-01 -8.592934e-10 -8.042840e-09 -2.514877e-04  1.856192e-01 </span></span>
<span><span class="co">#&gt;            36            37            38            39            40 </span></span>
<span><span class="co">#&gt; -1.097466e-02  8.261257e-02 -3.961750e-04 -6.450978e-15  5.523967e-01 </span></span>
<span><span class="co">#&gt;            41            42            43            44            45 </span></span>
<span><span class="co">#&gt; -5.169046e-09 -8.523020e-03 -1.586027e-07 -1.018698e-02 -2.598743e-15 </span></span>
<span><span class="co">#&gt;            46            47            48            49            50 </span></span>
<span><span class="co">#&gt; -3.069642e-03 -5.472771e-10 -3.278640e-16 -1.856164e-01  1.075299e-02 </span></span>
<span><span class="co">#&gt;            51            52            53            54            55 </span></span>
<span><span class="co">#&gt; -1.014002e-08 -7.175306e-02 -4.758185e-09 -4.216039e-02  9.969438e-01 </span></span>
<span><span class="co">#&gt;            56            57            58            59            60 </span></span>
<span><span class="co">#&gt; -5.498683e-11 -9.917412e-07 -3.195386e-07 -8.049978e-05 -1.617904e-01 </span></span>
<span><span class="co">#&gt;            61            62            63            64            65 </span></span>
<span><span class="co">#&gt; -6.801896e-07  5.303204e-01 -4.037155e-01 -1.927468e-16 -3.961013e-01 </span></span>
<span><span class="co">#&gt;            66            67            68            69            70 </span></span>
<span><span class="co">#&gt; -1.769160e-08 -4.800948e-20 -7.061154e-09 -9.098569e-01 -6.572449e-06 </span></span>
<span><span class="co">#&gt;            71            72            73            74            75 </span></span>
<span><span class="co">#&gt; -4.115968e-01 -2.056243e-01 -4.426646e-03 -1.361713e-15 -2.321597e-06 </span></span>
<span><span class="co">#&gt;            76            77            78            79            80 </span></span>
<span><span class="co">#&gt;  3.289011e-01 -2.220045e-04 -7.980437e-13 -6.108218e-09 -1.205199e-15 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$means</span></span>
<span><span class="co">#&gt; [1]  0.000000e+00 -1.110223e-17  4.163336e-17 -5.551115e-18  1.804112e-17</span></span>
<span><span class="co">#&gt; [6] -1.110223e-17</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$method</span></span>
<span><span class="co">#&gt; [1] "efron"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cox_fit$class</span></span>
<span><span class="co">#&gt; [1] "coxph"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $keepX</span></span>
<span><span class="co">#&gt; [1] 0 0 0 0 0 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $time</span></span>
<span><span class="co">#&gt;  [1] 6.1342466 2.0383562 0.8328767 1.1205479 3.9917808 1.4164384 1.3205479</span></span>
<span><span class="co">#&gt;  [8] 1.6712329 2.0547945 0.4520548 0.9150685 0.8794521 1.2356164 5.6712329</span></span>
<span><span class="co">#&gt; [15] 0.5013699 0.7506849 2.0164384 1.2794521 3.5452055 4.8493151 1.5890411</span></span>
<span><span class="co">#&gt; [22] 0.9150685 1.3287671 4.1123288 4.7589041 0.5945205 1.5780822 1.5780822</span></span>
<span><span class="co">#&gt; [29] 1.3506849 0.8602740 0.7753425 1.8109589 2.3452055 2.5178082 2.4356164</span></span>
<span><span class="co">#&gt; [36] 4.2246575 1.4246575 2.1972603 0.6054795 2.5013699 0.7150685 1.7260274</span></span>
<span><span class="co">#&gt; [43] 1.1315068 3.9013699 0.6164384 3.4191781 5.4219178 1.6054795 1.2849315</span></span>
<span><span class="co">#&gt; [50] 5.9260274 2.7726027 4.7041096 1.0849315 1.0246575 0.1835616 2.0958904</span></span>
<span><span class="co">#&gt; [57] 5.3369863 0.6410959 1.7726027 4.6821918 0.9260274 1.9397260 1.1890411</span></span>
<span><span class="co">#&gt; [64] 1.3260274 2.6575342 0.7561644 1.5972603 1.9150685 2.4493151 4.3726027</span></span>
<span><span class="co">#&gt; [71] 3.6876712 2.9753425 1.6000000 1.8410959 1.1890411 3.3397260 3.6958904</span></span>
<span><span class="co">#&gt; [78] 1.4712329 2.2712329 1.6630137</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $status</span></span>
<span><span class="co">#&gt;  [1] 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0</span></span>
<span><span class="co">#&gt; [39] 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1</span></span>
<span><span class="co">#&gt; [77] 0 0 0 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "big_pls_cox"</span></span></code></pre></div>
<p>The <code><a href="../reference/big_pls_cox_gd.html">big_pls_cox_gd()</a></code> function exposes a gradient-descent
variant that is often preferred for streaming workloads. Both functions
can be combined with <code><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">foreach::foreach()</a></code> for multi-core
execution.</p>
</div>
<div class="section level2">
<h2 id="further-reading">Further reading<a class="anchor" aria-label="anchor" href="#further-reading"></a>
</h2>
<ul>
<li>
<code><a href="../articles/getting-started.html">vignette("getting-started", package = "bigPLScox")</a></code> for
a detailed walkthrough of data preparation and model diagnostics.</li>
<li>
<code><a href="../articles/bigPLScox-benchmarking.html">vignette("bigPLScox-benchmarking", package = "bigPLScox")</a></code>
for reproducible performance comparisons.</li>
<li>The package website at <a href="https://fbertran.github.io/bigPLScox/" class="uri">https://fbertran.github.io/bigPLScox/</a> hosts reference
documentation and additional examples.</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Frederic Bertrand, Myriam Maumy-Bertrand.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
